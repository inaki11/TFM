{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-04T22:08:09.883027Z",
     "iopub.status.busy": "2024-04-04T22:08:09.882671Z",
     "iopub.status.idle": "2024-04-04T22:08:18.639334Z",
     "shell.execute_reply": "2024-04-04T22:08:18.638457Z",
     "shell.execute_reply.started": "2024-04-04T22:08:09.882996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/inaki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import BertTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/inaki/host_data')\n",
    "import models\n",
    "from utils import train_loop, evaluate, evaluate_kfold_ensemble\n",
    "from CreateDataset import BertDataset, RobertaDataset, createAuxSubmissionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"base_url\": \"/\",\n",
      "  \"hostname\": \"0.0.0.0\",\n",
      "  \"password\": false,\n",
      "  \"pid\": 1,\n",
      "  \"port\": 8888,\n",
      "  \"root_dir\": \"/home/inaki\",\n",
      "  \"secure\": false,\n",
      "  \"sock\": \"\",\n",
      "  \"token\": \"0fdb3c6a295628a703438890d46493f84fc307986b80d033\",\n",
      "  \"url\": \"http://8b0f407a9717:8888/\",\n",
      "  \"version\": \"2.14.0\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.local/share/jupyter/runtime/jpserver-1.json\n",
    "# http://g4.etsisi.upm.es:8898/?token=e46f49d093b44c3ab8dd1a901c171431c14e5c7781923de0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 30 15:38:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   43C    P8              21W / 370W |      1MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   45C    P8              32W / 370W |      1MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T22:08:18.659675Z",
     "iopub.status.busy": "2024-04-04T22:08:18.659387Z",
     "iopub.status.idle": "2024-04-04T22:08:18.666414Z",
     "shell.execute_reply": "2024-04-04T22:08:18.665390Z",
     "shell.execute_reply.started": "2024-04-04T22:08:18.659643Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "#                Ideas                 #\n",
    "########################################\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "    # Otros metodos \n",
    "        # Easy methods\n",
    "        #     Synonym Replacement  |  Random synonym Insertion   |   Random Swap   |    Random Deletion\n",
    "        # Albumentation (libreria)\n",
    "        # Libreria para muchos de estos métodos  -  NLPAug \n",
    "        \n",
    "\n",
    "    # Aumentado sobre embedding\n",
    "        # Añadir ruido gaussiano\n",
    "        # Ruido adversial\n",
    "        # MixUp  (mezclar embedding y su label en la proporcion dada por una funcion)\n",
    "        \n",
    "    # Consistency regularization ??\n",
    "    \n",
    "\n",
    "# TO DO tutorias\n",
    "    # mirar textos errores\n",
    "\n",
    "    # LoRa  (Low rank adaptation)      -    https://medium.com/@karkar.nizar/fine-tuning-bert-for-text-classification-with-lora-f12af7fa95e4\n",
    "\n",
    "    # Probar Con modelos que ven masyusculas bert-base-cased y bert-large-cased\n",
    "\n",
    "    # Within-task and in-domain further pre-training can significantly boost its performance\n",
    "    \n",
    "    # Seleccionar los mejores en validation y hacer un ensemble con ellos y evaluar test (sobre enfoque baseline)\n",
    "\n",
    "    # k-fold contrastive\n",
    "\n",
    "    # Remplazo de sinonimos\n",
    "    \n",
    "    # Tecnicas basicas de data aumentacion\n",
    "        # Round Trip transltion (quizas guardar las traducciones)\n",
    "        # Ruido gaussiano\n",
    "\n",
    "    # Volver a probar aumentado de datos con llama3\n",
    "        \n",
    "    # Probar CLS en vez de Mean Pooling ?\n",
    "\n",
    "\n",
    "# Probar otros modelos\n",
    "    # XLNet\n",
    "    # RoBERTa\n",
    "    # Roberta covid    -   https://huggingface.co/sagteam/covid-twitter-xlm-roberta-large\n",
    "    # DeBERTa\n",
    "\n",
    "\n",
    "# ----------\n",
    "    # Analizar matriz de confusion sobre baseline\n",
    "    # Bert ajustado para mensajes de redes sociales (telegram)\n",
    "    # investigar Equilibrado transformers\n",
    "    \n",
    "# Recently DONE\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# DONE\n",
    "    # implementar MixUp\n",
    "    # Probar MixUp\n",
    "\n",
    "    # Contrastive Loss\n",
    "        # Implementar yo el contrastive learning.  Probar con vectores muy sencillos a mano. revisar detach. cambiar a torch.\n",
    "        # Dividir entre numero de elementos en el batch ??\n",
    "        # Revisar formula paper y mirar mi codigo\n",
    "        # Ir aplicando a modo de prueba todos los pasos con un batch de vectores muy sencillos.\n",
    "        # Añado SWAP. SCL en dos fases, primero solo con contrastive loss y luego con BCE\n",
    "\n",
    "    # Añadir model.eval() en evaluate para que el dropout funcione adecuadamente en test\n",
    "    # devolver los logits y no la prediccion (y cambiar el BCE por el de logits)\n",
    "    # Añadir capa densa entre el bert y las neuronas de clasificacion\n",
    "\n",
    "\n",
    "\n",
    "    # Investigar *Supervised Contrastive learning \n",
    "    # Traduir dataset español y probar\n",
    "    # Aumentado de datos con llama3 \n",
    "\n",
    "    # Guardar modelos para probar forma de ensembles\n",
    "    # Baseline 10 folds sobre test, para tener 10 test como al probar 10 ensembles\n",
    "    # Plotear distribucion de errores\n",
    "    # implementar Predicciones 0, 1 o no lo se\n",
    "    # Matriz de confusion\n",
    "    # probar los k modelos sobre test\n",
    "    # Guardar ultimo epoch de validacion, quitar MCC cada epoch, gaurdar media y desviacion del ultimo\n",
    "    # Mirar si tiene emojis y traducirlos a texto (emojify)\n",
    "\n",
    "    #  ¿¿¿ #os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\" ???\n",
    "       # ERROR  # torch.use_deterministic_algorithms(True)  \n",
    "    # guardar los resultados weight and bias o ML flow\n",
    "    # Intentar guardar el MCC de cada fold para poder sacar desviaciones\n",
    "    # Guardar semilas.  La semilla es para que los datos sean los mismos.\n",
    "    # MCC  poner etiquetas a 1 y 2  ¿¿¿ seguro ???\n",
    "    # Arreglar docker\n",
    "    # sacar 10% de datos del dataset como sanity-check \n",
    "    # split stratify   (sklearn viene)\n",
    "    # cross validation (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:02:56.153864Z",
     "iopub.status.busy": "2024-04-04T23:02:56.152955Z",
     "iopub.status.idle": "2024-04-04T23:02:56.159239Z",
     "shell.execute_reply": "2024-04-04T23:02:56.158120Z",
     "shell.execute_reply.started": "2024-04-04T23:02:56.153830Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#       configuración         #\n",
    "###############################\n",
    "#  RobertaLargePooledOutput  #  BertLargeCovidPooledOutput  #  BertBasePooledOutput #BertLargeCovidMixupPooledOutput\n",
    "MODEL_NAME = \"BertLargeCovidPooledOutput\"  \n",
    "EVALUATE_FREQ = 'END' # 'EVERY_EPOCH' #  'END'\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "HEAD_DROPOUT = 0.0\n",
    "FOLDS_NUM = 5\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "LOSS_FN =  'cross_entropy' # 'cross_entropy' # 'supervised_contrastive' #  'MixUp'  # 'MixUp_SCL'\n",
    "\n",
    "# Data augmentation\n",
    "\n",
    "DATA_AUGMENTATION = [] #  \"Oversampling\"   #  '_es_into_en'  #  'llama_aug'  #  'WR'   #   'BT'\n",
    "\n",
    "WR_percentage = 0.1\n",
    "SR_percentage = 0.2\n",
    "RI_percentage = 0.1\n",
    "\n",
    "# SCL\n",
    "temperature = 0.3  # temprature for contrastive loss\n",
    "lam = 1  # lambda for loss\n",
    "SWAP = 2\n",
    "DECAY = 0\n",
    "\n",
    "# MixUp\n",
    "ALFA = 0.2\n",
    "\n",
    "# Selección de modelos\n",
    "SELECTION = 0.2\n",
    "\n",
    "\n",
    "checkoint_folder = 'Ensemble_baseline'\n",
    "\n",
    "datadir = \"/home/inaki/host_data/dataset_oppositional/\"\n",
    "cuda_device = 0\n",
    "wandb_project = 'Ensemble_baseline'    # 'BASELINE'  'Ensemble_baseline'  'trash'  'epoch_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:02:58.460893Z",
     "iopub.status.busy": "2024-04-04T23:02:58.460599Z",
     "iopub.status.idle": "2024-04-04T23:02:59.150899Z",
     "shell.execute_reply": "2024-04-04T23:02:59.149887Z",
     "shell.execute_reply.started": "2024-04-04T23:02:58.460871Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datasets de entrenamiento y test\n",
    "train_en_dataset_path = datadir + \"train_en_data.pth\"\n",
    "test_en_dataset_path = datadir + \"test_en_data.pth\"\n",
    "train_es_dataset_path = datadir + \"train_es_data.pth\"\n",
    "test_es_dataset_path = datadir + \"test_es_data.pth\"\n",
    "\n",
    "# Dataset traducido por llama3 8B\n",
    "train_es_translated_path = datadir + \"train_es_translated_data.pth\"\n",
    "\n",
    "# creamos los datasets de test\n",
    "X, y = torch.load(test_es_dataset_path)\n",
    "test_es_dataset = BertDataset(X, y)\n",
    "X, y = torch.load(test_en_dataset_path)\n",
    "test_en_dataset = BertDataset(X, y)\n",
    "\n",
    "#Creamos dataloader de test\n",
    "test_en_dataloader = DataLoader(test_en_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dataset final para la submission\n",
    "unalbeled_test_en_dataset_path = '/home/inaki/host_data/dataset_oppositional/dataset_en_official_test_nolabels.json'\n",
    "\n",
    "test_unlabelled_dataset = createAuxSubmissionDataset(unalbeled_test_en_dataset_path)\n",
    "\n",
    "test_unlabelled_dataloader = DataLoader(test_unlabelled_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T23:11:26.540949Z",
     "iopub.status.busy": "2024-04-04T23:11:26.540570Z",
     "iopub.status.idle": "2024-04-04T23:11:29.224028Z",
     "shell.execute_reply": "2024-04-04T23:11:29.222265Z",
     "shell.execute_reply.started": "2024-04-04T23:11:26.540917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33minakitodc\u001b[0m (\u001b[33minaki\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/inaki/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimento 0:\n",
      "seed: 2211\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/inaki/wandb/run-20240530_115343-ug3vw8nz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/inaki/Ensemble_baseline/runs/ug3vw8nz' target=\"_blank\">peach-paper-1013</a></strong> to <a href='https://wandb.ai/inaki/Ensemble_baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/inaki/Ensemble_baseline' target=\"_blank\">https://wandb.ai/inaki/Ensemble_baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/inaki/Ensemble_baseline/runs/ug3vw8nz' target=\"_blank\">https://wandb.ai/inaki/Ensemble_baseline/runs/ug3vw8nz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: 335142913 trainble params: 335142913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/225 [00:02<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(optimizer, num_warmup_steps\u001b[38;5;241m=\u001b[39mwarmup_steps, num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_en_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_en_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDECAY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOSS_FN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSWAP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mALFA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEVALUATE_FREQ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m pred, test_mcc \u001b[38;5;241m=\u001b[39m evaluate(model, test_en_dataloader, \u001b[38;5;241m0.5\u001b[39m, device, LOSS_FN, val_or_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/host_data/utils.py:39\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_dataloader, test_en_dataloader, positive, negative, optimizer, scheduler, NUM_EPOCHS, tem, lam, decay, loss_fn, device, swap, alfa, evaluate_freq)\u001b[0m\n\u001b[1;32m     36\u001b[0m     embeddings, logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(input_ids, attention_mask, mixup_input_ids, mixup_attention_masks, beta\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     embeddings, logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m BCE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss() \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/host_data/models.py:41\u001b[0m, in \u001b[0;36mBertLargeCovidPooledOutput.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     43\u001b[0m     pooled_output_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    979\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    981\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    982\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    983\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    986\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    987\u001b[0m )\n\u001b[0;32m--> 988\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1000\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    572\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    573\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         output_attentions,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    462\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    394\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:330\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1855\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m-> 1855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a softmax function.\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \n\u001b[1;32m   1858\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1878\u001b[0m \n\u001b[1;32m   1879\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#     Weigths and bias Login    #\n",
    "##################################\n",
    "# MY API KEY\n",
    "#    240062b42b3367d962eecb38802f856b41245735\n",
    "wandb.login(key=\"240062b42b3367d962eecb38802f856b41245735\")\n",
    "\n",
    "k_test_outputs = []\n",
    "\n",
    "for i in range(25):\n",
    "    print(f\"experimento {i}:\")\n",
    "    #####################\n",
    "    #  Reproducibilidad #\n",
    "    #####################\n",
    "    SEED = random.randint(0,10000)\n",
    "    print(f\"seed: {SEED}\")\n",
    "    # fuente  -  https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    X, y = torch.load(train_en_dataset_path)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "        \n",
    "    # Weigths and bias init\n",
    "    config = {\n",
    "    \"MAX_LENGTH\": MAX_LENGTH,\n",
    "    \"HEAD_DROPOUT\": HEAD_DROPOUT,\n",
    "    \"DATA_AUGMENTATION\": DATA_AUGMENTATION,\n",
    "    \"FOLDS_NUM\": FOLDS_NUM,\n",
    "    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"FOLD_IDX\": None,\n",
    "    \"DATA_AUGMENTATION\": DATA_AUGMENTATION,\n",
    "    \"LOSS_FN\": LOSS_FN,\n",
    "    \"SEED\": SEED\n",
    "    }\n",
    "    GROUP = f\"Final_model_{MODEL_NAME}_{HEAD_DROPOUT}_{BATCH_SIZE}_{LEARNING_RATE}_{DATA_AUGMENTATION}_{LOSS_FN}\"\n",
    "    \n",
    "\n",
    "    wandb.init(project=wandb_project, group=GROUP, config=config)\n",
    "\n",
    "    device = torch.device(f\"cuda:{cuda_device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    # Creo los datasets de entrenamiento y validación.\n",
    "    train_en_dataset = BertDataset(X, y, DATA_AUGMENTATION=DATA_AUGMENTATION, WR_percentage=WR_percentage, \n",
    "                                       SR_percentage=SR_percentage, RI_percentage=RI_percentage, device=device)\n",
    "    \n",
    "    train_en_dataloader = DataLoader(train_en_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Instanciamos el modelo cuya clase viene dada por la variable MODEL_NAME\n",
    "    # Obtén la referencia a la clase del módulo models\n",
    "    ModelClass = getattr(models, MODEL_NAME)\n",
    "    model = ModelClass(dropout_prob=HEAD_DROPOUT)\n",
    "    model.to(device)\n",
    "\n",
    "        \n",
    "    # Paralelizamos el modelo si hay mas de una GPU\n",
    "    if torch.cuda.device_count() > 2:\n",
    "        model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "        model.to(device)\n",
    "        #print(model.module.mixup_forward)\n",
    "          \n",
    "    # Activamos todas las capas\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # Contmaos los parametros entrenables\n",
    "    print(f\"total params: {sum(p.numel() for p in model.parameters())} trainble params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "        \n",
    "\n",
    "    # Define your optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "    # Define your learning rate scheduler\n",
    "    total_steps = len(train_en_dataloader) * NUM_EPOCHS\n",
    "    warmup_steps = int(total_steps * 0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "    # Train the model\n",
    "    train_loop(model, train_en_dataloader, test_en_dataloader, None, None, optimizer, scheduler, NUM_EPOCHS, temperature, lam, DECAY, LOSS_FN, device, SWAP, ALFA, EVALUATE_FREQ)\n",
    "\n",
    "    # Evaluate the model\n",
    "    pred, test_mcc = evaluate(model, test_en_dataloader, 0.5, device, LOSS_FN, val_or_test=\"Test\")\n",
    "    k_test_outputs += [pred]\n",
    "        \n",
    "        # Save the model\n",
    "    torch.save(model.state_dict(), f\"/home/inaki/host_data/checkpoints/{checkoint_folder}/{GROUP}_exp-{i}_test-MCC_{test_mcc}.pth\")\n",
    "\n",
    "evaluate_kfold_ensemble(k_test_outputs, test_en_dataloader)\n",
    "        \n",
    "# bB - Finalizamos el experimento\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertLargeCovidPooledOutput_0.0_8_2e-05_['WR']_cross_entropy_WR-0.1_exp-1_fold_0_Val-MCC_0.8180610657070114.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6742', '10596', '482', '1613', '10549', '1221', '11477', '3394', '12195', '7674', '11270', '1548', '77', '4720', '78', '12237', '363', '4373', '3698', '4027', '339', '10050', '11344', '10019', '11421', '10110', '3677', '74', '103', '4371', '3771', '4947', '287', '10042', '12430', '105', '933', '12210', '11535', '727', '3532', '12165', '1252', '13131', '5095', '6544', '13081', '10807', '4173', '1992', '5130', '10531', '3602', '10960', '1418', '184', '6679', '13059', '13099', '10277', '182', '3732', '484', '3876', '12329', '4703', '10515', '206', '11187', '5008', '6307', '10492', '3562', '14042', '1634', '11267', '10467', '13079', '3347', '10251', '6667', '6713', '10709', '10335', '3469', '244', '3590', '1820', '5039', '6602', '3165', '6700', '11412', '1632', '4597', '10794', '11078', '4663', '2024', '1138', '2012', '858', '6653', '3432', '12341', '5132', '472', '5099', '11274', '3509', '3445', '12074', '3408', '5078', '4508', '12338', '13206', '1239', '6597', '10877', '12382', '11456', '1589', '4955', '3851', '3676', '10347', '10394', '10146', '4750', '4620', '350', '1211', '13225', '3630', '12114', '10333', '690', '241', '12089', '10186', '4052', '12026', '460', '13006', '10583', '3959', '3565', '12306', '4952', '10487', '1806', '4056', '485', '12301', '4180', '488', '5027', '13186', '4604', '12078', '10364', '4452', '11321', '10319', '10452', '12231', '776', '11205', '11226', '10694', '10625', '6311', '13043', '11423', '237', '1621', '247', '4828', '12130', '4203', '5031', '2018', '3679', '12279', '13177', '4557', '1975', '1216', '4499', '2074', '1695', '6309', '256', '12337', '10977', '10162', '10672', '5006', '12168', '10833', '12282', '10092', '3433', '11170', '13220', '10816', '494', '1617', '1247', '10848', '293', '12263', '10053', '10312', '12157', '11372', '11027', '3952', '1439', '11481', '12108', '13054', '3583', '3371', '3994', '11461', '6548', '11303', '4738', '3680', '38', '2028', '67', '4389', '62', '3942', '4984', '10915', '3784', '11522', '1605', '3636', '2087', '2041', '11393', '10070', '1095', '1', '66', '11030', '1461', '3293', '10887', '12120', '3902', '10285', '894', '11174', '1887', '4810', '12321', '5173', '4858', '11005', '10859', '10523', '6506', '10527', '10442', '1646', '10811', '740', '3351', '3451', '10506', '208', '13243', '7629', '10377', '139', '414', '978', '7599', '1818', '474', '12071', '12381', '280', '10222', '12443', '4219', '12372', '4442', '10918', '4231', '2013', '13000', '11272', '3756', '1652', '464', '221', '4161', '11526', '6721', '12303', '3496', '2086', '10800', '14046', '10904', '12088', '12153', '4733', '4096', '10127', '4257', '11253', '13070', '202', '4926', '4578', '4736', '12260', '3874', '4170', '156', '1812', '14', '10736', '3923', '1781', '6654', '2047', '1690', '11465', '10665', '11108', '1127', '441', '2098', '12412', '3660', '11188', '11566', '10115', '6267', '4989', '2039', '4853', '10301', '13010', '10034', '3861', '12434', '5131', '1772', '10875', '4531', '3915', '10357', '1092', '4379', '4585', '11060', '3522', '6305', '10236', '4826', '11486', '5134', '11254', '3169', '3781', '2081', '1596', '1830', '6405', '10613', '6704', '94', '10993', '14038', '10755', '1725', '3571', '5129', '11038', '1684', '5207', '12152', '13133', '10338', '2096', '4502', '3436', '12125', '3266', '10405', '10769', '3506', '2055', '7634', '13015', '12319', '1445', '4295', '323', '6716', '12370', '3425', '308', '4857', '4340', '6610', '1610', '3920', '4074', '4376', '12311', '6660', '3793', '1651', '11403', '13147', '11144', '3336', '4901', '5029', '744', '11442', '12179', '10328', '12428', '10007', '4520', '3439', '11417', '2016', '6172', '10632', '972', '3459', '10860', '4902', '12265', '10562', '11068', '3449', '1437', '4326', '10076', '2093', '1888', '5070', '810', '12017', '4521', '6585', '10818', '4801', '1706', '3153', '11542', '684', '4176', '6748', '5076', '5097', '4962', '6648', '10770', '10792', '12414', '4291', '6680', '1099', '11352', '10219', '3638', '11149', '4421', '3896', '665', '11115', '3625', '11083', '10355', '12027', '10942', '5202', '5136', '10068', '4921', '4628', '4786', '11184', '10950', '4418', '13007', '1841', '10609', '4887', '365', '397', '1624', '12400', '10191', '11554', '4041', '11299', '4964', '149', '4515', '3696', '6744', '12436', '12373', '1615', '3889', '10345', '3611', '13066', '13034', '346', '3655', '12462', '4658', '92', '10815', '4244', '4474', '4409', '1839', '4329', '11152', '3666', '10618', '4146', '10314', '370', '4481', '4749', '3857', '12185', '1124', '5168', '11018', '11134', '3808', '3782', '3271', '5033', '3758', '4878', '4478', '3440', '12416', '10151', '11532', '5166', '4742', '1273', '218', '57', '10696', '10961', '3642', '13199', '167', '10205', '3343', '11462', '4731', '13228', '12342', '11430', '13194', '302', '3159', '10966', '4251', '3424', '4230', '6692', '3877', '1109', '11548', '4934', '4378', '12075', '3922', '1822', '13018', '4121', '306', '1686', '42', '10396', '5101', '12391', '10457', '3749', '292', '4820', '4044', '12449', '10646', '12107', '12357', '13024', '1408', '6392', '11199', '10708', '6594', '12444', '1642', '12215', '3217', '4997', '866', '4087', '4875', '1446', '1122', '768', '10367', '12087', '4399', '12047', '791', '4454', '12446', '3854', '6657', '11483', '3362', '4238', '166', '999', '4235', '3254', '3261', '11256', '10072', '3481', '772', '1774', '10751', '12066', '3690', '1910', '3826', '1094', '12095', '3482', '11087', '4868', '4560', '6629', '4609', '1661', '1620', '732', '12322', '3519', '5012', '70', '10211', '1663', '3747', '6605', '11128', '4538', '736', '10257', '204', '10985', '1593', '11497', '3302', '3596', '11259', '10488', '13144', '10315', '767', '1689', '12285', '11119', '10700', '6576', '4001', '13128', '4716', '6646', '13044', '214', '3825', '11015', '10802', '3714', '12363', '4213', '6549', '1098', '10051', '10926', '4540', '63', '10451', '26', '12250', '3664', '2049', '10358', '3616', '10654', '4522', '10578', '3348', '3810', '10866', '1843', '12192', '11160', '10988', '10881', '12206', '10997', '12290', '6666', '10529', '967', '3985', '5088', '5024', '788', '4747', '3423', '4547', '10706', '6612', '72', '12340', '4652', '10965', '12015', '13142', '3245', '4833', '3965', '194', '14033', '11467', '4937', '4331', '12046', '10611', '6592', '905', '6705', '5106', '661', '13188', '935', '770', '11076', '4210', '737', '4599', '10267', '1131', '1308', '11139', '10663', '73', '11531', '10052', '3211', '14039', '12080', '1737', '1709', '11309', '3622', '3726', '4026', '14029', '3328', '11484', '11368', '10747', '328', '5164', '475', '243', '3200', '140', '2056', '3988', '1760', '13246', '6580', '173', '4595', '12151', '5016', '24', '468', '11432', '4078', '12028', '309', '150', '3623', '13106', '6541', '1758', '4051', '10055', '6574', '71', '1664', '12347', '6635', '2065', '11287', '4920', '3993', '4526', '11558', '10262', '277', '307', '3470', '126', '679', '4350', '4890', '10063', '765', '4600', '161', '1611', '13223', '10359', '3821', '11392', '12202', '4128', '1640', '12367', '6728', '10715', '3494', '13028', '11429', '6529', '10429', '4654', '10513', '3594', '10446', '4766', '1317', '1792', '11037', '4927', '1672', '11300', '3730', '3335', '4131', '911', '4722', '189', '12258', '13239', '4951', '4413', '4789', '12266', '4069', '4642', '10435', '10460', '13237', '11153', '13012', '4685', '10838', '7611', '311', '6532', '4669', '13086', '4337', '1226', '2080', '6511', '10081', '6593', '1995', '1691', '1111', '11373', '5090', '12042', '10105', '6674', '3822', '5200', '4484', '4205', '5110', '936', '3393', '10167', '1779', '13205', '3235', '13072', '10631', '12223', '4473', '10221', '13009', '11516', '12201', '12317', '10188', '10041', '13155', '10841', '6609', '1126', '5127', '5178', '1399', '10489', '753', '11064', '10158', '187', '220', '11337', '276', '10241', '10397', '10607', '4380', '3925', '10341', '10374', '369', '10779', '348', '10994', '4080', '7627', '10204', '4895', '6598', '11478', '12102', '6518', '10707', '4462', '3430', '13122', '5177', '6176', '10710', '14010', '12344', '10321', '10731', '314', '801', '4363', '4366', '6709', '186', '4167', '55', '12181', '4589', '5146', '14048', '4263', '4776', '4269', '1314', '4153', '10197', '12099', '10705']\n",
      "[0.9959329962730408, 0.7470395565032959, 0.009126952849328518, 0.012118696235120296, 0.13332799077033997, 0.9958639144897461, 0.005327255465090275, 0.9945839047431946, 0.0007138810469768941, 0.015931811183691025, 0.5722882747650146, 0.9887844324111938, 0.995377779006958, 0.001744083478115499, 0.9953706860542297, 0.004482148215174675, 0.0008925840957090259, 0.001774866133928299, 0.08138298988342285, 0.9786689281463623, 0.002008317969739437, 0.01073909830302, 0.8874841928482056, 0.0007074882159940898, 0.0012356037041172385, 0.41087329387664795, 0.062094829976558685, 0.9952823519706726, 0.9960741996765137, 0.0008188736974261701, 0.39449915289878845, 0.9931215643882751, 0.8095784783363342, 0.0012615331215783954, 0.0014308139216154814, 0.995460569858551, 0.9961763620376587, 0.0007584582781419158, 0.008631592616438866, 0.9892465472221375, 0.0007392988190986216, 0.001163015142083168, 0.9955530762672424, 0.9943795800209045, 0.0016056738095358014, 0.9939135909080505, 0.9951030015945435, 0.0011086667655035853, 0.39104148745536804, 0.9059621691703796, 0.0008301735506393015, 0.0007082566153258085, 0.000867856084369123, 0.9956502318382263, 0.07766575366258621, 0.9955272078514099, 0.9965366125106812, 0.014750724658370018, 0.7714205980300903, 0.1272992640733719, 0.02247127890586853, 0.035732515156269073, 0.0011898578377440572, 0.995705783367157, 0.001748547307215631, 0.001428323215804994, 0.0009400330600328743, 0.43593689799308777, 0.9962794184684753, 0.0009475608821958303, 0.0015113679692149162, 0.9206605553627014, 0.0005009424057789147, 0.9505824446678162, 0.9844229817390442, 0.9627257585525513, 0.9720383286476135, 0.9856808185577393, 0.0007532236631959677, 0.004810519516468048, 0.9941324591636658, 0.9956276416778564, 0.0019034332362934947, 0.6358254551887512, 0.0006618979969061911, 0.6925238966941833, 0.0006826791795901954, 0.0008237188449129462, 0.001901396200992167, 0.9918398857116699, 0.0005084614967927337, 0.9715703129768372, 0.0038529138546437025, 0.002807042794302106, 0.001280686934478581, 0.9948710203170776, 0.9928642511367798, 0.0012452590744942427, 0.9818609952926636, 0.9961472749710083, 0.0020052827894687653, 0.994745135307312, 0.9949254989624023, 0.0006774708162993193, 0.0007798185688443482, 0.0010129614965990186, 0.002473657252267003, 0.002578915096819401, 0.0037428149953484535, 0.002167327795177698, 0.0009538838057778776, 0.0007652320782653987, 0.7104429602622986, 0.893008291721344, 0.0017453748732805252, 0.0024635775480419397, 0.0015805283328518271, 0.993898868560791, 0.9950586557388306, 0.0007171428296715021, 0.006620142143219709, 0.0013307082699611783, 0.004114863928407431, 0.0008582399459555745, 0.0028625912964344025, 0.8453972339630127, 0.0009100079769268632, 0.0016036730958148837, 0.005794018507003784, 0.000994600122794509, 0.0006648200796917081, 0.0011168564669787884, 0.011017752811312675, 0.004810784477740526, 0.0004412062407936901, 0.0005762019427493215, 0.0008688514935784042, 0.009123736061155796, 0.9955641031265259, 0.0011070847976952791, 0.0028988351114094257, 0.019449381157755852, 0.004224799573421478, 0.001342478091828525, 0.9958779811859131, 0.9955142140388489, 0.007272909861057997, 0.7910825610160828, 0.0009866382461041212, 0.012011396698653698, 0.00045851912000216544, 0.0008698749006725848, 0.01311588753014803, 0.0011769369011744857, 0.0009876916883513331, 0.9844227433204651, 0.0007316358387470245, 0.0016789919463917613, 0.0027941653970628977, 0.0008824360556900501, 0.002676385687664151, 0.0008433673065155745, 0.002830274635925889, 0.8529226183891296, 0.35699692368507385, 0.336601197719574, 0.001149411196820438, 0.8927158713340759, 0.9944047927856445, 0.0022244839929044247, 0.9571713805198669, 0.0020461573731154203, 0.9908768534660339, 0.0012342846021056175, 0.9956969022750854, 0.9800357222557068, 0.9932668209075928, 0.9847575426101685, 0.0658276304602623, 0.9961411356925964, 0.0017774039879441261, 0.0012634571176022291, 0.007854952476918697, 0.4684736430644989, 0.0015709245344623923, 0.0021681366488337517, 0.0005964052979834378, 0.8859900832176208, 0.04079689085483551, 0.0011504216818138957, 0.8610609173774719, 0.0006615706952288747, 0.9856250882148743, 0.002382953418418765, 0.001983445370569825, 0.9936125874519348, 0.8814874887466431, 0.9723281264305115, 0.0015816650120541453, 0.35448071360588074, 0.9875137209892273, 0.0007650541956536472, 0.9958321452140808, 0.0006957835867069662, 0.9911144971847534, 0.9961840510368347, 0.0984337255358696, 0.0012508841464295983, 0.0008371741278097034, 0.9960668683052063, 0.01972612924873829, 0.0006519746966660023, 0.000540020118933171, 0.0011362213408574462, 0.0016388826770707965, 0.9812822341918945, 0.9954380393028259, 0.0007834156858734787, 0.04714673012495041, 0.0018366543808951974, 0.0013126569101586938, 0.006839163601398468, 0.9952582716941833, 0.0005061927950009704, 0.0007840829784981906, 0.002136901253834367, 0.0008353453013114631, 0.9959549903869629, 0.9965372085571289, 0.9934380650520325, 0.05739725008606911, 0.001631961204111576, 0.9923813939094543, 0.9959267377853394, 0.001953565515577793, 0.9956156015396118, 0.004515668377280235, 0.0012024660827592015, 0.0008104309672489762, 0.9958553910255432, 0.000890670926310122, 0.0006485676276497543, 0.0007362573524005711, 0.9733778238296509, 0.9952532052993774, 0.0010386711219325662, 0.8593162298202515, 0.982258677482605, 0.9957410097122192, 0.0013617415679618716, 0.9962853193283081, 0.0020270023960620165, 0.04406624287366867, 0.0025741311255842447, 0.0007329554646275938, 0.011439619585871696, 0.000973366666585207, 0.9918038845062256, 0.6612890958786011, 0.001068904297426343, 0.004140131175518036, 0.9940789937973022, 0.002690497087314725, 0.9952706694602966, 0.009519566781818867, 0.007367833983153105, 0.0018012369982898235, 0.9926013350486755, 0.0009454753017053008, 0.0008617308340035379, 0.001995309954509139, 0.0006776148220524192, 0.9854133725166321, 0.001055723405443132, 0.0010139370569959283, 0.0007865670486353338, 0.000625362794380635, 0.003866377752274275, 0.9952754974365234, 0.0015956797869876027, 0.0017721477197483182, 0.9781088829040527, 0.9961658716201782, 0.033009111881256104, 0.0010901364730671048, 0.0008227735524997115, 0.0010845167562365532, 0.0008094180375337601, 0.0010061762295663357, 0.0017667488427832723, 0.001636700239032507, 0.0015218134503811598, 0.001304148812778294, 0.0006824316806159914, 0.9915406107902527, 0.001073733321391046, 0.0008841331000439823, 0.0010132654570043087, 0.2909981608390808, 0.08972227573394775, 0.9625015258789062, 0.0019558335188776255, 0.004837060812860727, 0.9895772933959961, 0.0009206517715938389, 0.9947011470794678, 0.0012660964857786894, 0.44484981894493103, 0.9940714240074158, 0.0030657534953206778, 0.0007881855126470327, 0.0018130635144189, 0.0017596185207366943, 0.9772741794586182, 0.9209904670715332, 0.0016668885946273804, 0.9957482218742371, 0.005158714950084686, 0.8106744885444641, 0.9944661259651184, 0.036247190088033676, 0.13605010509490967, 0.0021037664264440536, 0.001334599801339209, 0.0018418562831357121, 0.01125660166144371, 0.02145126461982727, 0.0020482847467064857, 0.0017046005232259631, 0.8537859320640564, 0.0015986558282747865, 0.004656117409467697, 0.9955417513847351, 0.9902353882789612, 0.9939239621162415, 0.0036333308089524508, 0.0011944700963795185, 0.0020195981487631798, 0.013332127593457699, 0.9956768155097961, 0.012344934977591038, 0.0007833850686438382, 0.008597711101174355, 0.993994414806366, 0.9131900668144226, 0.001776169054210186, 0.0014628299977630377, 0.9870867729187012, 0.0017459639348089695, 0.870290219783783, 0.39533713459968567, 0.0015882326988503337, 0.009410491213202477, 0.0023757005110383034, 0.0038497692439705133, 0.8297630548477173, 0.0008096742094494402, 0.0008064985158853233, 0.995897650718689, 0.0009297020733356476, 0.6068189144134521, 0.001407226431183517, 0.9954968690872192, 0.0012630161363631487, 0.0018028238555416465, 0.9964424967765808, 0.8061763048171997, 0.9926980137825012, 0.9958556294441223, 0.37543532252311707, 0.0011676974827423692, 0.0011421497911214828, 0.018485626205801964, 0.0009356848313473165, 0.8313952088356018, 0.6778896450996399, 0.027682198211550713, 0.0016020203474909067, 0.99671870470047, 0.0006968380184844136, 0.9944446682929993, 0.09248744696378708, 0.0005860125529579818, 0.9562908411026001, 0.9536314010620117, 0.0011030633468180895, 0.001467599067837, 0.003180848667398095, 0.004919052589684725, 0.12464195489883423, 0.002944118110463023, 0.08212406188249588, 0.001001791562885046, 0.0007813955307938159, 0.9665697813034058, 0.0008845684351399541, 0.0009421203285455704, 0.0007692434592172503, 0.0021326786372810602, 0.001241994323208928, 0.054569438099861145, 0.0010551573941484094, 0.9879053831100464, 0.01310095377266407, 0.0031374755781143904, 0.0009095727582462132, 0.9934563040733337, 0.001988446107134223, 0.033871058374643326, 0.9910378456115723, 0.9527689814567566, 0.9947077035903931, 0.005332984495908022, 0.9602491855621338, 0.0008522109128534794, 0.993759036064148, 0.0018507209606468678, 0.012979112565517426, 0.0022386303171515465, 0.0015438866103067994, 0.001042000250890851, 0.9904921650886536, 0.9883042573928833, 0.0019543624948710203, 0.0009200864587910473, 0.0007672719657421112, 0.0010867128148674965, 0.9955820441246033, 0.0345650389790535, 0.006831465754657984, 0.9961153268814087, 0.058892592787742615, 0.0007521014777012169, 0.003045200603082776, 0.8196583986282349, 0.001102698384784162, 0.0008546810713596642, 0.0005903566488996148, 0.0012323069386184216, 0.006089675240218639, 0.004219355061650276, 0.9954558610916138, 0.05220773071050644, 0.0009674416505731642, 0.0030659763142466545, 0.004025002475827932, 0.0025052486453205347, 0.05530581995844841, 0.9946670532226562, 0.0013415892608463764, 0.0012129753595218062, 0.0010368747171014547, 0.0037477235309779644, 0.9091201424598694, 0.001599842100404203, 0.0007579784723930061, 0.988194465637207, 0.9877992868423462, 0.00103579752612859, 0.9916067123413086, 0.0014790474670007825, 0.0018158556194975972, 0.0048778727650642395, 0.9547246694564819, 0.001028998289257288, 0.9969156980514526, 0.0009330741595476866, 0.9956235289573669, 0.0019777975976467133, 0.002276419661939144, 0.001064635580405593, 0.9932686686515808, 0.03035997599363327, 0.000507496704813093, 0.000893068965524435, 0.0018717758357524872, 0.9956827163696289, 0.9949518442153931, 0.9949221014976501, 0.004789772443473339, 0.0014879927039146423, 0.0009613664005883038, 0.0023101302795112133, 0.0027877846732735634, 0.00072814233135432, 0.0018384902505204082, 0.0010847171070054173, 0.996189534664154, 0.0009331817273050547, 0.008333779871463776, 0.005464439280331135, 0.0014063309645280242, 0.0007903263904154301, 0.0006147042149677873, 0.0018557044677436352, 0.0032642721198499203, 0.0014214186230674386, 0.6178305149078369, 0.9944409728050232, 0.00233570602722466, 0.9948012828826904, 0.0032245113980025053, 0.948968768119812, 0.002574903890490532, 0.00628970842808485, 0.9954923391342163, 0.004255007021129131, 0.0011525183217599988, 0.0014648903161287308, 0.0009201382636092603, 0.021310316398739815, 0.9959734082221985, 0.9828153252601624, 0.6775791049003601, 0.0014100275002419949, 0.09832857549190521, 0.9948607087135315, 0.011111188679933548, 0.0011505454313009977, 0.0028751816134899855, 0.6184252500534058, 0.0008686279761604965, 0.0006312100449576974, 0.9834647178649902, 0.0019378444412723184, 0.08956310898065567, 0.0006784541765227914, 0.004267500713467598, 0.002962303115054965, 0.0007374088745564222, 0.027078930288553238, 0.0038632990326732397, 0.0012506494531407952, 0.0020960932597517967, 0.0036431006155908108, 0.0005125468014739454, 0.9948164820671082, 0.0013135067420080304, 0.0016420752508565784, 0.004937971010804176, 0.000990992528386414, 0.34288740158081055, 0.0013821463799104095, 0.0008078839164227247, 0.006603104993700981, 0.0017495404463261366, 0.9953420162200928, 0.00567530607804656, 0.6335631608963013, 0.9952762126922607, 0.9559595584869385, 0.08350495994091034, 0.0012595412554219365, 0.0025255854707211256, 0.0005869002197869122, 0.0018077020067721605, 0.0020226980559527874, 0.0009128628298640251, 0.0203176848590374, 0.0019912971183657646, 0.0013130896259099245, 0.0018237377516925335, 0.9481678605079651, 0.9899927973747253, 0.0013006910448893905, 0.9953010082244873, 0.0008353804005309939, 0.005789586808532476, 0.0009812256321310997, 0.0017142855795100331, 0.0017698960145935416, 0.0048103779554367065, 0.33495286107063293, 0.004289759788662195, 0.0010700419079512358, 0.9936037659645081, 0.009863585233688354, 0.0005860530654899776, 0.0017033345066010952, 0.9925253391265869, 0.00062840391183272, 0.001616553752683103, 0.0008965701563283801, 0.002770459745079279, 0.0023774190340191126, 0.9947927594184875, 0.9917942881584167, 0.9957281947135925, 0.994170606136322, 0.029224103316664696, 0.000911913113668561, 0.00262569566257298, 0.0021633098367601633, 0.9914140701293945, 0.9927547574043274, 0.0009202351211570203, 0.994203507900238, 0.6786032915115356, 0.9863431453704834, 0.0008933395729400218, 0.0020147075410932302, 0.010361256077885628, 0.003739908803254366, 0.011208398267626762, 0.9964331388473511, 0.004531123675405979, 0.01984749175608158, 0.0016727803740650415, 0.9955702424049377, 0.9216822385787964, 0.0014578861882910132, 0.9811811447143555, 0.0009121890761889517, 0.9521383047103882, 0.010648435913026333, 0.994975209236145, 0.9931192398071289, 0.0006291656172834337, 0.0013929192209616303, 0.0009827446192502975, 0.0010105203837156296, 0.0006292957114055753, 0.981981098651886, 0.0029818720649927855, 0.9932500123977661, 0.0010586592834442854, 0.9963182210922241, 0.14976553618907928, 0.0010135748889297247, 0.0014994977973401546, 0.0008494745707139373, 0.0006586629315279424, 0.9957528114318848, 0.0008329119882546365, 0.41128554940223694, 0.0210911612957716, 0.9955910444259644, 0.012118542566895485, 0.00073150300886482, 0.0024896683171391487, 0.0006730544846504927, 0.9945384860038757, 0.002524110721424222, 0.003323211334645748, 0.0007231494528241456, 0.0009990137768909335, 0.0015628382097929716, 0.9943702816963196, 0.03916526958346367, 0.0018477101111784577, 0.9728400111198425, 0.00547234620898962, 0.014930603094398975, 0.996268093585968, 0.009743154980242252, 0.9948360919952393, 0.001950616016983986, 0.004823443945497274, 0.0013534860918298364, 0.006747535429894924, 0.0015478773275390267, 0.990908682346344, 0.001534901326522231, 0.993486762046814, 0.9906572103500366, 0.995937705039978, 0.9246470332145691, 0.0006497576250694692, 0.0026657255366444588, 0.9962945580482483, 0.001008228282444179, 0.9701905250549316, 0.006766596343368292, 0.9894475936889648, 0.9954702854156494, 0.9757484793663025, 0.001552883186377585, 0.001598664210177958, 0.844876766204834, 0.9942827224731445, 0.6952692270278931, 0.0031284214928746223, 0.9674803614616394, 0.0005995372775942087, 0.9961644411087036, 0.008682389743626118, 0.0006847052718512714, 0.0005745583330281079, 0.9492300748825073, 0.004790954757481813, 0.001747890724800527, 0.04395267367362976, 0.9659102559089661, 0.9292316436767578, 0.0034818206913769245, 0.0011118969414383173, 0.0011483923299238086, 0.9912691116333008, 0.0008246231591328979, 0.0007274327799677849, 0.005476980470120907, 0.012280236929655075, 0.9945797920227051, 0.004721523262560368, 0.9626061320304871, 0.0005199423176236451, 0.9788174033164978, 0.9769040942192078, 0.0035175501834601164, 0.9956592917442322, 0.0005781028303317726, 0.9956585168838501, 0.0014970531919971108, 0.9829134345054626, 0.00787754449993372, 0.001276009134016931, 0.9885703921318054, 0.0016690086340531707, 0.0006941096507944167, 0.004468466620892286, 0.002487954217940569, 0.253696471452713, 0.8514170050621033, 0.004101218190044165, 0.001124702743254602, 0.00219599693082273, 0.9845580458641052, 0.02044476754963398, 0.994840681552887, 0.9940592050552368, 0.0008838345529511571, 0.0011603671591728926, 0.0022771237418055534, 0.9952126741409302, 0.0034882458858191967, 0.9954692125320435, 0.002433894667774439, 0.0025163718964904547, 0.002158281160518527, 0.9956117868423462, 0.0009241271764039993, 0.0006326200091280043, 0.003182843793183565, 0.9900029897689819, 0.9956580400466919, 0.995426595211029, 0.9898393154144287, 0.0011273501440882683, 0.00480843149125576, 0.0006488736253231764, 0.013830994255840778, 0.0006629523122683167, 0.0005939617403782904, 0.015518976375460625, 0.9251548051834106, 0.8056865930557251, 0.0014635963598266244, 0.9927109479904175, 0.0008458694210276008, 0.0011634085094556212, 0.0018996070139110088, 0.9943320751190186, 0.996434211730957, 0.9921358823776245, 0.0005485148285515606, 0.010876781307160854, 0.0018256206531077623, 0.9949297308921814, 0.9947110414505005, 0.9960082769393921, 0.0008492617635056376, 0.5802552103996277, 0.0015367204323410988, 0.9955697655677795, 0.9951789379119873, 0.9874014258384705, 0.011355212889611721, 0.9937397241592407, 0.9954937696456909, 0.0012231149012222886, 0.0020919034723192453, 0.0010549055878072977, 0.9938614368438721, 0.0015837416285648942, 0.0009865376632660627, 0.0012024660827592015, 0.9961177110671997, 0.0019384162733331323, 0.008035163395106792, 0.013052534312009811, 0.9820711016654968, 0.9947280287742615, 0.0005897906376048923, 0.07557249814271927, 0.0009390456252731383, 0.0006520632305182517, 0.0012188554974272847, 0.0015568860108032823, 0.00160311593208462, 0.000572105054743588, 0.0015544276684522629, 0.984744131565094, 0.1685323417186737, 0.0006460330332629383, 0.0004967215354554355, 0.9960957169532776, 0.0008624824695289135, 0.0011651009554043412, 0.0010809411760419607, 0.0029424659442156553, 0.9180295467376709, 0.2797602117061615, 0.04491978511214256, 0.000777345267124474, 0.014864655211567879, 0.9951210618019104, 0.0007900823839008808, 0.0006792120984755456, 0.908820629119873, 0.9929736852645874, 0.04503773897886276, 0.007795514073222876, 0.9775170087814331, 0.9951100945472717, 0.9959424138069153, 0.005120771937072277, 0.0010235162917524576, 0.9942615032196045, 0.9819313287734985, 0.0011590050999075174, 0.9237614274024963, 0.02047513797879219, 0.0017007231945171952, 0.0006704901461489499, 0.98240065574646, 0.9757505059242249, 0.995951771736145, 0.001269895350560546, 0.9929377436637878, 0.9933165311813354, 0.0012482301099225879, 0.0009645104291848838, 0.9954633116722107, 0.9887396097183228, 0.0014702974585816264, 0.35189297795295715, 0.008319373242557049, 0.0007460627239197493, 0.0021238725166767836, 0.004286554642021656, 0.988135814666748, 0.0008545613382011652, 0.9428228735923767, 0.9793179035186768, 0.9303948879241943, 0.9919102787971497, 0.9563992023468018, 0.0012489414075389504, 0.01439322903752327, 0.005840049125254154, 0.010295664891600609, 0.327507346868515, 0.00428874371573329, 0.0007262718863785267, 0.0005561349680647254, 0.0013304618187248707, 0.004344474989920855, 0.9955108165740967, 0.0008699818863533437, 0.9961720108985901, 0.0008681186591275036, 0.9391942620277405, 0.995613694190979, 0.42653119564056396, 0.9950752854347229, 0.003376745618879795, 0.9879466891288757, 0.0010122056119143963, 0.996431827545166, 0.0010201071854680777, 0.0011745811207219958, 0.0007827469962649047, 0.001689384807832539, 0.0014746175147593021, 0.001083855051547289, 0.0012393861543387175, 0.0015343817649409175, 0.001512057613581419, 0.0010438105091452599, 0.0008571501239202917, 0.9951860308647156, 0.0007977038039825857, 0.0017006696434691548, 0.019555646926164627, 0.995556652545929, 0.0014928920427337289, 0.9941493272781372, 0.0036190191749483347, 0.9705671668052673, 0.002159426687285304, 0.9950030446052551, 0.9943431615829468, 0.02230697125196457, 0.8620458841323853, 0.9947057366371155, 0.13197530806064606, 0.9960112571716309, 0.9613870978355408, 0.5799087882041931, 0.0025163337122648954, 0.0011739698238670826, 0.0016600911039859056, 0.9691257476806641, 0.011150489561259747, 0.003971962258219719, 0.0008506536250934005, 0.0009096448193304241, 0.000586612441111356, 0.9961530566215515, 0.9610817432403564, 0.9944629073143005, 0.0008633802644908428, 0.8972617983818054, 0.0011989247286692262, 0.994623064994812, 0.0006547849043272436, 0.9842395782470703, 0.0008081090054474771, 0.007070935796946287, 0.0007443176000379026, 0.0018029081402346492, 0.0033849473111331463, 0.00190557143650949, 0.005090359598398209, 0.0010555906919762492, 0.6856966018676758, 0.005764543544501066, 0.9947472214698792, 0.9939273595809937, 0.0026228087954223156, 0.0015231921570375562, 0.0021289323922246695, 0.9951930046081543, 0.0023624382447451353, 0.0005449877353385091, 0.0026437288615852594, 0.018118785694241524, 0.9930607080459595, 0.9956510663032532, 0.9961536526679993, 0.0019580761436372995, 0.000761724601034075, 0.9482260942459106, 0.008206017315387726, 0.018260881304740906, 0.0009503383189439774, 0.003329792758449912, 0.0020820917561650276, 0.0012646194081753492, 0.8423058390617371, 0.004293657839298248, 0.0015393404755741358, 0.016369653865695, 0.9733132123947144, 0.0013999422080814838, 0.9949355721473694, 0.987572193145752, 0.0007837244193069637, 0.9897144436836243, 0.8139557242393494, 0.003318127943202853, 0.0035084281116724014, 0.01597539521753788, 0.0007549508009105921, 0.995223343372345, 0.0012974623823538423, 0.006955412216484547, 0.995229959487915, 0.9845543503761292, 0.0010124491527676582, 0.4817397892475128, 0.02230059541761875, 0.000811175792478025, 0.0005811972077935934, 0.9926585555076599, 0.9954806566238403, 0.00072110490873456, 0.9958133101463318, 0.0006165348459035158, 0.0015603335341438651, 0.002717748284339905, 0.0007593937334604561, 0.002714390167966485, 0.9241830706596375, 0.0008335821330547333, 0.9602196216583252, 0.0067182304337620735, 0.0021337333600968122, 0.0005760319763794541, 0.9947125911712646]\n",
      "BertLargeCovidPooledOutput_0.0_8_2e-05_['WR']_cross_entropy_WR-0.1_exp-5_fold_0_Val-MCC_0.812968847031843.pth\n",
      "['6742', '10596', '482', '1613', '10549', '1221', '11477', '3394', '12195', '7674', '11270', '1548', '77', '4720', '78', '12237', '363', '4373', '3698', '4027', '339', '10050', '11344', '10019', '11421', '10110', '3677', '74', '103', '4371', '3771', '4947', '287', '10042', '12430', '105', '933', '12210', '11535', '727', '3532', '12165', '1252', '13131', '5095', '6544', '13081', '10807', '4173', '1992', '5130', '10531', '3602', '10960', '1418', '184', '6679', '13059', '13099', '10277', '182', '3732', '484', '3876', '12329', '4703', '10515', '206', '11187', '5008', '6307', '10492', '3562', '14042', '1634', '11267', '10467', '13079', '3347', '10251', '6667', '6713', '10709', '10335', '3469', '244', '3590', '1820', '5039', '6602', '3165', '6700', '11412', '1632', '4597', '10794', '11078', '4663', '2024', '1138', '2012', '858', '6653', '3432', '12341', '5132', '472', '5099', '11274', '3509', '3445', '12074', '3408', '5078', '4508', '12338', '13206', '1239', '6597', '10877', '12382', '11456', '1589', '4955', '3851', '3676', '10347', '10394', '10146', '4750', '4620', '350', '1211', '13225', '3630', '12114', '10333', '690', '241', '12089', '10186', '4052', '12026', '460', '13006', '10583', '3959', '3565', '12306', '4952', '10487', '1806', '4056', '485', '12301', '4180', '488', '5027', '13186', '4604', '12078', '10364', '4452', '11321', '10319', '10452', '12231', '776', '11205', '11226', '10694', '10625', '6311', '13043', '11423', '237', '1621', '247', '4828', '12130', '4203', '5031', '2018', '3679', '12279', '13177', '4557', '1975', '1216', '4499', '2074', '1695', '6309', '256', '12337', '10977', '10162', '10672', '5006', '12168', '10833', '12282', '10092', '3433', '11170', '13220', '10816', '494', '1617', '1247', '10848', '293', '12263', '10053', '10312', '12157', '11372', '11027', '3952', '1439', '11481', '12108', '13054', '3583', '3371', '3994', '11461', '6548', '11303', '4738', '3680', '38', '2028', '67', '4389', '62', '3942', '4984', '10915', '3784', '11522', '1605', '3636', '2087', '2041', '11393', '10070', '1095', '1', '66', '11030', '1461', '3293', '10887', '12120', '3902', '10285', '894', '11174', '1887', '4810', '12321', '5173', '4858', '11005', '10859', '10523', '6506', '10527', '10442', '1646', '10811', '740', '3351', '3451', '10506', '208', '13243', '7629', '10377', '139', '414', '978', '7599', '1818', '474', '12071', '12381', '280', '10222', '12443', '4219', '12372', '4442', '10918', '4231', '2013', '13000', '11272', '3756', '1652', '464', '221', '4161', '11526', '6721', '12303', '3496', '2086', '10800', '14046', '10904', '12088', '12153', '4733', '4096', '10127', '4257', '11253', '13070', '202', '4926', '4578', '4736', '12260', '3874', '4170', '156', '1812', '14', '10736', '3923', '1781', '6654', '2047', '1690', '11465', '10665', '11108', '1127', '441', '2098', '12412', '3660', '11188', '11566', '10115', '6267', '4989', '2039', '4853', '10301', '13010', '10034', '3861', '12434', '5131', '1772', '10875', '4531', '3915', '10357', '1092', '4379', '4585', '11060', '3522', '6305', '10236', '4826', '11486', '5134', '11254', '3169', '3781', '2081', '1596', '1830', '6405', '10613', '6704', '94', '10993', '14038', '10755', '1725', '3571', '5129', '11038', '1684', '5207', '12152', '13133', '10338', '2096', '4502', '3436', '12125', '3266', '10405', '10769', '3506', '2055', '7634', '13015', '12319', '1445', '4295', '323', '6716', '12370', '3425', '308', '4857', '4340', '6610', '1610', '3920', '4074', '4376', '12311', '6660', '3793', '1651', '11403', '13147', '11144', '3336', '4901', '5029', '744', '11442', '12179', '10328', '12428', '10007', '4520', '3439', '11417', '2016', '6172', '10632', '972', '3459', '10860', '4902', '12265', '10562', '11068', '3449', '1437', '4326', '10076', '2093', '1888', '5070', '810', '12017', '4521', '6585', '10818', '4801', '1706', '3153', '11542', '684', '4176', '6748', '5076', '5097', '4962', '6648', '10770', '10792', '12414', '4291', '6680', '1099', '11352', '10219', '3638', '11149', '4421', '3896', '665', '11115', '3625', '11083', '10355', '12027', '10942', '5202', '5136', '10068', '4921', '4628', '4786', '11184', '10950', '4418', '13007', '1841', '10609', '4887', '365', '397', '1624', '12400', '10191', '11554', '4041', '11299', '4964', '149', '4515', '3696', '6744', '12436', '12373', '1615', '3889', '10345', '3611', '13066', '13034', '346', '3655', '12462', '4658', '92', '10815', '4244', '4474', '4409', '1839', '4329', '11152', '3666', '10618', '4146', '10314', '370', '4481', '4749', '3857', '12185', '1124', '5168', '11018', '11134', '3808', '3782', '3271', '5033', '3758', '4878', '4478', '3440', '12416', '10151', '11532', '5166', '4742', '1273', '218', '57', '10696', '10961', '3642', '13199', '167', '10205', '3343', '11462', '4731', '13228', '12342', '11430', '13194', '302', '3159', '10966', '4251', '3424', '4230', '6692', '3877', '1109', '11548', '4934', '4378', '12075', '3922', '1822', '13018', '4121', '306', '1686', '42', '10396', '5101', '12391', '10457', '3749', '292', '4820', '4044', '12449', '10646', '12107', '12357', '13024', '1408', '6392', '11199', '10708', '6594', '12444', '1642', '12215', '3217', '4997', '866', '4087', '4875', '1446', '1122', '768', '10367', '12087', '4399', '12047', '791', '4454', '12446', '3854', '6657', '11483', '3362', '4238', '166', '999', '4235', '3254', '3261', '11256', '10072', '3481', '772', '1774', '10751', '12066', '3690', '1910', '3826', '1094', '12095', '3482', '11087', '4868', '4560', '6629', '4609', '1661', '1620', '732', '12322', '3519', '5012', '70', '10211', '1663', '3747', '6605', '11128', '4538', '736', '10257', '204', '10985', '1593', '11497', '3302', '3596', '11259', '10488', '13144', '10315', '767', '1689', '12285', '11119', '10700', '6576', '4001', '13128', '4716', '6646', '13044', '214', '3825', '11015', '10802', '3714', '12363', '4213', '6549', '1098', '10051', '10926', '4540', '63', '10451', '26', '12250', '3664', '2049', '10358', '3616', '10654', '4522', '10578', '3348', '3810', '10866', '1843', '12192', '11160', '10988', '10881', '12206', '10997', '12290', '6666', '10529', '967', '3985', '5088', '5024', '788', '4747', '3423', '4547', '10706', '6612', '72', '12340', '4652', '10965', '12015', '13142', '3245', '4833', '3965', '194', '14033', '11467', '4937', '4331', '12046', '10611', '6592', '905', '6705', '5106', '661', '13188', '935', '770', '11076', '4210', '737', '4599', '10267', '1131', '1308', '11139', '10663', '73', '11531', '10052', '3211', '14039', '12080', '1737', '1709', '11309', '3622', '3726', '4026', '14029', '3328', '11484', '11368', '10747', '328', '5164', '475', '243', '3200', '140', '2056', '3988', '1760', '13246', '6580', '173', '4595', '12151', '5016', '24', '468', '11432', '4078', '12028', '309', '150', '3623', '13106', '6541', '1758', '4051', '10055', '6574', '71', '1664', '12347', '6635', '2065', '11287', '4920', '3993', '4526', '11558', '10262', '277', '307', '3470', '126', '679', '4350', '4890', '10063', '765', '4600', '161', '1611', '13223', '10359', '3821', '11392', '12202', '4128', '1640', '12367', '6728', '10715', '3494', '13028', '11429', '6529', '10429', '4654', '10513', '3594', '10446', '4766', '1317', '1792', '11037', '4927', '1672', '11300', '3730', '3335', '4131', '911', '4722', '189', '12258', '13239', '4951', '4413', '4789', '12266', '4069', '4642', '10435', '10460', '13237', '11153', '13012', '4685', '10838', '7611', '311', '6532', '4669', '13086', '4337', '1226', '2080', '6511', '10081', '6593', '1995', '1691', '1111', '11373', '5090', '12042', '10105', '6674', '3822', '5200', '4484', '4205', '5110', '936', '3393', '10167', '1779', '13205', '3235', '13072', '10631', '12223', '4473', '10221', '13009', '11516', '12201', '12317', '10188', '10041', '13155', '10841', '6609', '1126', '5127', '5178', '1399', '10489', '753', '11064', '10158', '187', '220', '11337', '276', '10241', '10397', '10607', '4380', '3925', '10341', '10374', '369', '10779', '348', '10994', '4080', '7627', '10204', '4895', '6598', '11478', '12102', '6518', '10707', '4462', '3430', '13122', '5177', '6176', '10710', '14010', '12344', '10321', '10731', '314', '801', '4363', '4366', '6709', '186', '4167', '55', '12181', '4589', '5146', '14048', '4263', '4776', '4269', '1314', '4153', '10197', '12099', '10705']\n",
      "[0.9946264624595642, 0.20344625413417816, 0.003640000009909272, 0.0019985067192465067, 0.02605516090989113, 0.9959316849708557, 0.0033310335129499435, 0.9950473308563232, 0.0015040761791169643, 0.008046078495681286, 0.9771280288696289, 0.9958345890045166, 0.9949353337287903, 0.0016373660182580352, 0.9948051571846008, 0.006835647858679295, 0.0031099957413971424, 0.0015108430525287986, 0.0346817672252655, 0.9912857413291931, 0.0032827723771333694, 0.01589776575565338, 0.9918695688247681, 0.001292350934818387, 0.002246591728180647, 0.7972246408462524, 0.43888059258461, 0.9947199821472168, 0.9951748847961426, 0.0021039494313299656, 0.5338872075080872, 0.9964399933815002, 0.9726231098175049, 0.005122681614011526, 0.0012903978349640965, 0.9946618676185608, 0.9954642653465271, 0.001455796300433576, 0.006110875401645899, 0.995105504989624, 0.0019886097870767117, 0.0015926818596199155, 0.9946634769439697, 0.9948781728744507, 0.003151901997625828, 0.9948455095291138, 0.9936955571174622, 0.0048930407501757145, 0.2992137372493744, 0.0278613343834877, 0.0019064350053668022, 0.0027081689331680536, 0.002531857695430517, 0.9942629933357239, 0.0017748904647305608, 0.9950579404830933, 0.9930081367492676, 0.0014869282022118568, 0.9822419881820679, 0.15324872732162476, 0.0845787525177002, 0.04435748606920242, 0.004958745092153549, 0.9954427480697632, 0.0021997843869030476, 0.001571521395817399, 0.0028833376709371805, 0.11141767352819443, 0.9946199655532837, 0.0022501659113913774, 0.011844555847346783, 0.808518648147583, 0.0032270748633891344, 0.9929157495498657, 0.9942653775215149, 0.1418229192495346, 0.9763584136962891, 0.9956682920455933, 0.0015981809701770544, 0.0038080797530710697, 0.9957499504089355, 0.9944057464599609, 0.0019124509999528527, 0.9510226845741272, 0.001648471225053072, 0.7894955277442932, 0.0018540325108915567, 0.0018593859858810902, 0.0016116466140374541, 0.9953255653381348, 0.002269838936626911, 0.9913651943206787, 0.0015691888984292746, 0.0032258068677037954, 0.0018218308687210083, 0.9936098456382751, 0.9956849813461304, 0.0018408376490697265, 0.008022589609026909, 0.9937826991081238, 0.001515941577963531, 0.9932970404624939, 0.9934653639793396, 0.0016514590242877603, 0.0017923632403835654, 0.0016060569323599339, 0.002350014401599765, 0.0013887223321944475, 0.01782139204442501, 0.0015640389174222946, 0.0023826826363801956, 0.0024555146228522062, 0.5063554048538208, 0.9532846808433533, 0.001986284041777253, 0.002701416378840804, 0.0020538910757750273, 0.9941144585609436, 0.9967772364616394, 0.0013886475935578346, 0.008303000591695309, 0.002399814547970891, 0.018375199288129807, 0.0018039752030745149, 0.003715795697644353, 0.7415870428085327, 0.0016530322609469295, 0.0015038785059005022, 0.003856739029288292, 0.0020373002626001835, 0.0017301382031291723, 0.001401781919412315, 0.4012083113193512, 0.0026979141402989626, 0.0020956925582140684, 0.001335397595539689, 0.003452678443863988, 0.019178612157702446, 0.9967721104621887, 0.001586024067364633, 0.008921319618821144, 0.007780709769576788, 0.0018080160953104496, 0.013685092329978943, 0.9947869777679443, 0.991381824016571, 0.006511212792247534, 0.22945621609687805, 0.00269179861061275, 0.013084440492093563, 0.0015577207086607814, 0.0015390283660963178, 0.010761558078229427, 0.0014757835306227207, 0.00140626251231879, 0.9961183071136475, 0.002925546607002616, 0.0020808943081647158, 0.023260697722434998, 0.0017569586634635925, 0.008292143233120441, 0.0014821322401985526, 0.0014226387720555067, 0.6807780265808105, 0.41153955459594727, 0.02153746411204338, 0.003686836687847972, 0.9850277900695801, 0.9948917627334595, 0.002852424280717969, 0.9510884881019592, 0.02298187091946602, 0.9913234710693359, 0.0019122743979096413, 0.9963604807853699, 0.8452628254890442, 0.9956234097480774, 0.8779075145721436, 0.18871857225894928, 0.9943523406982422, 0.003543973434716463, 0.0015214210143312812, 0.027006790041923523, 0.00838256161659956, 0.0019758560229092836, 0.0013843013439327478, 0.0013637467054650187, 0.11024592816829681, 0.03294066712260246, 0.0022120578214526176, 0.08021790534257889, 0.005088370759040117, 0.9416693449020386, 0.0037415686529129744, 0.001591459265910089, 0.9952659606933594, 0.6801220178604126, 0.9891273379325867, 0.0017964851576834917, 0.7288374304771423, 0.9944097399711609, 0.001402597757987678, 0.9962045550346375, 0.0015323639381676912, 0.9954984188079834, 0.9940394163131714, 0.021388795226812363, 0.004221819806843996, 0.0029765067156404257, 0.9949074387550354, 0.012954341247677803, 0.0012598724570125341, 0.0017506858566775918, 0.0016029479447752237, 0.00199871021322906, 0.9938719272613525, 0.9918919801712036, 0.001891009509563446, 0.0034359891433268785, 0.0024235742166638374, 0.011055897921323776, 0.005806419998407364, 0.9919345378875732, 0.001579197822138667, 0.00192787847481668, 0.002153752138838172, 0.0017656661802902818, 0.9957876801490784, 0.995428204536438, 0.9942607879638672, 0.15691803395748138, 0.0018759809900075197, 0.9956791996955872, 0.9928582906723022, 0.0014489339664578438, 0.9949888586997986, 0.00853448361158371, 0.001490410533733666, 0.001289833104237914, 0.9964537620544434, 0.001463192282244563, 0.0016879120375961065, 0.0019840686582028866, 0.9820099472999573, 0.9949069619178772, 0.001147662871517241, 0.9944943785667419, 0.9857349991798401, 0.987628698348999, 0.18850833177566528, 0.9958868622779846, 0.002002911875024438, 0.004945249296724796, 0.003759270766749978, 0.002173225162550807, 0.019279491156339645, 0.002056889934465289, 0.9937452077865601, 0.21468602120876312, 0.0018666025716811419, 0.0038715859409421682, 0.9956755042076111, 0.001970641314983368, 0.9956204295158386, 0.0019970026332885027, 0.025459591299295425, 0.0012316051870584488, 0.9956709146499634, 0.0013458430767059326, 0.0012360262917354703, 0.00162586010992527, 0.0017220121808350086, 0.9961383938789368, 0.0027642089407891035, 0.0023315693251788616, 0.002136367605999112, 0.04024195671081543, 0.0015016919933259487, 0.9913370609283447, 0.0024808733724057674, 0.0017120634438470006, 0.6096600890159607, 0.9956913590431213, 0.01033089216798544, 0.0018320252420380712, 0.00265871430747211, 0.0015274202451109886, 0.001986270770430565, 0.0021806289441883564, 0.0020969384349882603, 0.0013628709129989147, 0.001337092719040811, 0.0033031865023076534, 0.0013875800650566816, 0.9922106266021729, 0.002175369765609503, 0.001577652059495449, 0.0013692021602764726, 0.8393913507461548, 0.005275362636893988, 0.36678650975227356, 0.007426235359162092, 0.01579396426677704, 0.9948386549949646, 0.0017874193144962192, 0.9304302930831909, 0.0016638387460261583, 0.11735835671424866, 0.9965420365333557, 0.008311835117638111, 0.00348560675047338, 0.009010480716824532, 0.0017874150071293116, 0.9906039834022522, 0.03657795116305351, 0.00915064848959446, 0.9946085214614868, 0.0017211278900504112, 0.9446173310279846, 0.9902938604354858, 0.1523866504430771, 0.3995748460292816, 0.0015962800243869424, 0.0021050560753792524, 0.0031854016706347466, 0.0037062368355691433, 0.16090820729732513, 0.0027143722400069237, 0.0021455318201333284, 0.9067146182060242, 0.0019694066140800714, 0.005326396785676479, 0.9951664209365845, 0.9952762126922607, 0.9960502982139587, 0.0015117625007405877, 0.001555000664666295, 0.001842977711930871, 0.00788834597915411, 0.992879331111908, 0.021846942603588104, 0.0020751957781612873, 0.004098951816558838, 0.9959508180618286, 0.08283649384975433, 0.0038385139778256416, 0.00206801132299006, 0.9908451437950134, 0.002020314335823059, 0.9777282476425171, 0.34873300790786743, 0.0023068597074598074, 0.06394379585981369, 0.010171660222113132, 0.005989075172692537, 0.8349323868751526, 0.0014615727122873068, 0.0035636061802506447, 0.9959452748298645, 0.0016004834324121475, 0.9729896783828735, 0.017946070060133934, 0.9956067204475403, 0.0020298759918659925, 0.0048167165368795395, 0.9964463114738464, 0.468616783618927, 0.8390051126480103, 0.9944885969161987, 0.7159859538078308, 0.00341144111007452, 0.001671927864663303, 0.004762279335409403, 0.0020218337886035442, 0.9850146174430847, 0.008523346856236458, 0.004824281204491854, 0.024383828043937683, 0.9909838438034058, 0.0034009104128926992, 0.9953411817550659, 0.02085311897099018, 0.0016913337167352438, 0.9928227066993713, 0.9897588491439819, 0.0017673115944489837, 0.0015592455165460706, 0.006094121374189854, 0.0317857600748539, 0.07033964991569519, 0.0023740441538393497, 0.8107749223709106, 0.0015429842751473188, 0.0014124438166618347, 0.9952493906021118, 0.0020935118664056063, 0.0016025977674871683, 0.002101845107972622, 0.0014396186452358961, 0.0023132862988859415, 0.11124920099973679, 0.0027689291164278984, 0.9902657866477966, 0.03092215210199356, 0.002128238556906581, 0.001491270144470036, 0.9957464337348938, 0.0018906063633039594, 0.059804487973451614, 0.9962158799171448, 0.9712271094322205, 0.9946035742759705, 0.0016214679926633835, 0.9757100939750671, 0.0014358821790665388, 0.9945393204689026, 0.0013941945508122444, 0.003138491651043296, 0.001862186356447637, 0.0015591623960062861, 0.001713641220703721, 0.9957643747329712, 0.9752610921859741, 0.003151142504066229, 0.0025601950474083424, 0.0016876058652997017, 0.0016354145482182503, 0.9962282180786133, 0.26543372869491577, 0.05109557881951332, 0.9951817393302917, 0.1206691563129425, 0.001923699164763093, 0.002487046644091606, 0.9088876843452454, 0.002685166895389557, 0.00365560594946146, 0.002950382884591818, 0.0019169817678630352, 0.0017175873508676887, 0.015818005427718163, 0.993194580078125, 0.2797778248786926, 0.002194058382883668, 0.0039174314588308334, 0.06831595301628113, 0.004250889644026756, 0.005408461671322584, 0.9926958084106445, 0.0017532509518787265, 0.0014749376568943262, 0.0027254100423306227, 0.003255618503317237, 0.6943855285644531, 0.0026283005718141794, 0.0015033796662464738, 0.9930908679962158, 0.9952656030654907, 0.002020283369347453, 0.9957938194274902, 0.0036189367529004812, 0.0013464572839438915, 0.25085631012916565, 0.9921419620513916, 0.0016119566280394793, 0.995765209197998, 0.00275650667026639, 0.9912964105606079, 0.0014521663542836905, 0.002054176526144147, 0.054577119648456573, 0.9941020607948303, 0.04722568765282631, 0.001767024747096002, 0.001397585147060454, 0.0020065591670572758, 0.9943822622299194, 0.9955646991729736, 0.9939748644828796, 0.05850110948085785, 0.002681134734302759, 0.0015097600407898426, 0.0028415124397724867, 0.004575977101922035, 0.0017900144448503852, 0.002556183375418186, 0.002504608826711774, 0.9957237243652344, 0.0019621686078608036, 0.01620418019592762, 0.0028798580169677734, 0.0013543629320338368, 0.0015166454249992967, 0.0015409638872370124, 0.001860686345025897, 0.002204786753281951, 0.0021429075859487057, 0.9269391894340515, 0.9945705533027649, 0.0014380546053871512, 0.9914653897285461, 0.0025745180901139975, 0.9853731989860535, 0.0018347235163673759, 0.022797754034399986, 0.9936603903770447, 0.0014933781931176782, 0.001563184312544763, 0.0034504872746765614, 0.002097893273457885, 0.004555724561214447, 0.9957128763198853, 0.8906609416007996, 0.7305230498313904, 0.0018839847762137651, 0.8389472961425781, 0.9949617385864258, 0.0026168706826865673, 0.0019409474916756153, 0.0029023131355643272, 0.17614790797233582, 0.0017743853386491537, 0.0016605549026280642, 0.9952087998390198, 0.0021235987078398466, 0.10033784061670303, 0.001221905113197863, 0.011489931493997574, 0.0021674814634025097, 0.0015889693750068545, 0.039543841034173965, 0.002345877233892679, 0.002038287464529276, 0.0016265009762719274, 0.0016738851554691792, 0.0020627493504434824, 0.9950062036514282, 0.0014953912468627095, 0.004988985136151314, 0.004526164382696152, 0.001533788745291531, 0.209509015083313, 0.0020855702459812164, 0.0012562901247292757, 0.005125308874994516, 0.006691705901175737, 0.9963445067405701, 0.0015319371595978737, 0.9381713271141052, 0.996673583984375, 0.9931775331497192, 0.054675616323947906, 0.0033823635894805193, 0.0017356722382828593, 0.0029810937121510506, 0.006194231566041708, 0.0021206773817539215, 0.0020842221565544605, 0.0027313835453242064, 0.0014258289011195302, 0.0013730289647355676, 0.001984803471714258, 0.9950194358825684, 0.9918013215065002, 0.0015663004014641047, 0.9942100048065186, 0.0015526777133345604, 0.006499187555164099, 0.0016643836861476302, 0.0014339049812406301, 0.004161923658102751, 0.7642614841461182, 0.07457898557186127, 0.0053757899440824986, 0.0015317898942157626, 0.9948247671127319, 0.007869536057114601, 0.0014819488860666752, 0.0016532880254089832, 0.9808304309844971, 0.0019450716208666563, 0.010390618816018105, 0.0017191102961078286, 0.0022551913280040026, 0.001588943530805409, 0.9834173321723938, 0.9866015315055847, 0.9965097308158875, 0.9944011569023132, 0.01934458315372467, 0.003035173285752535, 0.0019337371923029423, 0.007213870994746685, 0.9952967762947083, 0.9944061040878296, 0.0021505909971892834, 0.996713399887085, 0.16651155054569244, 0.9946541786193848, 0.0016262137796729803, 0.0019493603613227606, 0.008187124505639076, 0.002464025281369686, 0.006749313324689865, 0.9953845143318176, 0.0018036540132015944, 0.006720620207488537, 0.0018053570529446006, 0.9925461411476135, 0.9554798007011414, 0.0014643127797171474, 0.9951909780502319, 0.002012622309848666, 0.9723542332649231, 0.004839460365474224, 0.9919209480285645, 0.9955551028251648, 0.0020306401420384645, 0.0016757077537477016, 0.0017452178290113807, 0.002227574586868286, 0.0013380814343690872, 0.9927142262458801, 0.0017926301807165146, 0.9953729510307312, 0.0036871996708214283, 0.9956676959991455, 0.05151878669857979, 0.0014839767245575786, 0.0016580368392169476, 0.0017104230355471373, 0.0015440646093338728, 0.996579110622406, 0.0016650604084134102, 0.6091292500495911, 0.014753586612641811, 0.9946821331977844, 0.002724189544096589, 0.001919737085700035, 0.00242966553196311, 0.0026457817293703556, 0.9938352108001709, 0.002098993631079793, 0.0015377671224996448, 0.0027491054497659206, 0.0018456295365467668, 0.0032096179202198982, 0.9939206838607788, 0.44391244649887085, 0.0013013570569455624, 0.9842049479484558, 0.007274668663740158, 0.11863820999860764, 0.9963418841362, 0.0027375146746635437, 0.9970995187759399, 0.002093368209898472, 0.006328664254397154, 0.002982817590236664, 0.001553746871650219, 0.0015868586488068104, 0.9961434602737427, 0.002249067882075906, 0.9958145022392273, 0.9951518774032593, 0.9955860376358032, 0.678592324256897, 0.002623101929202676, 0.0016612254548817873, 0.9946529865264893, 0.0014917836524546146, 0.015424256213009357, 0.004053079057484865, 0.9949122071266174, 0.9951509237289429, 0.9871790409088135, 0.003023439319804311, 0.0018038059351965785, 0.8151829838752747, 0.994877278804779, 0.9508206844329834, 0.012333102524280548, 0.9946720004081726, 0.002142325509339571, 0.9916903972625732, 0.01589353010058403, 0.0022354458924382925, 0.001485426095314324, 0.9365173578262329, 0.13123412430286407, 0.0021361743565648794, 0.016507765278220177, 0.9930732846260071, 0.7664548754692078, 0.027868125587701797, 0.002579889027401805, 0.001984958304092288, 0.9956265687942505, 0.0016701975837349892, 0.002311278833076358, 0.004003168549388647, 0.00529605895280838, 0.9953321814537048, 0.014446046203374863, 0.9927310347557068, 0.0014448306756094098, 0.9964538812637329, 0.9925580024719238, 0.003012758446857333, 0.9916824102401733, 0.001735336729325354, 0.9946725964546204, 0.0021366258151829243, 0.9258783459663391, 0.0056994264014065266, 0.001812933012843132, 0.9943650960922241, 0.0014669793890789151, 0.00165822624694556, 0.0054835607297718525, 0.0021451744250953197, 0.9959568381309509, 0.8817938566207886, 0.0059928689152002335, 0.0026602621655911207, 0.0036152503453195095, 0.9840865731239319, 0.022354841232299805, 0.9951399564743042, 0.9946601986885071, 0.0015945801278576255, 0.0020814083982259035, 0.001515793614089489, 0.9936215281486511, 0.0038355032447725534, 0.9951751232147217, 0.0023041439708322287, 0.0013199610402807593, 0.001714579644612968, 0.9957267045974731, 0.0016995787154883146, 0.0018365407595410943, 0.0015299393562600017, 0.9891451001167297, 0.9938621520996094, 0.9946261048316956, 0.9849027991294861, 0.0023526328150182962, 0.006547196768224239, 0.0012828093022108078, 0.005666782613843679, 0.0026327166706323624, 0.0019541755318641663, 0.00789677631109953, 0.9958707690238953, 0.07030583173036575, 0.0021890990901738405, 0.9957218170166016, 0.002094987314194441, 0.0016789983492344618, 0.020317554473876953, 0.9948981404304504, 0.995111882686615, 0.9942862391471863, 0.011570964008569717, 0.01844458095729351, 0.010972397401928902, 0.9951983094215393, 0.9948115348815918, 0.9946984052658081, 0.0023345528170466423, 0.07856255024671555, 0.0016049327095970511, 0.9958904981613159, 0.9961574673652649, 0.994492769241333, 0.24387286603450775, 0.995434582233429, 0.9949631690979004, 0.0012233415618538857, 0.0030397060327231884, 0.0016014812281355262, 0.9966687560081482, 0.00803860742598772, 0.00301730097271502, 0.001490410533733666, 0.995710015296936, 0.0015323383267968893, 0.0033700524363666773, 0.005137682892382145, 0.9956497550010681, 0.9900636076927185, 0.003595160087570548, 0.09738434851169586, 0.0015459380811080337, 0.005949176847934723, 0.0016586226411163807, 0.0045075733214616776, 0.005336205009371042, 0.00240901717916131, 0.004274667240679264, 0.9935512542724609, 0.013971691019833088, 0.0014247699873521924, 0.001459623919799924, 0.9961613416671753, 0.0038961563259363174, 0.004534575156867504, 0.001505423104390502, 0.001853513647802174, 0.4678697884082794, 0.6123598217964172, 0.09738551080226898, 0.0018008153419941664, 0.034478310495615005, 0.9960468411445618, 0.0015459064161404967, 0.0021254820749163628, 0.9104790091514587, 0.9801728129386902, 0.3462926149368286, 0.03445679321885109, 0.9933875799179077, 0.9949604272842407, 0.9917042255401611, 0.001985270995646715, 0.027926720678806305, 0.9964184761047363, 0.9915363788604736, 0.0017534479266032577, 0.8033413290977478, 0.005473353434354067, 0.0017721273470669985, 0.0015751648461446166, 0.9911074042320251, 0.9348433017730713, 0.9959480166435242, 0.0020467336289584637, 0.9951759576797485, 0.9951906204223633, 0.001727010472677648, 0.0015611902344971895, 0.9966292977333069, 0.9957917928695679, 0.0026947802398353815, 0.6294118165969849, 0.0029737416189163923, 0.0018023151205852628, 0.002330570248886943, 0.0030730548314750195, 0.947541356086731, 0.0029426824767142534, 0.951798141002655, 0.9950313568115234, 0.13729463517665863, 0.9878330230712891, 0.9835401177406311, 0.0015561411855742335, 0.4750400483608246, 0.018333856016397476, 0.026331814005970955, 0.4678400456905365, 0.001553113223053515, 0.0014666874194517732, 0.002712944755330682, 0.0031195131596177816, 0.010884946212172508, 0.9955419898033142, 0.0013865682994946837, 0.995155930519104, 0.00200193515047431, 0.3723820745944977, 0.995937705039978, 0.8029464483261108, 0.9923415184020996, 0.0028831157833337784, 0.994961142539978, 0.0034325732849538326, 0.9960177540779114, 0.0021370425820350647, 0.0018251175060868263, 0.003387945704162121, 0.0017957071540877223, 0.0019013445125892758, 0.0025148859713226557, 0.001589010818861425, 0.0012499094009399414, 0.0015711294254288077, 0.005289784632623196, 0.0025775369722396135, 0.9957714676856995, 0.001719251275062561, 0.00136180582921952, 0.004903271794319153, 0.9919078350067139, 0.0033079530112445354, 0.9965687990188599, 0.00155455875210464, 0.9903779029846191, 0.002053453354164958, 0.9968749284744263, 0.9948365688323975, 0.6818207502365112, 0.9909577369689941, 0.9959099292755127, 0.25381821393966675, 0.9950390458106995, 0.1850045919418335, 0.13276228308677673, 0.0014542933786287904, 0.0026887371204793453, 0.006240301299840212, 0.9961313009262085, 0.004996631760150194, 0.001959857763722539, 0.002090214053168893, 0.0015028994530439377, 0.002434296067804098, 0.9947858452796936, 0.9496586322784424, 0.9958347082138062, 0.013273268938064575, 0.9470840096473694, 0.0017894369084388018, 0.9905932545661926, 0.0017042290419340134, 0.9958454966545105, 0.0015911167720332742, 0.044007427990436554, 0.0014771523419767618, 0.0017911597387865186, 0.005890205502510071, 0.0016094247112050653, 0.03954111412167549, 0.0019276326056569815, 0.5744112133979797, 0.020130684599280357, 0.9928076267242432, 0.9949872493743896, 0.001928813522681594, 0.009059599600732327, 0.0022087430115789175, 0.991945207118988, 0.014872378669679165, 0.0013921736972406507, 0.0023174709640443325, 0.005451249424368143, 0.9889107942581177, 0.9956026077270508, 0.9951434135437012, 0.014157217927277088, 0.005222406703978777, 0.9814105033874512, 0.0033560250885784626, 0.004089947324246168, 0.001548868720419705, 0.005661741364747286, 0.011182084679603577, 0.008355699479579926, 0.9587715864181519, 0.0029774296563118696, 0.0019514739979058504, 0.057663802057504654, 0.9553868770599365, 0.0046208687126636505, 0.9957655668258667, 0.9945825934410095, 0.001400871085934341, 0.9829540848731995, 0.6092922687530518, 0.0015999593306332827, 0.0026067360304296017, 0.0022040619514882565, 0.0019291285425424576, 0.9944179058074951, 0.002094200113788247, 0.00343061750754714, 0.99439537525177, 0.9935100674629211, 0.0016501827631145716, 0.3197074830532074, 0.049105990678071976, 0.0013895794982090592, 0.001891107764095068, 0.9949576258659363, 0.9962955117225647, 0.0019263715948909521, 0.9946203231811523, 0.0014860901283100247, 0.002015115926042199, 0.0022569012362509966, 0.0014329603873193264, 0.0032286548521369696, 0.2892528176307678, 0.0014695794088765979, 0.9844361543655396, 0.010842525400221348, 0.007252004463225603, 0.0014474494382739067, 0.9938279986381531]\n",
      "BertLargeCovidPooledOutput_0.0_8_2e-05_['WR']_cross_entropy_WR-0.1_exp-1_fold_1_Val-MCC_0.0.pth\n",
      "['6742', '10596', '482', '1613', '10549', '1221', '11477', '3394', '12195', '7674', '11270', '1548', '77', '4720', '78', '12237', '363', '4373', '3698', '4027', '339', '10050', '11344', '10019', '11421', '10110', '3677', '74', '103', '4371', '3771', '4947', '287', '10042', '12430', '105', '933', '12210', '11535', '727', '3532', '12165', '1252', '13131', '5095', '6544', '13081', '10807', '4173', '1992', '5130', '10531', '3602', '10960', '1418', '184', '6679', '13059', '13099', '10277', '182', '3732', '484', '3876', '12329', '4703', '10515', '206', '11187', '5008', '6307', '10492', '3562', '14042', '1634', '11267', '10467', '13079', '3347', '10251', '6667', '6713', '10709', '10335', '3469', '244', '3590', '1820', '5039', '6602', '3165', '6700', '11412', '1632', '4597', '10794', '11078', '4663', '2024', '1138', '2012', '858', '6653', '3432', '12341', '5132', '472', '5099', '11274', '3509', '3445', '12074', '3408', '5078', '4508', '12338', '13206', '1239', '6597', '10877', '12382', '11456', '1589', '4955', '3851', '3676', '10347', '10394', '10146', '4750', '4620', '350', '1211', '13225', '3630', '12114', '10333', '690', '241', '12089', '10186', '4052', '12026', '460', '13006', '10583', '3959', '3565', '12306', '4952', '10487', '1806', '4056', '485', '12301', '4180', '488', '5027', '13186', '4604', '12078', '10364', '4452', '11321', '10319', '10452', '12231', '776', '11205', '11226', '10694', '10625', '6311', '13043', '11423', '237', '1621', '247', '4828', '12130', '4203', '5031', '2018', '3679', '12279', '13177', '4557', '1975', '1216', '4499', '2074', '1695', '6309', '256', '12337', '10977', '10162', '10672', '5006', '12168', '10833', '12282', '10092', '3433', '11170', '13220', '10816', '494', '1617', '1247', '10848', '293', '12263', '10053', '10312', '12157', '11372', '11027', '3952', '1439', '11481', '12108', '13054', '3583', '3371', '3994', '11461', '6548', '11303', '4738', '3680', '38', '2028', '67', '4389', '62', '3942', '4984', '10915', '3784', '11522', '1605', '3636', '2087', '2041', '11393', '10070', '1095', '1', '66', '11030', '1461', '3293', '10887', '12120', '3902', '10285', '894', '11174', '1887', '4810', '12321', '5173', '4858', '11005', '10859', '10523', '6506', '10527', '10442', '1646', '10811', '740', '3351', '3451', '10506', '208', '13243', '7629', '10377', '139', '414', '978', '7599', '1818', '474', '12071', '12381', '280', '10222', '12443', '4219', '12372', '4442', '10918', '4231', '2013', '13000', '11272', '3756', '1652', '464', '221', '4161', '11526', '6721', '12303', '3496', '2086', '10800', '14046', '10904', '12088', '12153', '4733', '4096', '10127', '4257', '11253', '13070', '202', '4926', '4578', '4736', '12260', '3874', '4170', '156', '1812', '14', '10736', '3923', '1781', '6654', '2047', '1690', '11465', '10665', '11108', '1127', '441', '2098', '12412', '3660', '11188', '11566', '10115', '6267', '4989', '2039', '4853', '10301', '13010', '10034', '3861', '12434', '5131', '1772', '10875', '4531', '3915', '10357', '1092', '4379', '4585', '11060', '3522', '6305', '10236', '4826', '11486', '5134', '11254', '3169', '3781', '2081', '1596', '1830', '6405', '10613', '6704', '94', '10993', '14038', '10755', '1725', '3571', '5129', '11038', '1684', '5207', '12152', '13133', '10338', '2096', '4502', '3436', '12125', '3266', '10405', '10769', '3506', '2055', '7634', '13015', '12319', '1445', '4295', '323', '6716', '12370', '3425', '308', '4857', '4340', '6610', '1610', '3920', '4074', '4376', '12311', '6660', '3793', '1651', '11403', '13147', '11144', '3336', '4901', '5029', '744', '11442', '12179', '10328', '12428', '10007', '4520', '3439', '11417', '2016', '6172', '10632', '972', '3459', '10860', '4902', '12265', '10562', '11068', '3449', '1437', '4326', '10076', '2093', '1888', '5070', '810', '12017', '4521', '6585', '10818', '4801', '1706', '3153', '11542', '684', '4176', '6748', '5076', '5097', '4962', '6648', '10770', '10792', '12414', '4291', '6680', '1099', '11352', '10219', '3638', '11149', '4421', '3896', '665', '11115', '3625', '11083', '10355', '12027', '10942', '5202', '5136', '10068', '4921', '4628', '4786', '11184', '10950', '4418', '13007', '1841', '10609', '4887', '365', '397', '1624', '12400', '10191', '11554', '4041', '11299', '4964', '149', '4515', '3696', '6744', '12436', '12373', '1615', '3889', '10345', '3611', '13066', '13034', '346', '3655', '12462', '4658', '92', '10815', '4244', '4474', '4409', '1839', '4329', '11152', '3666', '10618', '4146', '10314', '370', '4481', '4749', '3857', '12185', '1124', '5168', '11018', '11134', '3808', '3782', '3271', '5033', '3758', '4878', '4478', '3440', '12416', '10151', '11532', '5166', '4742', '1273', '218', '57', '10696', '10961', '3642', '13199', '167', '10205', '3343', '11462', '4731', '13228', '12342', '11430', '13194', '302', '3159', '10966', '4251', '3424', '4230', '6692', '3877', '1109', '11548', '4934', '4378', '12075', '3922', '1822', '13018', '4121', '306', '1686', '42', '10396', '5101', '12391', '10457', '3749', '292', '4820', '4044', '12449', '10646', '12107', '12357', '13024', '1408', '6392', '11199', '10708', '6594', '12444', '1642', '12215', '3217', '4997', '866', '4087', '4875', '1446', '1122', '768', '10367', '12087', '4399', '12047', '791', '4454', '12446', '3854', '6657', '11483', '3362', '4238', '166', '999', '4235', '3254', '3261', '11256', '10072', '3481', '772', '1774', '10751', '12066', '3690', '1910', '3826', '1094', '12095', '3482', '11087', '4868', '4560', '6629', '4609', '1661', '1620', '732', '12322', '3519', '5012', '70', '10211', '1663', '3747', '6605', '11128', '4538', '736', '10257', '204', '10985', '1593', '11497', '3302', '3596', '11259', '10488', '13144', '10315', '767', '1689', '12285', '11119', '10700', '6576', '4001', '13128', '4716', '6646', '13044', '214', '3825', '11015', '10802', '3714', '12363', '4213', '6549', '1098', '10051', '10926', '4540', '63', '10451', '26', '12250', '3664', '2049', '10358', '3616', '10654', '4522', '10578', '3348', '3810', '10866', '1843', '12192', '11160', '10988', '10881', '12206', '10997', '12290', '6666', '10529', '967', '3985', '5088', '5024', '788', '4747', '3423', '4547', '10706', '6612', '72', '12340', '4652', '10965', '12015', '13142', '3245', '4833', '3965', '194', '14033', '11467', '4937', '4331', '12046', '10611', '6592', '905', '6705', '5106', '661', '13188', '935', '770', '11076', '4210', '737', '4599', '10267', '1131', '1308', '11139', '10663', '73', '11531', '10052', '3211', '14039', '12080', '1737', '1709', '11309', '3622', '3726', '4026', '14029', '3328', '11484', '11368', '10747', '328', '5164', '475', '243', '3200', '140', '2056', '3988', '1760', '13246', '6580', '173', '4595', '12151', '5016', '24', '468', '11432', '4078', '12028', '309', '150', '3623', '13106', '6541', '1758', '4051', '10055', '6574', '71', '1664', '12347', '6635', '2065', '11287', '4920', '3993', '4526', '11558', '10262', '277', '307', '3470', '126', '679', '4350', '4890', '10063', '765', '4600', '161', '1611', '13223', '10359', '3821', '11392', '12202', '4128', '1640', '12367', '6728', '10715', '3494', '13028', '11429', '6529', '10429', '4654', '10513', '3594', '10446', '4766', '1317', '1792', '11037', '4927', '1672', '11300', '3730', '3335', '4131', '911', '4722', '189', '12258', '13239', '4951', '4413', '4789', '12266', '4069', '4642', '10435', '10460', '13237', '11153', '13012', '4685', '10838', '7611', '311', '6532', '4669', '13086', '4337', '1226', '2080', '6511', '10081', '6593', '1995', '1691', '1111', '11373', '5090', '12042', '10105', '6674', '3822', '5200', '4484', '4205', '5110', '936', '3393', '10167', '1779', '13205', '3235', '13072', '10631', '12223', '4473', '10221', '13009', '11516', '12201', '12317', '10188', '10041', '13155', '10841', '6609', '1126', '5127', '5178', '1399', '10489', '753', '11064', '10158', '187', '220', '11337', '276', '10241', '10397', '10607', '4380', '3925', '10341', '10374', '369', '10779', '348', '10994', '4080', '7627', '10204', '4895', '6598', '11478', '12102', '6518', '10707', '4462', '3430', '13122', '5177', '6176', '10710', '14010', '12344', '10321', '10731', '314', '801', '4363', '4366', '6709', '186', '4167', '55', '12181', '4589', '5146', '14048', '4263', '4776', '4269', '1314', '4153', '10197', '12099', '10705']\n",
      "[0.33684241771698, 0.3368355333805084, 0.33683517575263977, 0.33684036135673523, 0.33683961629867554, 0.33683106303215027, 0.33683934807777405, 0.33683860301971436, 0.33684206008911133, 0.336853563785553, 0.3368395268917084, 0.3368370831012726, 0.33683010935783386, 0.3368396759033203, 0.33683130145072937, 0.3368438482284546, 0.336836576461792, 0.336856484413147, 0.33683669567108154, 0.33683866262435913, 0.33683380484580994, 0.3368348777294159, 0.3368302583694458, 0.3368370234966278, 0.3368358314037323, 0.3368333876132965, 0.3368436098098755, 0.3368297815322876, 0.3368343114852905, 0.33683887124061584, 0.3368343114852905, 0.336846262216568, 0.33683162927627563, 0.33683255314826965, 0.3368380069732666, 0.33683323860168457, 0.3368317484855652, 0.3368353545665741, 0.33685365319252014, 0.3368303179740906, 0.3368321657180786, 0.3368418216705322, 0.33683156967163086, 0.3368326425552368, 0.3368469774723053, 0.3368452489376068, 0.33683449029922485, 0.336847186088562, 0.33684268593788147, 0.33683887124061584, 0.3368341326713562, 0.33683887124061584, 0.33683985471725464, 0.3368438482284546, 0.33685001730918884, 0.33683693408966064, 0.3368566334247589, 0.33683618903160095, 0.3368370831012726, 0.336830198764801, 0.33683106303215027, 0.33683618903160095, 0.3368392884731293, 0.33684098720550537, 0.3368385434150696, 0.3368380069732666, 0.3368431627750397, 0.33683571219444275, 0.3368282616138458, 0.336838036775589, 0.3368435800075531, 0.33683767914772034, 0.33684679865837097, 0.33683669567108154, 0.33683958649635315, 0.3368357717990875, 0.33683648705482483, 0.3368352949619293, 0.33683377504348755, 0.33683550357818604, 0.33683785796165466, 0.33683568239212036, 0.3368401527404785, 0.3368355929851532, 0.33684617280960083, 0.3368275463581085, 0.005112252198159695, 0.33683669567108154, 0.33683744072914124, 0.3368385434150696, 0.004665658343583345, 0.3368473947048187, 0.33683425188064575, 0.3368377089500427, 0.33683860301971436, 0.3368285298347473, 0.3368380069732666, 0.3368362486362457, 0.33683305978775024, 0.3368360996246338, 0.33683204650878906, 0.33682599663734436, 0.33684033155441284, 0.3368375301361084, 0.33685049414634705, 0.3368397355079651, 0.33683255314826965, 0.33684617280960083, 0.33683833479881287, 0.33684876561164856, 0.3368467688560486, 0.3368341624736786, 0.33684518933296204, 0.33684059977531433, 0.33683469891548157, 0.3368384838104248, 0.3368363678455353, 0.33682981133461, 0.3368390202522278, 0.3368428647518158, 0.33684831857681274, 0.3368472456932068, 0.33683550357818604, 0.33683452010154724, 0.3368382155895233, 0.3368337154388428, 0.3368415832519531, 0.3368430435657501, 0.33683037757873535, 0.336835652589798, 0.3368380665779114, 0.33683642745018005, 0.33682751655578613, 0.3368363678455353, 0.33685043454170227, 0.33683887124061584, 0.33683985471725464, 0.3368390202522278, 0.3368337154388428, 0.3368297517299652, 0.3368324339389801, 0.33680975437164307, 0.3368428647518158, 0.33683744072914124, 0.33684059977531433, 0.3368287980556488, 0.04227616265416145, 0.3368377089500427, 0.3368395268917084, 0.3368400037288666, 0.336847722530365, 0.3368479609489441, 0.3368370831012726, 0.3368399739265442, 0.33684098720550537, 0.3368337154388428, 0.3368383049964905, 0.33683550357818604, 0.33684042096138, 0.33684033155441284, 0.3368612229824066, 0.3368356227874756, 0.33682987093925476, 0.3368456959724426, 0.3368336260318756, 0.3368481397628784, 0.3368425667285919, 0.3368333876132965, 0.3368419110774994, 0.33684664964675903, 0.3368338346481323, 0.33683958649635315, 0.33683332800865173, 0.3368442952632904, 0.336831659078598, 0.3368334472179413, 0.33683690428733826, 0.336835652589798, 0.33684247732162476, 0.3368363082408905, 0.33684059977531433, 0.33683449029922485, 0.33683502674102783, 0.33684924244880676, 0.336841344833374, 0.3368353843688965, 0.33684664964675903, 0.33684036135673523, 0.33683067560195923, 0.3368383049964905, 0.33683502674102783, 0.336843341588974, 0.33683934807777405, 0.33683449029922485, 0.3368476927280426, 0.3368428647518158, 0.3368348479270935, 0.3368331789970398, 0.3368412256240845, 0.3368441164493561, 0.336838960647583, 0.33684206008911133, 0.33683866262435913, 0.3368387222290039, 0.33683156967163086, 0.3368406593799591, 0.33683788776397705, 0.33683475852012634, 0.33683961629867554, 0.33682912588119507, 0.3368394076824188, 0.3368363082408905, 0.3368457555770874, 0.33683300018310547, 0.3368400037288666, 0.33684539794921875, 0.33682867884635925, 0.33683305978775024, 0.33684614300727844, 0.33685049414634705, 0.33685004711151123, 0.3368358314037323, 0.33685484528541565, 0.33685237169265747, 0.3368472456932068, 0.33683571219444275, 0.3368447422981262, 0.33683493733406067, 0.33682912588119507, 0.336864709854126, 0.33686262369155884, 0.3368317782878876, 0.3368340730667114, 0.33682897686958313, 0.3368338942527771, 0.33683183789253235, 0.33685824275016785, 0.3368391692638397, 0.3368336260318756, 0.33683595061302185, 0.336841344833374, 0.33683696389198303, 0.33683836460113525, 0.3368440866470337, 0.3368339538574219, 0.33683833479881287, 0.33683478832244873, 0.33683544397354126, 0.33683156967163086, 0.3368352949619293, 0.3368287980556488, 0.3368380069732666, 0.336849182844162, 0.33684220910072327, 0.3368490934371948, 0.3368450701236725, 0.33684030175209045, 0.3368305563926697, 0.3368326425552368, 0.3368341326713562, 0.3368418514728546, 0.3368411660194397, 0.33683350682258606, 0.3368432819843292, 0.3368534743785858, 0.3368346393108368, 0.3368373513221741, 0.3368357717990875, 0.336834192276001, 0.3368474841117859, 0.33684492111206055, 0.33684155344963074, 0.33683302998542786, 0.33683815598487854, 0.3368378281593323, 0.3368402421474457, 0.336838036775589, 0.3368473947048187, 0.3368397653102875, 0.3368377089500427, 0.3368355929851532, 0.3368336260318756, 0.33683106303215027, 0.034747347235679626, 0.336834579706192, 0.33683502674102783, 0.3368368148803711, 0.3368465006351471, 0.33683183789253235, 0.3368327021598816, 0.3368457853794098, 0.33683332800865173, 0.33684036135673523, 0.33684241771698, 0.33683955669403076, 0.336838036775589, 0.3368352949619293, 0.33683571219444275, 0.3368457853794098, 0.33684149384498596, 0.33683541417121887, 0.33683663606643677, 0.3368343710899353, 0.3368435502052307, 0.3368416130542755, 0.336845725774765, 0.33683761954307556, 0.3368488848209381, 0.3368397653102875, 0.33683815598487854, 0.3368358314037323, 0.3368358314037323, 0.3368355631828308, 0.33683621883392334, 0.3368321359157562, 0.33683985471725464, 0.336830735206604, 0.3368387520313263, 0.336834192276001, 0.33683764934539795, 0.33683502674102783, 0.33683791756629944, 0.33684104681015015, 0.33687445521354675, 0.3368489742279053, 0.3368368446826935, 0.3368372917175293, 0.33683475852012634, 0.33685415983200073, 0.3368341326713562, 0.3368418216705322, 0.33683860301971436, 0.33683642745018005, 0.33684226870536804, 0.33683642745018005, 0.3368408977985382, 0.3368434011936188, 0.3368396759033203, 0.3368416130542755, 0.336831271648407, 0.33683711290359497, 0.3368580937385559, 0.3368423581123352, 0.33683210611343384, 0.3368353843688965, 0.3368454575538635, 0.3368358910083771, 0.33683955669403076, 0.33684173226356506, 0.33683958649635315, 0.33683714270591736, 0.33683744072914124, 0.3368455171585083, 0.3368370532989502, 0.3368367552757263, 0.33684492111206055, 0.33684471249580383, 0.3368406891822815, 0.33683183789253235, 0.33684858679771423, 0.336843341588974, 0.33684638142585754, 0.33683276176452637, 0.33684241771698, 0.33684006333351135, 0.3368338346481323, 0.3368358910083771, 0.3368382155895233, 0.336828351020813, 0.33683449029922485, 0.3368441164493561, 0.33685293793678284, 0.3368421196937561, 0.3368469476699829, 0.33683472871780396, 0.33683815598487854, 0.3368434011936188, 0.336847186088562, 0.3368353843688965, 0.3368368446826935, 0.33683648705482483, 0.3368353843688965, 0.3368409276008606, 0.33683571219444275, 0.3368348777294159, 0.3368331789970398, 0.3368455171585083, 0.3368329703807831, 0.3368309736251831, 0.3368426561355591, 0.33683642745018005, 0.3368470370769501, 0.3368331789970398, 0.33683809638023376, 0.33683696389198303, 0.3368391692638397, 0.33683595061302185, 0.336852103471756, 0.3368396461009979, 0.3368370532989502, 0.33683890104293823, 0.3368334472179413, 0.33683887124061584, 0.03078332170844078, 0.33684590458869934, 0.3368317782878876, 0.33684638142585754, 0.33683907985687256, 0.33683279156684875, 0.3368493616580963, 0.33683478832244873, 0.33683204650878906, 0.3368372321128845, 0.336843878030777, 0.33683478832244873, 0.3368418216705322, 0.33683887124061584, 0.3368367552757263, 0.33685562014579773, 0.336840957403183, 0.3368447721004486, 0.33684292435646057, 0.3368339538574219, 0.33684152364730835, 0.3368327021598816, 0.33683955669403076, 0.33683744072914124, 0.3368406295776367, 0.3368331789970398, 0.3368414640426636, 0.3368379473686218, 0.3368400037288666, 0.3368454575538635, 0.3368372917175293, 0.33684685826301575, 0.33683955669403076, 0.33684059977531433, 0.3368348777294159, 0.33683449029922485, 0.33683744072914124, 0.3368411660194397, 0.3368338942527771, 0.3368362486362457, 0.3368508815765381, 0.3368434011936188, 0.3368363082408905, 0.33683642745018005, 0.3368411362171173, 0.3368333876132965, 0.33683982491493225, 0.3368506133556366, 0.3368327021598816, 0.33683472871780396, 0.3368360698223114, 0.33683106303215027, 0.33683809638023376, 0.3368304669857025, 0.3368312418460846, 0.3368390202522278, 0.3368382751941681, 0.3368412256240845, 0.33684757351875305, 0.33683741092681885, 0.3368399441242218, 0.33683517575263977, 0.33683285117149353, 0.336840957403183, 0.3368391692638397, 0.3368377387523651, 0.33684128522872925, 0.3368392884731293, 0.33684617280960083, 0.3368394374847412, 0.3368321359157562, 0.3368474543094635, 0.33683863282203674, 0.33684346079826355, 0.3368355333805084, 0.33684006333351135, 0.3368293046951294, 0.33685383200645447, 0.33683469891548157, 0.33683210611343384, 0.33683300018310547, 0.3368356227874756, 0.33684462308883667, 0.33684346079826355, 0.3368377089500427, 0.3368348777294159, 0.3368384838104248, 0.3368380069732666, 0.33684301376342773, 0.3368380665779114, 0.3368331789970398, 0.33683502674102783, 0.3368382751941681, 0.33683907985687256, 0.33683517575263977, 0.3368385434150696, 0.33684152364730835, 0.3368634879589081, 0.33685368299484253, 0.3368396759033203, 0.3368337154388428, 0.33683183789253235, 0.33682820200920105, 0.3368416726589203, 0.3368475139141083, 0.3368340730667114, 0.3368380069732666, 0.066032275557518, 0.33683204650878906, 0.33684810996055603, 0.336838036775589, 0.33683907985687256, 0.3368319869041443, 0.33684852719306946, 0.3368399739265442, 0.3368437886238098, 0.3368370532989502, 0.3368433117866516, 0.336844801902771, 0.33684423565864563, 0.33683663606643677, 0.3368532061576843, 0.3368358314037323, 0.33685269951820374, 0.3368352949619293, 0.33683326840400696, 0.33683642745018005, 0.33683761954307556, 0.33684247732162476, 0.3368385434150696, 0.33683809638023376, 0.33683469891548157, 0.3368337154388428, 0.3368459939956665, 0.33685582876205444, 0.3368346393108368, 0.3368404805660248, 0.3368397355079651, 0.336831659078598, 0.3368406891822815, 0.33683881163597107, 0.33684128522872925, 0.3368377983570099, 0.33682891726493835, 0.3368352949619293, 0.3368375897407532, 0.33683302998542786, 0.33684074878692627, 0.336839884519577, 0.33685529232025146, 0.3368390202522278, 0.3368341326713562, 0.33683496713638306, 0.3368452489376068, 0.33683404326438904, 0.3368436098098755, 0.3368331789970398, 0.33684173226356506, 0.3368344306945801, 0.3368367552757263, 0.33683544397354126, 0.3368395268917084, 0.33682921528816223, 0.33684593439102173, 0.33684468269348145, 0.3368498384952545, 0.3368349075317383, 0.33683598041534424, 0.33683595061302185, 0.3368394374847412, 0.33683767914772034, 0.33683550357818604, 0.3368430435657501, 0.336842805147171, 0.33684831857681274, 0.3368341624736786, 0.33683595061302185, 0.33684518933296204, 0.33683615922927856, 0.33683523535728455, 0.33683598041534424, 0.33684030175209045, 0.33683937788009644, 0.336836576461792, 0.3368336260318756, 0.3368397355079651, 0.33684200048446655, 0.3368426561355591, 0.3368496894836426, 0.3368418216705322, 0.33683162927627563, 0.33683639764785767, 0.33686065673828125, 0.3368368148803711, 0.3368377089500427, 0.33683285117149353, 0.3368338346481323, 0.3368350863456726, 0.3368402421474457, 0.33683669567108154, 0.3368377983570099, 0.3368299901485443, 0.33685147762298584, 0.3368431329727173, 0.3368373513221741, 0.336841881275177, 0.3368442952632904, 0.3368397355079651, 0.3368527591228485, 0.33684679865837097, 0.336841344833374, 0.33683449029922485, 0.33683279156684875, 0.33683326840400696, 0.33685076236724854, 0.3368414044380188, 0.3368435502052307, 0.008056452497839928, 0.33684128522872925, 0.3368334472179413, 0.33682817220687866, 0.3368348777294159, 0.3368440270423889, 0.33683571219444275, 0.33683475852012634, 0.3368360996246338, 0.3368322551250458, 0.33683449029922485, 0.3368428647518158, 0.33683452010154724, 0.33683106303215027, 0.3368307948112488, 0.3368412256240845, 0.3368357717990875, 0.3368386924266815, 0.33684149384498596, 0.33684349060058594, 0.33683595061302185, 0.33683475852012634, 0.33683860301971436, 0.3368706703186035, 0.3368450403213501, 0.3368411064147949, 0.33683067560195923, 0.3368397355079651, 0.3368343114852905, 0.3368423581123352, 0.33683326840400696, 0.3368436098098755, 0.3368479013442993, 0.3368367552757263, 0.33683744072914124, 0.33683469891548157, 0.3368344306945801, 0.3368534743785858, 0.33684298396110535, 0.33683937788009644, 0.3368440568447113, 0.3368496000766754, 0.3368415832519531, 0.33683300018310547, 0.3368400037288666, 0.33682945370674133, 0.3368431329727173, 0.33682987093925476, 0.33684074878692627, 0.336828351020813, 0.336838036775589, 0.33684444427490234, 0.33684444427490234, 0.33684930205345154, 0.3368348479270935, 0.33684518933296204, 0.33683550357818604, 0.3368362486362457, 0.33682894706726074, 0.33683210611343384, 0.33683690428733826, 0.336841344833374, 0.336834579706192, 0.005194163415580988, 0.3368356227874756, 0.3368319869041443, 0.33683836460113525, 0.3368411958217621, 0.336834192276001, 0.33684399724006653, 0.3368416130542755, 0.33683502674102783, 0.33683809638023376, 0.33683279156684875, 0.3368368148803711, 0.3368353843688965, 0.3368423283100128, 0.3368411958217621, 0.3368355929851532, 0.3368391692638397, 0.3368394076824188, 0.33684873580932617, 0.336842805147171, 0.33683645725250244, 0.33683300018310547, 0.33683696389198303, 0.33683541417121887, 0.3368295133113861, 0.33683186769485474, 0.336843878030777, 0.3368443548679352, 0.3368304967880249, 0.33684903383255005, 0.33683425188064575, 0.33683398365974426, 0.3368379473686218, 0.3368472158908844, 0.33683356642723083, 0.3368383049964905, 0.3368455469608307, 0.33683907985687256, 0.33683520555496216, 0.33683279156684875, 0.33683863282203674, 0.3368317186832428, 0.3368352949619293, 0.3368392288684845, 0.3368368446826935, 0.33683183789253235, 0.33684226870536804, 0.3368375897407532, 0.33684825897216797, 0.33684155344963074, 0.3368435204029083, 0.3368346095085144, 0.33682942390441895, 0.33684301376342773, 0.33683809638023376, 0.33684322237968445, 0.336834192276001, 0.3368394076824188, 0.33683836460113525, 0.33684149384498596, 0.336835116147995, 0.33684241771698, 0.336830198764801, 0.33686399459838867, 0.3368387520313263, 0.3368321657180786, 0.33684876561164856, 0.3368353843688965, 0.004705184604972601, 0.33685019612312317, 0.040513381361961365, 0.33682966232299805, 0.3368375897407532, 0.33684042096138, 0.3368399739265442, 0.3368353843688965, 0.33684197068214417, 0.3368474543094635, 0.3368391692638397, 0.3368355929851532, 0.33684036135673523, 0.33684003353118896, 0.3368355929851532, 0.33683809638023376, 0.3368334472179413, 0.33683279156684875, 0.3368337154388428, 0.3368396759033203, 0.3368392884731293, 0.336838036775589, 0.336830735206604, 0.3368319869041443, 0.3368397355079651, 0.336833655834198, 0.3368338644504547, 0.3368293344974518, 0.33684152364730835, 0.3368324339389801, 0.007300565484911203, 0.33684325218200684, 0.33683884143829346, 0.33684325218200684, 0.3368391692638397, 0.3368355631828308, 0.336860328912735, 0.3368394374847412, 0.33684003353118896, 0.33683884143829346, 0.3368430435657501, 0.3368357717990875, 0.3368358314037323, 0.3368367850780487, 0.33683809638023376, 0.3368373513221741, 0.3368336260318756, 0.3368290364742279, 0.3368437886238098, 0.33683836460113525, 0.3368397653102875, 0.33687445521354675, 0.33684173226356506, 0.33684298396110535, 0.3368428647518158, 0.3368314504623413, 0.33683890104293823, 0.336836576461792, 0.3368377089500427, 0.33683159947395325, 0.33683091402053833, 0.3368368148803711, 0.33684518933296204, 0.3368368446826935, 0.3368331789970398, 0.3368355929851532, 0.3368469178676605, 0.33684390783309937, 0.33684298396110535, 0.33684948086738586, 0.33683955669403076, 0.33683186769485474, 0.33684077858924866, 0.3368285000324249, 0.3368365466594696, 0.33683255314826965, 0.3368455171585083, 0.3368547558784485, 0.3368363082408905, 0.3368484377861023, 0.3368317782878876, 0.3368377387523651, 0.3368482291698456, 0.3368362486362457, 0.3368288576602936, 0.336831271648407, 0.3368321359157562, 0.33683547377586365, 0.33682993054389954, 0.3368380665779114, 0.33683517575263977, 0.33683744072914124, 0.33683523535728455, 0.33684486150741577, 0.33683937788009644, 0.3368423879146576, 0.3368426561355591, 0.3368355631828308, 0.3368378281593323, 0.33683380484580994, 0.3368402123451233, 0.3368406295776367, 0.336835652589798, 0.33683517575263977, 0.33684417605400085, 0.3368428647518158, 0.33684226870536804, 0.3368375301361084, 0.33684372901916504, 0.33685335516929626, 0.3368411064147949, 0.336836576461792, 0.3368390202522278, 0.008455655537545681, 0.3368450403213501, 0.3368450999259949, 0.33683228492736816, 0.3368360996246338, 0.33683377504348755, 0.3368344306945801, 0.3368344306945801, 0.33682820200920105, 0.33684787154197693, 0.3368411958217621, 0.021266592666506767, 0.33684346079826355, 0.33684200048446655, 0.3368324339389801, 0.3368515074253082, 0.3368431627750397, 0.33683454990386963, 0.33683815598487854, 0.33683815598487854, 0.3368532657623291, 0.33684900403022766, 0.33684030175209045, 0.3368493914604187, 0.336834579706192, 0.33684298396110535, 0.3368300497531891, 0.33686012029647827, 0.33683961629867554, 0.33684539794921875, 0.3368426561355591, 0.33683159947395325, 0.3368406295776367, 0.3368367850780487, 0.33683454990386963, 0.3368328809738159, 0.33682912588119507, 0.3368319869041443, 0.3368508219718933, 0.3368329703807831, 0.3368343710899353, 0.3368386924266815, 0.3368363082408905, 0.33682960271835327, 0.3368379473686218, 0.3368452489376068, 0.3368368148803711, 0.33683037757873535, 0.33683809638023376, 0.3368418216705322, 0.3368428647518158, 0.33684447407722473, 0.3368395268917084, 0.33684030175209045, 0.336834192276001, 0.3368372321128845, 0.336834192276001, 0.3368338942527771, 0.33683139085769653, 0.3368428647518158, 0.3368333876132965, 0.33683231472969055, 0.3368324339389801, 0.33684372901916504, 0.33683207631111145, 0.33684241771698, 0.3368392884731293, 0.33683866262435913, 0.33684054017066956, 0.336829274892807, 0.33683833479881287, 0.3368316888809204, 0.336839884519577, 0.33683887124061584, 0.3368329703807831, 0.33684009313583374, 0.33684027194976807, 0.3368567228317261, 0.33683890104293823, 0.33683469891548157, 0.33683502674102783, 0.3368334472179413, 0.3368321359157562, 0.3368378281593323, 0.33682939410209656, 0.3368343114852905, 0.33682841062545776, 0.33684253692626953, 0.3368321657180786, 0.33683839440345764, 0.3368337154388428, 0.33683663606643677, 0.3368360698223114, 0.33683085441589355, 0.3368322551250458, 0.3368298411369324, 0.3368510603904724, 0.3368777632713318, 0.33683526515960693, 0.33683478832244873, 0.336846262216568, 0.336836576461792, 0.3368368446826935, 0.3368382751941681, 0.3368379473686218, 0.33683058619499207, 0.3368421196937561, 0.3368368446826935, 0.33684319257736206, 0.33685413002967834, 0.3368434011936188, 0.3368397355079651, 0.33684593439102173, 0.3368453085422516, 0.3368375599384308, 0.3368384838104248, 0.3368356227874756, 0.33683285117149353, 0.3368447721004486, 0.33684101700782776, 0.3368411362171173, 0.3368293046951294, 0.3368392288684845, 0.33682960271835327, 0.3368377089500427, 0.3368442952632904, 0.3368344306945801, 0.3368385434150696, 0.336841344833374, 0.33684664964675903, 0.3368401527404785, 0.33683696389198303, 0.33686038851737976, 0.33682799339294434, 0.3368362486362457, 0.3368357717990875]\n",
      "BertLargeCovidPooledOutput_0.0_8_2e-05_['WR']_cross_entropy_WR-0.1_exp-2_fold_1_Val-MCC_0.8265072431431403.pth\n",
      "['6742', '10596', '482', '1613', '10549', '1221', '11477', '3394', '12195', '7674', '11270', '1548', '77', '4720', '78', '12237', '363', '4373', '3698', '4027', '339', '10050', '11344', '10019', '11421', '10110', '3677', '74', '103', '4371', '3771', '4947', '287', '10042', '12430', '105', '933', '12210', '11535', '727', '3532', '12165', '1252', '13131', '5095', '6544', '13081', '10807', '4173', '1992', '5130', '10531', '3602', '10960', '1418', '184', '6679', '13059', '13099', '10277', '182', '3732', '484', '3876', '12329', '4703', '10515', '206', '11187', '5008', '6307', '10492', '3562', '14042', '1634', '11267', '10467', '13079', '3347', '10251', '6667', '6713', '10709', '10335', '3469', '244', '3590', '1820', '5039', '6602', '3165', '6700', '11412', '1632', '4597', '10794', '11078', '4663', '2024', '1138', '2012', '858', '6653', '3432', '12341', '5132', '472', '5099', '11274', '3509', '3445', '12074', '3408', '5078', '4508', '12338', '13206', '1239', '6597', '10877', '12382', '11456', '1589', '4955', '3851', '3676', '10347', '10394', '10146', '4750', '4620', '350', '1211', '13225', '3630', '12114', '10333', '690', '241', '12089', '10186', '4052', '12026', '460', '13006', '10583', '3959', '3565', '12306', '4952', '10487', '1806', '4056', '485', '12301', '4180', '488', '5027', '13186', '4604', '12078', '10364', '4452', '11321', '10319', '10452', '12231', '776', '11205', '11226', '10694', '10625', '6311', '13043', '11423', '237', '1621', '247', '4828', '12130', '4203', '5031', '2018', '3679', '12279', '13177', '4557', '1975', '1216', '4499', '2074', '1695', '6309', '256', '12337', '10977', '10162', '10672', '5006', '12168', '10833', '12282', '10092', '3433', '11170', '13220', '10816', '494', '1617', '1247', '10848', '293', '12263', '10053', '10312', '12157', '11372', '11027', '3952', '1439', '11481', '12108', '13054', '3583', '3371', '3994', '11461', '6548', '11303', '4738', '3680', '38', '2028', '67', '4389', '62', '3942', '4984', '10915', '3784', '11522', '1605', '3636', '2087', '2041', '11393', '10070', '1095', '1', '66', '11030', '1461', '3293', '10887', '12120', '3902', '10285', '894', '11174', '1887', '4810', '12321', '5173', '4858', '11005', '10859', '10523', '6506', '10527', '10442', '1646', '10811', '740', '3351', '3451', '10506', '208', '13243', '7629', '10377', '139', '414', '978', '7599', '1818', '474', '12071', '12381', '280', '10222', '12443', '4219', '12372', '4442', '10918', '4231', '2013', '13000', '11272', '3756', '1652', '464', '221', '4161', '11526', '6721', '12303', '3496', '2086', '10800', '14046', '10904', '12088', '12153', '4733', '4096', '10127', '4257', '11253', '13070', '202', '4926', '4578', '4736', '12260', '3874', '4170', '156', '1812', '14', '10736', '3923', '1781', '6654', '2047', '1690', '11465', '10665', '11108', '1127', '441', '2098', '12412', '3660', '11188', '11566', '10115', '6267', '4989', '2039', '4853', '10301', '13010', '10034', '3861', '12434', '5131', '1772', '10875', '4531', '3915', '10357', '1092', '4379', '4585', '11060', '3522', '6305', '10236', '4826', '11486', '5134', '11254', '3169', '3781', '2081', '1596', '1830', '6405', '10613', '6704', '94', '10993', '14038', '10755', '1725', '3571', '5129', '11038', '1684', '5207', '12152', '13133', '10338', '2096', '4502', '3436', '12125', '3266', '10405', '10769', '3506', '2055', '7634', '13015', '12319', '1445', '4295', '323', '6716', '12370', '3425', '308', '4857', '4340', '6610', '1610', '3920', '4074', '4376', '12311', '6660', '3793', '1651', '11403', '13147', '11144', '3336', '4901', '5029', '744', '11442', '12179', '10328', '12428', '10007', '4520', '3439', '11417', '2016', '6172', '10632', '972', '3459', '10860', '4902', '12265', '10562', '11068', '3449', '1437', '4326', '10076', '2093', '1888', '5070', '810', '12017', '4521', '6585', '10818', '4801', '1706', '3153', '11542', '684', '4176', '6748', '5076', '5097', '4962', '6648', '10770', '10792', '12414', '4291', '6680', '1099', '11352', '10219', '3638', '11149', '4421', '3896', '665', '11115', '3625', '11083', '10355', '12027', '10942', '5202', '5136', '10068', '4921', '4628', '4786', '11184', '10950', '4418', '13007', '1841', '10609', '4887', '365', '397', '1624', '12400', '10191', '11554', '4041', '11299', '4964', '149', '4515', '3696', '6744', '12436', '12373', '1615', '3889', '10345', '3611', '13066', '13034', '346', '3655', '12462', '4658', '92', '10815', '4244', '4474', '4409', '1839', '4329', '11152', '3666', '10618', '4146', '10314', '370', '4481', '4749', '3857', '12185', '1124', '5168', '11018', '11134', '3808', '3782', '3271', '5033', '3758', '4878', '4478', '3440', '12416', '10151', '11532', '5166', '4742', '1273', '218', '57', '10696', '10961', '3642', '13199', '167', '10205', '3343', '11462', '4731', '13228', '12342', '11430', '13194', '302', '3159', '10966', '4251', '3424', '4230', '6692', '3877', '1109', '11548', '4934', '4378', '12075', '3922', '1822', '13018', '4121', '306', '1686', '42', '10396', '5101', '12391', '10457', '3749', '292', '4820', '4044', '12449', '10646', '12107', '12357', '13024', '1408', '6392', '11199', '10708', '6594', '12444', '1642', '12215', '3217', '4997', '866', '4087', '4875', '1446', '1122', '768', '10367', '12087', '4399', '12047', '791', '4454', '12446', '3854', '6657', '11483', '3362', '4238', '166', '999', '4235', '3254', '3261', '11256', '10072', '3481', '772', '1774', '10751', '12066', '3690', '1910', '3826', '1094', '12095', '3482', '11087', '4868', '4560', '6629', '4609', '1661', '1620', '732', '12322', '3519', '5012', '70', '10211', '1663', '3747', '6605', '11128', '4538', '736', '10257', '204', '10985', '1593', '11497', '3302', '3596', '11259', '10488', '13144', '10315', '767', '1689', '12285', '11119', '10700', '6576', '4001', '13128', '4716', '6646', '13044', '214', '3825', '11015', '10802', '3714', '12363', '4213', '6549', '1098', '10051', '10926', '4540', '63', '10451', '26', '12250', '3664', '2049', '10358', '3616', '10654', '4522', '10578', '3348', '3810', '10866', '1843', '12192', '11160', '10988', '10881', '12206', '10997', '12290', '6666', '10529', '967', '3985', '5088', '5024', '788', '4747', '3423', '4547', '10706', '6612', '72', '12340', '4652', '10965', '12015', '13142', '3245', '4833', '3965', '194', '14033', '11467', '4937', '4331', '12046', '10611', '6592', '905', '6705', '5106', '661', '13188', '935', '770', '11076', '4210', '737', '4599', '10267', '1131', '1308', '11139', '10663', '73', '11531', '10052', '3211', '14039', '12080', '1737', '1709', '11309', '3622', '3726', '4026', '14029', '3328', '11484', '11368', '10747', '328', '5164', '475', '243', '3200', '140', '2056', '3988', '1760', '13246', '6580', '173', '4595', '12151', '5016', '24', '468', '11432', '4078', '12028', '309', '150', '3623', '13106', '6541', '1758', '4051', '10055', '6574', '71', '1664', '12347', '6635', '2065', '11287', '4920', '3993', '4526', '11558', '10262', '277', '307', '3470', '126', '679', '4350', '4890', '10063', '765', '4600', '161', '1611', '13223', '10359', '3821', '11392', '12202', '4128', '1640', '12367', '6728', '10715', '3494', '13028', '11429', '6529', '10429', '4654', '10513', '3594', '10446', '4766', '1317', '1792', '11037', '4927', '1672', '11300', '3730', '3335', '4131', '911', '4722', '189', '12258', '13239', '4951', '4413', '4789', '12266', '4069', '4642', '10435', '10460', '13237', '11153', '13012', '4685', '10838', '7611', '311', '6532', '4669', '13086', '4337', '1226', '2080', '6511', '10081', '6593', '1995', '1691', '1111', '11373', '5090', '12042', '10105', '6674', '3822', '5200', '4484', '4205', '5110', '936', '3393', '10167', '1779', '13205', '3235', '13072', '10631', '12223', '4473', '10221', '13009', '11516', '12201', '12317', '10188', '10041', '13155', '10841', '6609', '1126', '5127', '5178', '1399', '10489', '753', '11064', '10158', '187', '220', '11337', '276', '10241', '10397', '10607', '4380', '3925', '10341', '10374', '369', '10779', '348', '10994', '4080', '7627', '10204', '4895', '6598', '11478', '12102', '6518', '10707', '4462', '3430', '13122', '5177', '6176', '10710', '14010', '12344', '10321', '10731', '314', '801', '4363', '4366', '6709', '186', '4167', '55', '12181', '4589', '5146', '14048', '4263', '4776', '4269', '1314', '4153', '10197', '12099', '10705']\n",
      "[0.9973952770233154, 0.17558090388774872, 0.0043255360797047615, 0.052201997488737106, 0.11146381497383118, 0.9976428151130676, 0.004212892614305019, 0.9952357411384583, 0.0031275725923478603, 0.016728052869439125, 0.8705130815505981, 0.9963489770889282, 0.9954037666320801, 0.00285095046274364, 0.9964293837547302, 0.1868649274110794, 0.005716838873922825, 0.008031249977648258, 0.35028043389320374, 0.9700294137001038, 0.009166797623038292, 0.019127467647194862, 0.8579841256141663, 0.0020644806791096926, 0.0027763082180172205, 0.7211344242095947, 0.12278249114751816, 0.9954892992973328, 0.9959419369697571, 0.06267935782670975, 0.6236284375190735, 0.9877090454101562, 0.9706358909606934, 0.004151624161750078, 0.0029390447307378054, 0.9970616698265076, 0.997945249080658, 0.003071627812460065, 0.04489539563655853, 0.987171471118927, 0.007478772662580013, 0.011132890358567238, 0.9981630444526672, 0.9970545768737793, 0.009821973741054535, 0.9966545104980469, 0.9956366419792175, 0.02121734619140625, 0.7335220575332642, 0.9374001026153564, 0.0015102005563676357, 0.003077120054513216, 0.007613661698997021, 0.9972493052482605, 0.033126138150691986, 0.9926343560218811, 0.996374785900116, 0.06319073587656021, 0.9922388792037964, 0.9897398948669434, 0.08049396425485611, 0.42733219265937805, 0.007739594671875238, 0.9962795376777649, 0.0034932687412947416, 0.001157818827778101, 0.04764233157038689, 0.9870902895927429, 0.9980771541595459, 0.003516256809234619, 0.003315126756206155, 0.635179340839386, 0.0050843628123402596, 0.9893476963043213, 0.9925244450569153, 0.992652416229248, 0.9945958256721497, 0.9963950514793396, 0.004211788531392813, 0.006539590191096067, 0.9974907636642456, 0.9974721074104309, 0.008287148550152779, 0.9928218722343445, 0.0032535104546695948, 0.9889569878578186, 0.002493726322427392, 0.0028130917344242334, 0.001845611142925918, 0.9923964142799377, 0.0047338251024484634, 0.9909411072731018, 0.002391122281551361, 0.009078823029994965, 0.0023558896500617266, 0.9974857568740845, 0.9953937530517578, 0.00321165076456964, 0.913955807685852, 0.9979458451271057, 0.002812745049595833, 0.9979115128517151, 0.9960160851478577, 0.0026673919055610895, 0.004347768146544695, 0.0026730899699032307, 0.008274974301457405, 0.008869112469255924, 0.010131100192666054, 0.004640557337552309, 0.0034130027052015066, 0.005907732527703047, 0.591953694820404, 0.9943997263908386, 0.00230228784494102, 0.005295845214277506, 0.0034116762690246105, 0.9971470236778259, 0.9957899451255798, 0.0035664530005306005, 0.6378383040428162, 0.0023827925324440002, 0.017960701137781143, 0.002955230651423335, 0.0028887935914099216, 0.8093414306640625, 0.0035712977405637503, 0.00277559831738472, 0.004811231978237629, 0.005202093161642551, 0.0022113441955298185, 0.0027233294676989317, 0.012552229687571526, 0.018269948661327362, 0.008056978695094585, 0.0019525040406733751, 0.0055987900123000145, 0.2248259335756302, 0.9977557063102722, 0.016854440793395042, 0.00498133385553956, 0.0294501855969429, 0.002007311675697565, 0.01572180725634098, 0.996279776096344, 0.995287299156189, 0.017326997593045235, 0.704784631729126, 0.0015192334540188313, 0.033842507749795914, 0.0017523447750136256, 0.002417838666588068, 0.010036233812570572, 0.0023234973195940256, 0.0010886680101975799, 0.996976375579834, 0.0029996505472809076, 0.002584893023595214, 0.019475003704428673, 0.0012370151234790683, 0.013303427956998348, 0.002990988316014409, 0.0021717657800763845, 0.7226994633674622, 0.01664104498922825, 0.49604880809783936, 0.009571538306772709, 0.9946475625038147, 0.9962546825408936, 0.040395960211753845, 0.9030604362487793, 0.0071804882027208805, 0.9968582391738892, 0.0024780204985290766, 0.9973721504211426, 0.4542577862739563, 0.9953213334083557, 0.7286349534988403, 0.02385362982749939, 0.997383177280426, 0.0022285848390311003, 0.002020408632233739, 0.5263042449951172, 0.580391526222229, 0.0016238874522969127, 0.0018561144825071096, 0.0043983375653624535, 0.02938249707221985, 0.06935321539640427, 0.0032068276777863503, 0.47331738471984863, 0.10123173892498016, 0.9972085356712341, 0.02342398092150688, 0.003851773915812373, 0.9977960586547852, 0.8879197835922241, 0.9917901754379272, 0.004516223445534706, 0.7925392389297485, 0.9966423511505127, 0.0016487004468217492, 0.9972972273826599, 0.004978533834218979, 0.997747004032135, 0.9969673752784729, 0.5902319550514221, 0.0031023116316646338, 0.004400426056236029, 0.9973042011260986, 0.04029823839664459, 0.005935098975896835, 0.0037538085598498583, 0.01736714318394661, 0.005525527056306601, 0.995646059513092, 0.9976180195808411, 0.0032629533670842648, 0.012898234650492668, 0.0038234104868024588, 0.007566115818917751, 0.011581188067793846, 0.9941814541816711, 0.004728943575173616, 0.005410939920693636, 0.005215655546635389, 0.003157816594466567, 0.9972890615463257, 0.9978410005569458, 0.994562566280365, 0.058778177946805954, 0.00566325057297945, 0.8745207190513611, 0.9980573058128357, 0.0035075158812105656, 0.9959962368011475, 0.041472263634204865, 0.0022246395237743855, 0.003335457993671298, 0.9976676106452942, 0.002235743682831526, 0.017201511189341545, 0.002753262873739004, 0.9938144683837891, 0.9950892329216003, 0.004053383134305477, 0.9961808919906616, 0.9965968728065491, 0.9979002475738525, 0.7351778149604797, 0.9976068735122681, 0.0024343424011021852, 0.03760441765189171, 0.0034129589330404997, 0.003811375005170703, 0.004146438557654619, 0.0022714463993906975, 0.9685775637626648, 0.5120038986206055, 0.0027252405416220427, 0.00400815112516284, 0.9977295994758606, 0.0025310427881777287, 0.9954727292060852, 0.004284273833036423, 0.11477400362491608, 0.002684140345081687, 0.9972835779190063, 0.0034213103353977203, 0.0020872491877526045, 0.00225605396553874, 0.004205559380352497, 0.9971099495887756, 0.0024513343814760447, 0.0026312069967389107, 0.0021494932007044554, 0.019651245325803757, 0.0032124873250722885, 0.9931215643882751, 0.008438438177108765, 0.003424267517402768, 0.9533262848854065, 0.9976385831832886, 0.028960850089788437, 0.00502849742770195, 0.05069441720843315, 0.0026636854745447636, 0.004092000890523195, 0.014578941278159618, 0.052308715879917145, 0.0025428205262869596, 0.00200251373462379, 0.003486804198473692, 0.0013567719142884016, 0.9965258240699768, 0.0016692359931766987, 0.009260900318622589, 0.0014928117161616683, 0.40237855911254883, 0.04970363900065422, 0.7665826082229614, 0.0031753380317240953, 0.1604059636592865, 0.9970692992210388, 0.00286583392880857, 0.9787911176681519, 0.0014624024042859674, 0.2329064905643463, 0.9935598373413086, 0.008964684791862965, 0.0058414749801158905, 0.2572593092918396, 0.0022636358626186848, 0.9815083146095276, 0.11665096879005432, 0.08252988010644913, 0.9950045943260193, 0.0015070955269038677, 0.9841026663780212, 0.9951367974281311, 0.04215884581208229, 0.8030346035957336, 0.0036129718646407127, 0.010034993290901184, 0.0029619147535413504, 0.0026857415214180946, 0.41035762429237366, 0.005657351575791836, 0.0022069192491471767, 0.7905337810516357, 0.004530592355877161, 0.002561361761763692, 0.9964922070503235, 0.9976959824562073, 0.9969061017036438, 0.00536772096529603, 0.002413735259324312, 0.002895497251302004, 0.017309339717030525, 0.9969452023506165, 0.13742461800575256, 0.003807500936090946, 0.11718040704727173, 0.9972955584526062, 0.10510813444852829, 0.06926566362380981, 0.0023428972344845533, 0.9976263642311096, 0.003673632862046361, 0.9863390922546387, 0.4065992534160614, 0.01234472543001175, 0.5887433290481567, 0.024647070094943047, 0.0036587663926184177, 0.9502125978469849, 0.006379722151905298, 0.019759895280003548, 0.9967495203018188, 0.0029083718545734882, 0.9075183868408203, 0.007941036485135555, 0.9967748522758484, 0.0031585688702762127, 0.0034446646459400654, 0.9977147579193115, 0.3715261220932007, 0.5894676446914673, 0.9971127510070801, 0.7764774560928345, 0.01542262639850378, 0.0033047348260879517, 0.011062698438763618, 0.002972986549139023, 0.9951583743095398, 0.6096357703208923, 0.47706338763237, 0.08724252134561539, 0.9964351654052734, 0.0573083721101284, 0.9965649247169495, 0.23831254243850708, 0.0023316137958317995, 0.9928205609321594, 0.983445942401886, 0.0016811297973617911, 0.0033953306265175343, 0.0046948459930717945, 0.039260245859622955, 0.8309582471847534, 0.002809192519634962, 0.1607130765914917, 0.0021710919681936502, 0.0016906872624531388, 0.9845916032791138, 0.0013951894361525774, 0.002506018616259098, 0.0034267790615558624, 0.005094578023999929, 0.003550783032551408, 0.5956325531005859, 0.005886543542146683, 0.9954916834831238, 0.014367257244884968, 0.010504771955311298, 0.002765761688351631, 0.9970466494560242, 0.003975017461925745, 0.04187306389212608, 0.9948683977127075, 0.6716482043266296, 0.9969207048416138, 0.013722273521125317, 0.8313369750976562, 0.003956515807658434, 0.9933993816375732, 0.0030310596339404583, 0.012105373665690422, 0.005256711505353451, 0.003629835322499275, 0.0033036323729902506, 0.9924620985984802, 0.9821169972419739, 0.013834348879754543, 0.03489987924695015, 0.00316220847889781, 0.0035193811636418104, 0.9963045120239258, 0.8735785484313965, 0.016912342980504036, 0.9963029623031616, 0.5668193101882935, 0.004545988515019417, 0.01936836540699005, 0.7989773154258728, 0.00578283378854394, 0.001277037663385272, 0.022412870079278946, 0.003526959102600813, 0.002527660923078656, 0.011899162083864212, 0.9957701563835144, 0.1901056319475174, 0.004322756547480822, 0.03432995453476906, 0.0923805832862854, 0.012119786813855171, 0.15616418421268463, 0.9975408315658569, 0.003830441739410162, 0.004611666314303875, 0.004564313217997551, 0.006885195150971413, 0.9641804695129395, 0.021533219143748283, 0.0023088918533176184, 0.908210277557373, 0.8869931101799011, 0.0013101171934977174, 0.9961589574813843, 0.011036384850740433, 0.007115217857062817, 0.20881599187850952, 0.9938830137252808, 0.0030304212123155594, 0.9976176619529724, 0.01576775312423706, 0.9975534081459045, 0.0025989681016653776, 0.00511916633695364, 0.6598119735717773, 0.9968836903572083, 0.5201822519302368, 0.0020739755127578974, 0.0037295666988939047, 0.0017987106693908572, 0.9968720078468323, 0.9975312948226929, 0.997334361076355, 0.017353883013129234, 0.010924506932497025, 0.0028264792636036873, 0.04651223495602608, 0.0338861420750618, 0.0024170842953026295, 0.0024387850426137447, 0.0026288158260285854, 0.9980930685997009, 0.011977163143455982, 0.25854381918907166, 0.007216494996100664, 0.001750216819345951, 0.001640194095671177, 0.002405146835371852, 0.013370001688599586, 0.0014200980076566339, 0.1488226056098938, 0.8803603053092957, 0.9972947239875793, 0.0012629583943635225, 0.9916208982467651, 0.004835677333176136, 0.969242513179779, 0.0022746247705072165, 0.01617998629808426, 0.9978299736976624, 0.005090159364044666, 0.003367129247635603, 0.002783676842227578, 0.0026147307362407446, 0.0367245189845562, 0.9980873465538025, 0.985112726688385, 0.9967219233512878, 0.0018783584237098694, 0.06638093292713165, 0.9969474673271179, 0.017229748889803886, 0.01656755991280079, 0.1357322335243225, 0.33519938588142395, 0.003286914201453328, 0.0033973227255046368, 0.9959141612052917, 0.00340304896235466, 0.41835394501686096, 0.0021725075785070658, 0.02714850753545761, 0.006405116990208626, 0.3570025861263275, 0.06486541777849197, 0.0019093714654445648, 0.00451225321739912, 0.002082407008856535, 0.001990075223147869, 0.004266305360943079, 0.99199378490448, 0.003922683652490377, 0.01385892927646637, 0.011793454177677631, 0.0029971771873533726, 0.12053924798965454, 0.0034588496200740337, 0.002627213252708316, 0.009582732804119587, 0.03754420951008797, 0.9977312684059143, 0.005246404092758894, 0.08839308470487595, 0.9981302618980408, 0.9954419136047363, 0.8274853825569153, 0.006382566876709461, 0.002490018727257848, 0.013308431021869183, 0.030283642932772636, 0.03138887882232666, 0.004308229777961969, 0.06226072832942009, 0.002202857518568635, 0.005653275642544031, 0.002247592667117715, 0.9906041026115417, 0.9966313242912292, 0.00449391221627593, 0.9961453676223755, 0.0023089710157364607, 0.04003855213522911, 0.013338088057935238, 0.0022082512732595205, 0.01622975617647171, 0.7370079159736633, 0.5263277292251587, 0.0032165669836103916, 0.002156677655875683, 0.9961036443710327, 0.19165147840976715, 0.0026984119322150946, 0.00215705344453454, 0.9966562986373901, 0.007280990481376648, 0.43889862298965454, 0.0032539479434490204, 0.0036050141789019108, 0.0017669002991169691, 0.9960052371025085, 0.8675233125686646, 0.9975800514221191, 0.9967970252037048, 0.03823506087064743, 0.01045863889157772, 0.0021180936601012945, 0.004376720637083054, 0.9948753714561462, 0.9957516193389893, 0.0037228174041956663, 0.996619701385498, 0.22027646005153656, 0.9279100894927979, 0.002663168590515852, 0.0052684033289551735, 0.033103134483098984, 0.03245628997683525, 0.6295573115348816, 0.9976703524589539, 0.004675793461501598, 0.012637711130082607, 0.0020375698804855347, 0.9955659508705139, 0.99510657787323, 0.0012605733936652541, 0.9977093935012817, 0.0033599811140447855, 0.9946028590202332, 0.006301058456301689, 0.9948223829269409, 0.9966057538986206, 0.019055675715208054, 0.0025544685777276754, 0.011971701867878437, 0.009802209213376045, 0.003523046849295497, 0.9974594712257385, 0.001449541188776493, 0.9954593777656555, 0.004175723064690828, 0.9978887438774109, 0.5294104814529419, 0.003993634134531021, 0.00694369338452816, 0.06473305076360703, 0.002504925709217787, 0.998004138469696, 0.003070871578529477, 0.1735648661851883, 0.026201380416750908, 0.9975989460945129, 0.005187360104173422, 0.0045027658343315125, 0.002365079475566745, 0.05259346589446068, 0.997506320476532, 0.002067708410322666, 0.0059692091308534145, 0.007037252653390169, 0.007083461154252291, 0.009598948061466217, 0.996604323387146, 0.6566134095191956, 0.0032878124620765448, 0.9907275438308716, 0.0059976717457175255, 0.04402158036828041, 0.9977951049804688, 0.0032562841661274433, 0.9979002475738525, 0.005932938773185015, 0.012923496775329113, 0.04177264869213104, 0.0029793947469443083, 0.005755010526627302, 0.9973556995391846, 0.0014088824391365051, 0.995094895362854, 0.9962819218635559, 0.9974393844604492, 0.9380218982696533, 0.003410541219636798, 0.002179923467338085, 0.9974774718284607, 0.0030829005409032106, 0.8213596940040588, 0.010422139428555965, 0.9974651336669922, 0.9969093203544617, 0.9972871541976929, 0.014601117931306362, 0.09378625452518463, 0.8500007390975952, 0.9975288510322571, 0.9721094965934753, 0.02188791334629059, 0.9946133494377136, 0.0031711000483483076, 0.9977496266365051, 0.011169943027198315, 0.00297341076657176, 0.002513969549909234, 0.9810121059417725, 0.18115107715129852, 0.0015129792736843228, 0.1622725874185562, 0.8364754915237427, 0.8585983514785767, 0.6506299376487732, 0.0054999967105686665, 0.0015990532701835036, 0.9972597360610962, 0.0030037902761250734, 0.015505889430642128, 0.003470266703516245, 0.030035853385925293, 0.9967300891876221, 0.02299194596707821, 0.12600181996822357, 0.0019073589937761426, 0.9977579712867737, 0.9325997829437256, 0.00343157141469419, 0.9957605004310608, 0.002433107467368245, 0.9961205124855042, 0.012154473923146725, 0.9151767492294312, 0.015122927725315094, 0.0025282897986471653, 0.9953703284263611, 0.002690604655072093, 0.0026137810200452805, 0.023220127448439598, 0.0029760864563286304, 0.8347002267837524, 0.26923638582229614, 0.004072440322488546, 0.0024313649628311396, 0.0021560911554843187, 0.9891875386238098, 0.038890447467565536, 0.9975242018699646, 0.9978952407836914, 0.003946651238948107, 0.010684696957468987, 0.0014404522953554988, 0.9968652129173279, 0.08753224462270737, 0.9965040683746338, 0.01984150893986225, 0.002813962521031499, 0.0033345497213304043, 0.9972469806671143, 0.0026768147945404053, 0.008630181662738323, 0.008576637133955956, 0.9956336617469788, 0.9969428181648254, 0.9957118034362793, 0.9928551316261292, 0.001290207845158875, 0.04109765961766243, 0.002347485860809684, 0.0035327558871358633, 0.0035043044481426477, 0.005024569109082222, 0.01580103673040867, 0.9609580039978027, 0.9091819524765015, 0.0015890207141637802, 0.9977522492408752, 0.017521735280752182, 0.0018436417449265718, 0.13844819366931915, 0.995876133441925, 0.9980913996696472, 0.9974870681762695, 0.005105885211378336, 0.09730410575866699, 0.10443957895040512, 0.9958387613296509, 0.9957568049430847, 0.9969486594200134, 0.0029361825436353683, 0.05227591469883919, 0.0014876831555739045, 0.9976078271865845, 0.9971178770065308, 0.9964368343353271, 0.6556471586227417, 0.8914008736610413, 0.9958360195159912, 0.003715209662914276, 0.14567254483699799, 0.0024672409053891897, 0.9978516101837158, 0.004351736977696419, 0.021013643592596054, 0.0022246395237743855, 0.9980950951576233, 0.0033761183731257915, 0.03627017140388489, 0.0072572072967886925, 0.9922096729278564, 0.9922634363174438, 0.005341922864317894, 0.04781216382980347, 0.002614253433421254, 0.04313913360238075, 0.0020658790599554777, 0.003697601379826665, 0.21565821766853333, 0.0034955202136188745, 0.0022879817988723516, 0.9973838925361633, 0.8630879521369934, 0.006207378581166267, 0.002645528642460704, 0.9980758428573608, 0.002080992329865694, 0.04124220460653305, 0.0027140856254845858, 0.002818336011841893, 0.8174471259117126, 0.7432053089141846, 0.13317111134529114, 0.004746526479721069, 0.14768792688846588, 0.9975128173828125, 0.0026450948789715767, 0.005201708059757948, 0.9355413317680359, 0.995231568813324, 0.3356063961982727, 0.020063987001776695, 0.9854889512062073, 0.9976810216903687, 0.9981244206428528, 0.07070741802453995, 0.1953318566083908, 0.9973125457763672, 0.997225821018219, 0.003649241290986538, 0.7240164875984192, 0.012441394850611687, 0.003803120693191886, 0.002402203856036067, 0.9186962246894836, 0.9048641324043274, 0.9963411688804626, 0.002632704097777605, 0.9974492192268372, 0.9964463114738464, 0.0014399545034393668, 0.00221489486284554, 0.9970268607139587, 0.9860127568244934, 0.0024530861992388964, 0.4196002185344696, 0.37921902537345886, 0.0169950183480978, 0.009051606059074402, 0.0033433912321925163, 0.9650793671607971, 0.01683780923485756, 0.9969678521156311, 0.9829985499382019, 0.25679776072502136, 0.9849164485931396, 0.8822487592697144, 0.0015961492899805307, 0.4714476764202118, 0.0583825521171093, 0.013089953921735287, 0.5245393514633179, 0.001371301244944334, 0.0023194728419184685, 0.0057157548144459724, 0.0073980470187962055, 0.013993668369948864, 0.9973672032356262, 0.0023520218674093485, 0.9980373978614807, 0.004581925459206104, 0.17881785333156586, 0.9978047013282776, 0.9863242506980896, 0.992975115776062, 0.009947716258466244, 0.996444046497345, 0.0023837722837924957, 0.9978463649749756, 0.0030878554098308086, 0.002829367760568857, 0.02124016359448433, 0.0017362978542223573, 0.004477642010897398, 0.036671679466962814, 0.004541757050901651, 0.0011302053462713957, 0.010776619426906109, 0.12299232929944992, 0.006198386661708355, 0.9972357153892517, 0.0026686429046094418, 0.0009464722243137658, 0.01286652684211731, 0.9961820244789124, 0.007354049943387508, 0.9977154731750488, 0.0013600696111097932, 0.9897639751434326, 0.005188917741179466, 0.9968383312225342, 0.9979948997497559, 0.19040082395076752, 0.06316235661506653, 0.9963986873626709, 0.5331244468688965, 0.9969883561134338, 0.8486246466636658, 0.46757885813713074, 0.02486327476799488, 0.06178851053118706, 0.0036238764878362417, 0.9940669536590576, 0.008850269950926304, 0.0014286857331171632, 0.008031371049582958, 0.0013503098161891103, 0.0018707339186221361, 0.9971978664398193, 0.9817773699760437, 0.9969404935836792, 0.1267538070678711, 0.984355092048645, 0.0090758902952075, 0.9943820834159851, 0.0024937880225479603, 0.9952309727668762, 0.015491192229092121, 0.015222537331283092, 0.003849624888971448, 0.006158020813018084, 0.025238975882530212, 0.0036171746905893087, 0.02606557123363018, 0.010478025302290916, 0.6207801103591919, 0.01543374452739954, 0.9973264932632446, 0.9952060580253601, 0.001550770364701748, 0.014656794257462025, 0.006209549494087696, 0.9942348599433899, 0.0222227293998003, 0.002268176758661866, 0.003435438498854637, 0.027040082961320877, 0.9901729822158813, 0.997052788734436, 0.9971612691879272, 0.024388134479522705, 0.004091622307896614, 0.954215407371521, 0.011180071160197258, 0.0031994981691241264, 0.0026663723401725292, 0.023768454790115356, 0.0121707608923316, 0.003160056658089161, 0.9946163296699524, 0.013656006194651127, 0.009434368461370468, 0.018982168287038803, 0.8424616456031799, 0.005072891246527433, 0.9942863583564758, 0.9813562631607056, 0.0024712979793548584, 0.9963933825492859, 0.9139565825462341, 0.0024371964391320944, 0.0029212115332484245, 0.008745516650378704, 0.002788215409964323, 0.9977986216545105, 0.002682178048416972, 0.004219701513648033, 0.9963654279708862, 0.8789698481559753, 0.011518547311425209, 0.7292444109916687, 0.052411165088415146, 0.001941645867191255, 0.010249167680740356, 0.9980347752571106, 0.9976592063903809, 0.00417446019127965, 0.9954786896705627, 0.0020162900909781456, 0.0044729639776051044, 0.002549568424001336, 0.0020315535366535187, 0.004940066020935774, 0.9837800860404968, 0.0012476019328460097, 0.9046540260314941, 0.011399869807064533, 0.0031481035985052586, 0.002983522368595004, 0.9962312579154968]\n",
      "BertLargeCovidPooledOutput_0.0_8_2e-05_['WR']_cross_entropy_WR-0.1_exp-3_fold_1_Val-MCC_0.8106992380860406.pth\n",
      "['6742', '10596', '482', '1613', '10549', '1221', '11477', '3394', '12195', '7674', '11270', '1548', '77', '4720', '78', '12237', '363', '4373', '3698', '4027', '339', '10050', '11344', '10019', '11421', '10110', '3677', '74', '103', '4371', '3771', '4947', '287', '10042', '12430', '105', '933', '12210', '11535', '727', '3532', '12165', '1252', '13131', '5095', '6544', '13081', '10807', '4173', '1992', '5130', '10531', '3602', '10960', '1418', '184', '6679', '13059', '13099', '10277', '182', '3732', '484', '3876', '12329', '4703', '10515', '206', '11187', '5008', '6307', '10492', '3562', '14042', '1634', '11267', '10467', '13079', '3347', '10251', '6667', '6713', '10709', '10335', '3469', '244', '3590', '1820', '5039', '6602', '3165', '6700', '11412', '1632', '4597', '10794', '11078', '4663', '2024', '1138', '2012', '858', '6653', '3432', '12341', '5132', '472', '5099', '11274', '3509', '3445', '12074', '3408', '5078', '4508', '12338', '13206', '1239', '6597', '10877', '12382', '11456', '1589', '4955', '3851', '3676', '10347', '10394', '10146', '4750', '4620', '350', '1211', '13225', '3630', '12114', '10333', '690', '241', '12089', '10186', '4052', '12026', '460', '13006', '10583', '3959', '3565', '12306', '4952', '10487', '1806', '4056', '485', '12301', '4180', '488', '5027', '13186', '4604', '12078', '10364', '4452', '11321', '10319', '10452', '12231', '776', '11205', '11226', '10694', '10625', '6311', '13043', '11423', '237', '1621', '247', '4828', '12130', '4203', '5031', '2018', '3679', '12279', '13177', '4557', '1975', '1216', '4499', '2074', '1695', '6309', '256', '12337', '10977', '10162', '10672', '5006', '12168', '10833', '12282', '10092', '3433', '11170', '13220', '10816', '494', '1617', '1247', '10848', '293', '12263', '10053', '10312', '12157', '11372', '11027', '3952', '1439', '11481', '12108', '13054', '3583', '3371', '3994', '11461', '6548', '11303', '4738', '3680', '38', '2028', '67', '4389', '62', '3942', '4984', '10915', '3784', '11522', '1605', '3636', '2087', '2041', '11393', '10070', '1095', '1', '66', '11030', '1461', '3293', '10887', '12120', '3902', '10285', '894', '11174', '1887', '4810', '12321', '5173', '4858', '11005', '10859', '10523', '6506', '10527', '10442', '1646', '10811', '740', '3351', '3451', '10506', '208', '13243', '7629', '10377', '139', '414', '978', '7599', '1818', '474', '12071', '12381', '280', '10222', '12443', '4219', '12372', '4442', '10918', '4231', '2013', '13000', '11272', '3756', '1652', '464', '221', '4161', '11526', '6721', '12303', '3496', '2086', '10800', '14046', '10904', '12088', '12153', '4733', '4096', '10127', '4257', '11253', '13070', '202', '4926', '4578', '4736', '12260', '3874', '4170', '156', '1812', '14', '10736', '3923', '1781', '6654', '2047', '1690', '11465', '10665', '11108', '1127', '441', '2098', '12412', '3660', '11188', '11566', '10115', '6267', '4989', '2039', '4853', '10301', '13010', '10034', '3861', '12434', '5131', '1772', '10875', '4531', '3915', '10357', '1092', '4379', '4585', '11060', '3522', '6305', '10236', '4826', '11486', '5134', '11254', '3169', '3781', '2081', '1596', '1830', '6405', '10613', '6704', '94', '10993', '14038', '10755', '1725', '3571', '5129', '11038', '1684', '5207', '12152', '13133', '10338', '2096', '4502', '3436', '12125', '3266', '10405', '10769', '3506', '2055', '7634', '13015', '12319', '1445', '4295', '323', '6716', '12370', '3425', '308', '4857', '4340', '6610', '1610', '3920', '4074', '4376', '12311', '6660', '3793', '1651', '11403', '13147', '11144', '3336', '4901', '5029', '744', '11442', '12179', '10328', '12428', '10007', '4520', '3439', '11417', '2016', '6172', '10632', '972', '3459', '10860', '4902', '12265', '10562', '11068', '3449', '1437', '4326', '10076', '2093', '1888', '5070', '810', '12017', '4521', '6585', '10818', '4801', '1706', '3153', '11542', '684', '4176', '6748', '5076', '5097', '4962', '6648', '10770', '10792', '12414', '4291', '6680', '1099', '11352', '10219', '3638', '11149', '4421', '3896', '665', '11115', '3625', '11083', '10355', '12027', '10942', '5202', '5136', '10068', '4921', '4628', '4786', '11184', '10950', '4418', '13007', '1841', '10609', '4887', '365', '397', '1624', '12400', '10191', '11554', '4041', '11299', '4964', '149', '4515', '3696', '6744', '12436', '12373', '1615', '3889', '10345', '3611', '13066', '13034', '346', '3655', '12462', '4658', '92', '10815', '4244', '4474', '4409', '1839', '4329', '11152', '3666', '10618', '4146', '10314', '370', '4481', '4749', '3857', '12185', '1124', '5168', '11018', '11134', '3808', '3782', '3271', '5033', '3758', '4878', '4478', '3440', '12416', '10151', '11532', '5166', '4742', '1273', '218', '57', '10696', '10961', '3642', '13199', '167', '10205', '3343', '11462', '4731', '13228', '12342', '11430', '13194', '302', '3159', '10966', '4251', '3424', '4230', '6692', '3877', '1109', '11548', '4934', '4378', '12075', '3922', '1822', '13018', '4121', '306', '1686', '42', '10396', '5101', '12391', '10457', '3749', '292', '4820', '4044', '12449', '10646', '12107', '12357', '13024', '1408', '6392', '11199', '10708', '6594', '12444', '1642', '12215', '3217', '4997', '866', '4087', '4875', '1446', '1122', '768', '10367', '12087', '4399', '12047', '791', '4454', '12446', '3854', '6657', '11483', '3362', '4238', '166', '999', '4235', '3254', '3261', '11256', '10072', '3481', '772', '1774', '10751', '12066', '3690', '1910', '3826', '1094', '12095', '3482', '11087', '4868', '4560', '6629', '4609', '1661', '1620', '732', '12322', '3519', '5012', '70', '10211', '1663', '3747', '6605', '11128', '4538', '736', '10257', '204', '10985', '1593', '11497', '3302', '3596', '11259', '10488', '13144', '10315', '767', '1689', '12285', '11119', '10700', '6576', '4001', '13128', '4716', '6646', '13044', '214', '3825', '11015', '10802', '3714', '12363', '4213', '6549', '1098', '10051', '10926', '4540', '63', '10451', '26', '12250', '3664', '2049', '10358', '3616', '10654', '4522', '10578', '3348', '3810', '10866', '1843', '12192', '11160', '10988', '10881', '12206', '10997', '12290', '6666', '10529', '967', '3985', '5088', '5024', '788', '4747', '3423', '4547', '10706', '6612', '72', '12340', '4652', '10965', '12015', '13142', '3245', '4833', '3965', '194', '14033', '11467', '4937', '4331', '12046', '10611', '6592', '905', '6705', '5106', '661', '13188', '935', '770', '11076', '4210', '737', '4599', '10267', '1131', '1308', '11139', '10663', '73', '11531', '10052', '3211', '14039', '12080', '1737', '1709', '11309', '3622', '3726', '4026', '14029', '3328', '11484', '11368', '10747', '328', '5164', '475', '243', '3200', '140', '2056', '3988', '1760', '13246', '6580', '173', '4595', '12151', '5016', '24', '468', '11432', '4078', '12028', '309', '150', '3623', '13106', '6541', '1758', '4051', '10055', '6574', '71', '1664', '12347', '6635', '2065', '11287', '4920', '3993', '4526', '11558', '10262', '277', '307', '3470', '126', '679', '4350', '4890', '10063', '765', '4600', '161', '1611', '13223', '10359', '3821', '11392', '12202', '4128', '1640', '12367', '6728', '10715', '3494', '13028', '11429', '6529', '10429', '4654', '10513', '3594', '10446', '4766', '1317', '1792', '11037', '4927', '1672', '11300', '3730', '3335', '4131', '911', '4722', '189', '12258', '13239', '4951', '4413', '4789', '12266', '4069', '4642', '10435', '10460', '13237', '11153', '13012', '4685', '10838', '7611', '311', '6532', '4669', '13086', '4337', '1226', '2080', '6511', '10081', '6593', '1995', '1691', '1111', '11373', '5090', '12042', '10105', '6674', '3822', '5200', '4484', '4205', '5110', '936', '3393', '10167', '1779', '13205', '3235', '13072', '10631', '12223', '4473', '10221', '13009', '11516', '12201', '12317', '10188', '10041', '13155', '10841', '6609', '1126', '5127', '5178', '1399', '10489', '753', '11064', '10158', '187', '220', '11337', '276', '10241', '10397', '10607', '4380', '3925', '10341', '10374', '369', '10779', '348', '10994', '4080', '7627', '10204', '4895', '6598', '11478', '12102', '6518', '10707', '4462', '3430', '13122', '5177', '6176', '10710', '14010', '12344', '10321', '10731', '314', '801', '4363', '4366', '6709', '186', '4167', '55', '12181', '4589', '5146', '14048', '4263', '4776', '4269', '1314', '4153', '10197', '12099', '10705']\n",
      "[0.9951713681221008, 0.39245903491973877, 0.007297152187675238, 0.0024387710727751255, 0.4422149956226349, 0.9966398477554321, 0.0036431646440178156, 0.9972090125083923, 0.0017551247728988528, 0.022797733545303345, 0.5739408135414124, 0.9974314570426941, 0.997868537902832, 0.001831760280765593, 0.9972743391990662, 0.04886026307940483, 0.0037689018063247204, 0.0029479616787284613, 0.28471633791923523, 0.775986909866333, 0.022616347298026085, 0.01619170978665352, 0.877799928188324, 0.0013385351048782468, 0.001558904186822474, 0.442859947681427, 0.081205353140831, 0.9974797368049622, 0.9978160858154297, 0.8573703765869141, 0.4123024344444275, 0.9979721903800964, 0.9244371652603149, 0.0024872443173080683, 0.0021942483726888895, 0.997582197189331, 0.9973602890968323, 0.0017236006679013371, 0.008485114201903343, 0.9897955060005188, 0.007346636150032282, 0.008245150558650494, 0.9975717663764954, 0.9957656860351562, 0.0025847649667412043, 0.9976102113723755, 0.9975593090057373, 0.027442455291748047, 0.26373544335365295, 0.786635160446167, 0.0009713438339531422, 0.0034727524034678936, 0.0013821871252730489, 0.9975916147232056, 0.006054098252207041, 0.9980366826057434, 0.9960599541664124, 0.004406580701470375, 0.9897676110267639, 0.0735904648900032, 0.026507047936320305, 0.027513941749930382, 0.002177937189117074, 0.9971926808357239, 0.0039948709309101105, 0.001272047171369195, 0.0072891018353402615, 0.9732252359390259, 0.997309684753418, 0.0036317692138254642, 0.004083570092916489, 0.1727680265903473, 0.001961825881153345, 0.9043931365013123, 0.9815968871116638, 0.9732891917228699, 0.9060678482055664, 0.9969960451126099, 0.001392569625750184, 0.013914203271269798, 0.9984142780303955, 0.9980483055114746, 0.004153470043092966, 0.9393608570098877, 0.0033346987329423428, 0.4092189073562622, 0.0020821315702050924, 0.0011584130115807056, 0.001411567209288478, 0.9974365830421448, 0.0023734932765364647, 0.991905927658081, 0.0021543477196246386, 0.002035511424764991, 0.0013363799080252647, 0.9975104331970215, 0.9982494115829468, 0.0008335126913152635, 0.5032146573066711, 0.9974562525749207, 0.002005691407248378, 0.996961772441864, 0.9974684715270996, 0.0012052026577293873, 0.001030592480674386, 0.0029423257801681757, 0.0037246872670948505, 0.0026458357460796833, 0.04799313470721245, 0.0030251978896558285, 0.0012690084986388683, 0.000886482885107398, 0.16771750152111053, 0.9965667724609375, 0.0009754053317010403, 0.0052056703716516495, 0.0021435662638396025, 0.9960824251174927, 0.9982789754867554, 0.0017231060191988945, 0.0407620407640934, 0.0026395118329674006, 0.08577510714530945, 0.0023573562502861023, 0.002847850788384676, 0.9872482419013977, 0.002718118019402027, 0.0028275884687900543, 0.004190413746982813, 0.0025286024902015924, 0.001314110471867025, 0.002069854410365224, 0.003072769846767187, 0.015547612681984901, 0.001195032149553299, 0.0015540444292128086, 0.003908861428499222, 0.040069013833999634, 0.9976561069488525, 0.003611133899539709, 0.002405208768323064, 0.08309285342693329, 0.001923242351040244, 0.0025256816297769547, 0.9977518916130066, 0.9948866963386536, 0.013264640234410763, 0.5574896931648254, 0.0018685065442696214, 0.015397570095956326, 0.0021446538157761097, 0.0015799971297383308, 0.010767964646220207, 0.001714717480354011, 0.001121352193877101, 0.9972495436668396, 0.001588997314684093, 0.0024571456015110016, 0.00794297456741333, 0.0012092365650460124, 0.01127066370099783, 0.0018616555025801063, 0.0012457205448299646, 0.3793988525867462, 0.033333975821733475, 0.2445983737707138, 0.00953555479645729, 0.9651614427566528, 0.9976661205291748, 0.007339028641581535, 0.8700053095817566, 0.008903023786842823, 0.995779275894165, 0.0056510139256715775, 0.996435284614563, 0.9946033358573914, 0.9973228573799133, 0.9927728772163391, 0.35542619228363037, 0.9974499344825745, 0.0025357636623084545, 0.002196855843067169, 0.20171742141246796, 0.5621904730796814, 0.0020509925670921803, 0.0015468730125576258, 0.003675781888887286, 0.0028042334597557783, 0.18116670846939087, 0.0008176324190571904, 0.7665649652481079, 0.14027047157287598, 0.9956923127174377, 0.08593320101499557, 0.0026336759328842163, 0.9968230724334717, 0.9828141927719116, 0.9650951623916626, 0.0012086153728887439, 0.8767746686935425, 0.9954100251197815, 0.0014794060261920094, 0.9834616184234619, 0.002141882199794054, 0.9972545504570007, 0.9977436065673828, 0.2853962182998657, 0.0036594762932509184, 0.0031945258378982544, 0.9973688125610352, 0.023476334288716316, 0.0024112241808325052, 0.001122834743000567, 0.0015985759673640132, 0.0033457677345722914, 0.9919439554214478, 0.9960982799530029, 0.0026863894890993834, 0.010487097315490246, 0.0029417690820991993, 0.004304643254727125, 0.009218860417604446, 0.9975932240486145, 0.0014146940084174275, 0.0008570983191020787, 0.019210180267691612, 0.0020885358098894358, 0.99699866771698, 0.9962049126625061, 0.9883822798728943, 0.06940412521362305, 0.002829554956406355, 0.7962260842323303, 0.9977014660835266, 0.001973025733605027, 0.9975663423538208, 0.02959788590669632, 0.0019666035659611225, 0.0018768840236589313, 0.9973913431167603, 0.0014545246958732605, 0.019460240378975868, 0.0020032504107803106, 0.9898965358734131, 0.9978623986244202, 0.002470147330313921, 0.9775475263595581, 0.9928239583969116, 0.99727863073349, 0.032619260251522064, 0.9960153698921204, 0.005044073797762394, 0.008099080063402653, 0.0049230782315135, 0.002781531773507595, 0.003099918132647872, 0.005550035275518894, 0.9964861869812012, 0.15846779942512512, 0.00126487179659307, 0.004240870010107756, 0.9980267882347107, 0.005707927979528904, 0.9979557991027832, 0.005795447621494532, 0.040601812303066254, 0.001102432026527822, 0.9977594614028931, 0.001749552902765572, 0.0015721875242888927, 0.0015690050786361098, 0.002676383126527071, 0.9954407215118408, 0.0016749262576922774, 0.0011016583302989602, 0.0010879227193072438, 0.01828262209892273, 0.004495243541896343, 0.9981118440628052, 0.004661185666918755, 0.005157990846782923, 0.994612455368042, 0.9972232580184937, 0.03113739751279354, 0.0022585887927562, 0.004220894072204828, 0.0012195928720757365, 0.0011651187669485807, 0.001856854883953929, 0.012821140699088573, 0.0015601805644109845, 0.0015352710615843534, 0.00398790230974555, 0.0009509148076176643, 0.9954420328140259, 0.0021932944655418396, 0.008582104928791523, 0.0011550714261829853, 0.06488899886608124, 0.2416236251592636, 0.15632815659046173, 0.0023516719229519367, 0.009893705137073994, 0.99689781665802, 0.003780102590098977, 0.9952126741409302, 0.0018463131273165345, 0.04488518461585045, 0.997657299041748, 0.006816180422902107, 0.002758038230240345, 0.11365161836147308, 0.0019255357328802347, 0.9891267418861389, 0.016552867367863655, 0.36463621258735657, 0.9975323677062988, 0.0015215990133583546, 0.9302894473075867, 0.9965611100196838, 0.3133787512779236, 0.8938524723052979, 0.0027162819169461727, 0.002628335729241371, 0.0014891551109030843, 0.0019137985073029995, 0.7135215997695923, 0.003332705469802022, 0.0023742318153381348, 0.37461337447166443, 0.001763812149874866, 0.00480866152793169, 0.9978269934654236, 0.9979967474937439, 0.9979647397994995, 0.003450024640187621, 0.00153174321167171, 0.0018313733162358403, 0.01872776448726654, 0.9958980679512024, 0.008706744760274887, 0.003276185365393758, 0.004946290981024504, 0.998193085193634, 0.12394603341817856, 0.01185524370521307, 0.0019339729333296418, 0.9972621202468872, 0.010376667603850365, 0.9940412640571594, 0.1324455440044403, 0.014143520966172218, 0.9239370226860046, 0.009824627079069614, 0.003267343621701002, 0.913258969783783, 0.003209264250472188, 0.00601353170350194, 0.9963790774345398, 0.0030153850093483925, 0.94237220287323, 0.0063823009841144085, 0.9967750906944275, 0.0023317812010645866, 0.0044278353452682495, 0.9975384473800659, 0.08291470259428024, 0.8603241443634033, 0.9975449442863464, 0.776595950126648, 0.004381672944873571, 0.0023465401027351618, 0.00944664515554905, 0.001428575487807393, 0.9775676727294922, 0.7411943674087524, 0.448106050491333, 0.035983990877866745, 0.9979791045188904, 0.0029102584812790155, 0.9983166456222534, 0.04746704548597336, 0.0014645548071712255, 0.99727863073349, 0.8889749646186829, 0.0013893706491217017, 0.004785746335983276, 0.003055930370464921, 0.007968784309923649, 0.49429085850715637, 0.0022449444513767958, 0.48038116097450256, 0.0020571062341332436, 0.0013919464545324445, 0.9865091443061829, 0.0018759898375719786, 0.0030614573042839766, 0.007512347772717476, 0.0020995549857616425, 0.001411676057614386, 0.28500282764434814, 0.0029859417118132114, 0.9942460656166077, 0.016367612406611443, 0.013373241759836674, 0.002445642603561282, 0.9974154233932495, 0.0018125000642612576, 0.027847476303577423, 0.9981796741485596, 0.952424168586731, 0.998005211353302, 0.006351088639348745, 0.2679581642150879, 0.0044648959301412106, 0.9977153539657593, 0.0015567042864859104, 0.005123079754412174, 0.0028633426409214735, 0.002090024994686246, 0.0022058591712266207, 0.9979943037033081, 0.9955998659133911, 0.005062404088675976, 0.0023231778759509325, 0.0020981947891414165, 0.0019355373224243522, 0.9974573254585266, 0.03268345072865486, 0.0066175078973174095, 0.9975887537002563, 0.024073626846075058, 0.00503012677654624, 0.0036236820742487907, 0.8646251559257507, 0.0034778707195073366, 0.006039181258529425, 0.014759249985218048, 0.0047705634497106075, 0.0014631316298618913, 0.00801274087280035, 0.9979889392852783, 0.12371935695409775, 0.001214363845065236, 0.005136449821293354, 0.011087714694440365, 0.0164093729108572, 0.11353999376296997, 0.9973884224891663, 0.0012742298422381282, 0.0034478334710001945, 0.0015820272965356708, 0.004601569380611181, 0.945098876953125, 0.045871421694755554, 0.001000827644020319, 0.9858304858207703, 0.977916419506073, 0.0009089272934943438, 0.9976524710655212, 0.034115877002477646, 0.004774567671120167, 0.08238282799720764, 0.9923422932624817, 0.002165926853194833, 0.9922325611114502, 0.011682824231684208, 0.9962904453277588, 0.0034288265742361546, 0.002073158510029316, 0.658545732498169, 0.9980708956718445, 0.20099106431007385, 0.001068405108526349, 0.001055484521202743, 0.001282691489905119, 0.9970813393592834, 0.997141420841217, 0.9959138035774231, 0.00983915664255619, 0.00917014665901661, 0.0018743753898888826, 0.01012990903109312, 0.0066946931183338165, 0.001459975610487163, 0.004836971405893564, 0.0011874529300257564, 0.9975093603134155, 0.0020384970121085644, 0.026075158268213272, 0.002006834140047431, 0.0016334039391949773, 0.002613823162391782, 0.0013037614990025759, 0.005457183346152306, 0.0014812519075348973, 0.23561324179172516, 0.2280307114124298, 0.9981105327606201, 0.0015279358485713601, 0.998121440410614, 0.0033338209614157677, 0.9512863159179688, 0.0011092906352132559, 0.014281900599598885, 0.9970932006835938, 0.0030464704614132643, 0.005295290146023035, 0.0011940672993659973, 0.0013376347487792373, 0.013846208341419697, 0.9964061379432678, 0.8051518201828003, 0.9971926808357239, 0.0021597081795334816, 0.03836280107498169, 0.9984681010246277, 0.012501838617026806, 0.010272828862071037, 0.0043001556769013405, 0.49484941363334656, 0.003604541067034006, 0.001992190023884177, 0.9729571342468262, 0.00596169289201498, 0.18013055622577667, 0.001762024941854179, 0.1707943081855774, 0.0012023808667436242, 0.07484672963619232, 0.047107994556427, 0.0017735856818035245, 0.00375191168859601, 0.0014008136931806803, 0.0013319883728399873, 0.00313927186653018, 0.9943680167198181, 0.00500642741099, 0.00842243805527687, 0.028878722339868546, 0.001315633300691843, 0.4131034016609192, 0.0021260343492031097, 0.001544293249025941, 0.013534306548535824, 0.0036517789121717215, 0.9974114298820496, 0.0026021443773061037, 0.9790971875190735, 0.9976303577423096, 0.9961645603179932, 0.2363595962524414, 0.001285824691876769, 0.003536927979439497, 0.002852600533515215, 0.01872899755835533, 0.015552463941276073, 0.006131269037723541, 0.010441552847623825, 0.0021079708822071552, 0.002592236502096057, 0.00231418339535594, 0.9847242832183838, 0.9933011531829834, 0.0038069277070462704, 0.9976367950439453, 0.00238440721295774, 0.032815542072057724, 0.005204413086175919, 0.002472306601703167, 0.002896794816479087, 0.008091846480965614, 0.7727518081665039, 0.0035713573452085257, 0.0014011065941303968, 0.9979637861251831, 0.021601557731628418, 0.004568689037114382, 0.0017423416720703244, 0.9969009160995483, 0.001352196908555925, 0.9596865773200989, 0.0010576703352853656, 0.0021774573251605034, 0.0012112724361941218, 0.996616542339325, 0.9435752034187317, 0.9973819851875305, 0.9977222084999084, 0.0849100649356842, 0.001271171378903091, 0.004469283390790224, 0.0042130048386752605, 0.9981108903884888, 0.9974616765975952, 0.005652504041790962, 0.9966874718666077, 0.18490412831306458, 0.9973053932189941, 0.0012724106200039387, 0.004142972640693188, 0.014378956519067287, 0.014995825476944447, 0.26100954413414, 0.9973689317703247, 0.0018127916846424341, 0.0123842628672719, 0.001902119372971356, 0.99718177318573, 0.9472092390060425, 0.0022529982961714268, 0.9966456294059753, 0.0019943376537412405, 0.8789441585540771, 0.006293291691690683, 0.9964985847473145, 0.9973798394203186, 0.0021164696663618088, 0.0025264108553528786, 0.003233447903767228, 0.0015917221317067742, 0.0017863594694063067, 0.9957365989685059, 0.004049169365316629, 0.9968298077583313, 0.0028925335500389338, 0.9975810050964355, 0.26080843806266785, 0.0016414826968684793, 0.0030143747571855783, 0.0021908620838075876, 0.0016361612360924482, 0.9971523284912109, 0.0010617418447509408, 0.4399808347225189, 0.05235900729894638, 0.9977516531944275, 0.005346064455807209, 0.0009784838184714317, 0.0013418339658528566, 0.007384168915450573, 0.9980770349502563, 0.0009528456721454859, 0.005151838064193726, 0.0012189616682007909, 0.0015060179866850376, 0.0018606845987960696, 0.9966931343078613, 0.2293781340122223, 0.0016799058066681027, 0.9809344410896301, 0.009362706914544106, 0.04523925110697746, 0.9975504279136658, 0.0026699379086494446, 0.997372031211853, 0.0031798433046787977, 0.004226412624120712, 0.007511178497225046, 0.001981025794520974, 0.002693246817216277, 0.9977113008499146, 0.001281915814615786, 0.9952307343482971, 0.9980706572532654, 0.9974967837333679, 0.3190293312072754, 0.0013864032225683331, 0.0025602728128433228, 0.9976323843002319, 0.0020585712045431137, 0.15299543738365173, 0.027845479547977448, 0.9902523756027222, 0.9981299042701721, 0.9936347007751465, 0.008800707757472992, 0.0037082761991769075, 0.9086250066757202, 0.9978445768356323, 0.5881580114364624, 0.06135449931025505, 0.9641003012657166, 0.002292474964633584, 0.996450662612915, 0.004234236665070057, 0.0024750507436692715, 0.0037135013844817877, 0.8066970705986023, 0.06540921330451965, 0.002438592491671443, 0.41578027606010437, 0.9126567840576172, 0.6942551732063293, 0.516718327999115, 0.0033412978518754244, 0.0008680028258822858, 0.9979968667030334, 0.0021072840318083763, 0.006259150803089142, 0.010054034180939198, 0.06726871430873871, 0.9978997707366943, 0.01668231002986431, 0.00880074966698885, 0.0021578767336905003, 0.9958679676055908, 0.9860365986824036, 0.0017687238287180662, 0.9940747618675232, 0.00579946581274271, 0.9975153207778931, 0.005925814155489206, 0.9598038792610168, 0.0039423140697181225, 0.0015841035638004541, 0.9964602589607239, 0.0033710200805217028, 0.0031660948880016804, 0.00535998772829771, 0.0062525165267288685, 0.9661026000976562, 0.9220529198646545, 0.003012347500771284, 0.004104959312826395, 0.001208778703585267, 0.9896525740623474, 0.027366111055016518, 0.9975878000259399, 0.9976357221603394, 0.0028467215597629547, 0.010700898244976997, 0.0014687805669382215, 0.9983071088790894, 0.004609860945492983, 0.994572103023529, 0.012197274714708328, 0.0018455346580594778, 0.007694092113524675, 0.9944944977760315, 0.001291328459046781, 0.006416181568056345, 0.004722103476524353, 0.998173713684082, 0.9949826002120972, 0.9977890253067017, 0.992293119430542, 0.0018444773741066456, 0.004370009992271662, 0.002170567400753498, 0.00423036003485322, 0.0011510738404467702, 0.0015783777926117182, 0.013025694526731968, 0.9797663688659668, 0.4861096739768982, 0.0013488688273355365, 0.9976180195808411, 0.005853203125298023, 0.0014020403614267707, 0.014449121430516243, 0.9981983304023743, 0.9978241920471191, 0.9983867406845093, 0.005618317984044552, 0.013703875243663788, 0.042915645986795425, 0.9961346387863159, 0.9966363906860352, 0.9970560073852539, 0.0015544675989076495, 0.31417933106422424, 0.0011255028657615185, 0.9953030347824097, 0.9973293542861938, 0.9981354475021362, 0.25372156500816345, 0.9907406568527222, 0.9977657794952393, 0.0022136529441922903, 0.0015319488011300564, 0.0015974384732544422, 0.9980126619338989, 0.0024266832042485476, 0.003365118522197008, 0.0019666035659611225, 0.9972345232963562, 0.0017812508158385754, 0.042080171406269073, 0.025295676663517952, 0.9970280528068542, 0.9883586168289185, 0.006245268043130636, 0.06182520464062691, 0.0014409723225980997, 0.003147557144984603, 0.003025745740160346, 0.001965839881449938, 0.026291364803910255, 0.002173256129026413, 0.0016467096284031868, 0.9956185221672058, 0.31497514247894287, 0.0026114960201084614, 0.0022407379001379013, 0.9974626302719116, 0.0015152113046497107, 0.002779320115223527, 0.0014051320031285286, 0.0016066249227151275, 0.8268406987190247, 0.8553184866905212, 0.017393503338098526, 0.00296690221875906, 0.32627618312835693, 0.9957467913627625, 0.002728233113884926, 0.0018972785910591483, 0.9978330731391907, 0.9858888983726501, 0.4075900614261627, 0.02350027486681938, 0.9852109551429749, 0.9981277585029602, 0.9978094696998596, 0.003713844111189246, 0.09202829748392105, 0.9973648190498352, 0.9969004392623901, 0.0017233300022780895, 0.8194620013237, 0.01581253670156002, 0.0010784879559651017, 0.007225460838526487, 0.952543318271637, 0.29021140933036804, 0.9976577758789062, 0.0024330737069249153, 0.9957320094108582, 0.9942837357521057, 0.0014755390584468842, 0.0014988319016993046, 0.9975479245185852, 0.9908958077430725, 0.0017590406350791454, 0.18342939019203186, 0.004956275690346956, 0.016124486923217773, 0.003159061074256897, 0.0049948422238230705, 0.9926416277885437, 0.002063175430521369, 0.9487408399581909, 0.8877827525138855, 0.9803053140640259, 0.977784276008606, 0.9470488429069519, 0.001028556260280311, 0.0789635181427002, 0.04731713980436325, 0.012066476978361607, 0.08487012982368469, 0.0009158453904092312, 0.0019624216947704554, 0.0011773876613005996, 0.002245033159852028, 0.004473178181797266, 0.9976792931556702, 0.002112120622768998, 0.9976328611373901, 0.003760142717510462, 0.0757051408290863, 0.9957109689712524, 0.919110119342804, 0.9979889392852783, 0.014303907752037048, 0.979885995388031, 0.0023474344052374363, 0.9978412389755249, 0.0021621068008244038, 0.0017388137057423592, 0.004555119201540947, 0.0023327909875661135, 0.003199417609721422, 0.0059293294325470924, 0.002600837731733918, 0.0010599979432299733, 0.003987470641732216, 0.0042361910454928875, 0.0033892306964844465, 0.9971592426300049, 0.004676694516092539, 0.0015104329213500023, 0.016769498586654663, 0.9977039694786072, 0.0049606189131736755, 0.9982484579086304, 0.0020799865014851093, 0.9936780333518982, 0.002972706686705351, 0.9956763386726379, 0.998318076133728, 0.05999824404716492, 0.016355732455849648, 0.9975852966308594, 0.11898931860923767, 0.9976761937141418, 0.9768617749214172, 0.06341695040464401, 0.01699375919997692, 0.025372928008437157, 0.002878231694921851, 0.9982309937477112, 0.0025985415559262037, 0.0044050454162061214, 0.005554245784878731, 0.0014080408727750182, 0.0017311653355136514, 0.995790958404541, 0.9562497138977051, 0.9974543452262878, 0.00996358785778284, 0.571746289730072, 0.004512878600507975, 0.9942125678062439, 0.0016319240676239133, 0.9879932403564453, 0.003225191729143262, 0.004191580228507519, 0.0028281519189476967, 0.0024790093302726746, 0.011755581013858318, 0.001671923091635108, 0.0059872702695429325, 0.010930510237812996, 0.951889157295227, 0.028980543836951256, 0.9883167147636414, 0.9975364208221436, 0.0014705201610922813, 0.01263166218996048, 0.00374020216986537, 0.9959568381309509, 0.005725950468331575, 0.0010842563351616263, 0.0029176457319408655, 0.004919061902910471, 0.9928244352340698, 0.9968230724334717, 0.9977098703384399, 0.008830265142023563, 0.0017707700608298182, 0.9017775654792786, 0.012793295085430145, 0.0046963877975940704, 0.003061284078285098, 0.0077581084333360195, 0.003103282069787383, 0.003382839262485504, 0.9173759818077087, 0.008589204400777817, 0.00424055615440011, 0.0429815798997879, 0.9659753441810608, 0.0012589877005666494, 0.9982573390007019, 0.9932489395141602, 0.0017658652504906058, 0.9933162331581116, 0.979866087436676, 0.0017997357062995434, 0.0015829644398763776, 0.00808779802173376, 0.008114888332784176, 0.9973728656768799, 0.002410368761047721, 0.010955499485135078, 0.9978261590003967, 0.7189509868621826, 0.004229601006954908, 0.08375471085309982, 0.019369972869753838, 0.004058490972965956, 0.003024527570232749, 0.9974284768104553, 0.997204601764679, 0.0015654579037800431, 0.9977777600288391, 0.00120719731785357, 0.002658839337527752, 0.0018056923290714622, 0.0011301763588562608, 0.001724917208775878, 0.6569638252258301, 0.0008929574978537858, 0.9363308548927307, 0.013572781346738338, 0.011016168631613255, 0.002321656560525298, 0.9981107711791992]\n",
      "[{'id': '4263', 'category': 'CRITICAL'}, {'id': '4776', 'category': 'CONSPIRACY'}, {'id': '4269', 'category': 'CRITICAL'}, {'id': '1314', 'category': 'CONSPIRACY'}, {'id': '4153', 'category': 'CRITICAL'}, {'id': '10197', 'category': 'CRITICAL'}, {'id': '12099', 'category': 'CRITICAL'}, {'id': '10705', 'category': 'CONSPIRACY'}]\n",
      "[1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#### Bucle cargando todos los modelos BASELINE\n",
    "baseline_test_outputs = []\n",
    "device = torch.device(f\"cuda:{cuda_device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Filtramos los modelos que queremos evaluar\n",
    "modelos = os.listdir(\"/home/inaki/host_data/checkpoints/Ensemble_baseline/\")\n",
    "modelos = [m for m in modelos if m.startswith(\"BertLargeCovidPooledOutput_0.0_8_2e-05_['WR']_cross_entropy\")]\n",
    "# modelos = [m for m in modelos if m.startswith(GROUP)]\n",
    "\n",
    "MODEL_NAME = \"BertLargeCovidPooledOutput\"\n",
    "\n",
    "for model_path in modelos[0:5]:\n",
    "    print(model_path)\n",
    "    ModelClass = getattr(models, MODEL_NAME)\n",
    "    model = ModelClass(dropout_prob=HEAD_DROPOUT)\n",
    "    # Load the saved state dictionary into the initialized model\n",
    "    \n",
    "    state_dict = torch.load('/home/inaki/host_data/checkpoints/Ensemble_baseline/' + model_path)\n",
    "    # Remove the 'module.' prefix from keys if present (esto es por ser un modelo paralelizado)\n",
    "    if 'module.' in list(state_dict.keys())[0]:\n",
    "        state_dict = {key[7:]: value for key, value in state_dict.items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    if torch.cuda.device_count() > 2:\n",
    "        model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model.to(device)\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    all_ids = []\n",
    "    all_pred = []\n",
    "    for input_ids, attention_mask, id in test_unlabelled_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        # concadenamos las ids como una lista\n",
    "        all_ids += list(id)\n",
    "        with torch.no_grad():\n",
    "            embb, outputs = model(input_ids, attention_mask)\n",
    "            pred = torch.sigmoid(outputs).cpu().numpy()\n",
    "            # concadenamos las predicciones como una lista\n",
    "            all_pred += [p[0] for p in pred.tolist()]\n",
    "\n",
    "    print(all_ids)\n",
    "    print(all_pred)\n",
    "    baseline_test_outputs += [all_pred]\n",
    "\n",
    "submission = []\n",
    "baseline_test_outputs = np.mean(baseline_test_outputs, axis=0)\n",
    "all_pred = np.round(baseline_test_outputs)\n",
    "for id_, pred_ in zip(all_ids, all_pred):\n",
    "    submission.append({\"id\":f\"{id_}\", \"category\":\"CRITICAL\" if pred_ < 0.5 else \"CONSPIRACY\" })\n",
    "\n",
    "print(submission)\n",
    "print(all_pred)\n",
    "# save the submission as json file",
    "with open('/home/inaki/host_data/submissions/submission.json', 'w') as f:",
    "json.dump(submission, f)",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcc</th>\n",
       "      <th>low</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.873522</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mcc   low    up\n",
       "104  0.873522  0.49  0.55\n",
       "15   0.873522  0.41  0.54\n",
       "16   0.873522  0.41  0.55\n",
       "103  0.873522  0.49  0.54\n",
       "92   0.873522  0.48  0.54\n",
       "93   0.873522  0.48  0.55\n",
       "27   0.873522  0.42  0.55\n",
       "26   0.873522  0.42  0.54\n",
       "81   0.873522  0.47  0.54\n",
       "82   0.873522  0.47  0.55\n",
       "37   0.873522  0.43  0.54\n",
       "38   0.873522  0.43  0.55\n",
       "71   0.873522  0.46  0.55\n",
       "70   0.873522  0.46  0.54\n",
       "48   0.873522  0.44  0.54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGdCAYAAADNHANuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACbDklEQVR4nOzdd3hUVf7H8fe5U9ITAoTQQleaNEGQYsdFWZFdewXL4urqrsIWxa67K+u6sqyKov5EdBXFghVsYFcQBRFQpHdIIKS3Kfee3x+TREKSSYZkTuLm+3qe+ygzd2Y+mblz7/eec+4ZpbXWCCGEEEI0MaupAwghhBBCgBQlQgghhGgmpCgRQgghRLMgRYkQQgghmgUpSoQQQgjRLEhRIoQQQohmQYoSIYQQQjQLUpQIIYQQollwN3WAxuA4Dnv37iUpKQmlVFPHEUII0YxprSksLKRjx45YVvTOzcvKyvD7/Y3yXF6vl9jY2EZ5rubsf6Io2bt3LxkZGU0dQwghxM/Irl276Ny5c1Seu6ysjO5dE8ncbzfK87Vv355t27b9zxcm/xNFSVJSEhDawJKTk5s4jRBCiOasoKCAjIyMymNHNPj9fjL322xb2ZXkpIa1xhQUOnQfugO/3y9Fyc9BRZdNcnKyFCVCCCHqxUR3f3KS1eCipCX5nyhKhBBCiObI1g52A3/21tZO44T5GZCiRAghhIgSB41Dw6qShj7+50SKEiGEECJKHBwa2s7R8Gf4+ZCOLiGEEEI0C9JSIoQQQkSJrTW2blj3S0Mf/3MiRYkQQggRJTKmJDLSfSOEEEKIZkFaSoQQQogocdDY0lJSb1KUlLODNt9+uI6cfbmktm/FsacNwOV2NVkex9F8991O9u/PJyUlnmOP7YbX23Qfl9aa77/fw549OSQmxjJsWHdiYjxNmmfDj/vYuesgcbFehg7rRnx8TJPlAdiyJYstW/YT43Vz7NBuJCXFNWmeHTuy2bhhH26PiyFDutGqVXyT5tm7J5fvf9iDy1IMGNiFtLTozaZZH/v3F7B27S601hxzTGfat2/VpHlycopYvXontu3Qp08HMjLaNGme/PwSvv12BwF/kF5Htad797QmzVNUVMbKldvx+QJ065bG0Ue3b9I89SXdN5E5oqPc7NmzeeCBB8jMzGTQoEE8/PDDDB8+vNb18/LyuO2221i4cCE5OTl07dqVWbNmMX78+CN+zsb0yUtf8ujUeeTsy628LTU9hWtnXsGpF48xkuFQX321hVn/fpf9+wsqb0tKiuU3U07mrLOGGM+z5rudPPjgO+zenVN5W3y8l8svH8P5Fww3/iOIGzdm8s9/vs22rQcqb4uJcXPhhcdz+aQxWJbZPDt2ZHP//W+z4cd9lbd5PC4mTjyWKdecgttwcZuVmc8/7n+bNd/trLzN5bI444yB3PD7040Xtzk5xTzwwCJWfLWl8jalFKee2o+bpo4zXkwWFpYy88F3+OyzDRw6fnDUqKP405/Hk5JitngrLfXz8EPv88EH63CcnwIdO7Qbf/nLWcaLN78/yJw5S1n09mqCwZ8uRe3fvxO33DKBjp1SjeaxbYen537Kq69+jd8frLy911Hp3HzzWfTo0c5oHhFdSuvIhvUuWLCASZMmMWfOHEaMGMGsWbN4+eWX2bBhA+3aVd84/H4/o0ePpl27dtx666106tSJHTt20KpVKwYNGnREz3m4goICUlJSyM/Pj3ia+U9fWcZfL5hZ6/23zr+JUy4aHdFzNsTKldu4+S8LAE1Nn8yNN47j7InHGsuzfv0ebrrxeWzboaZN5corT+Syy829P9u3Z3P97+bh9wer7MArnHvecfzud2ON5cnKzOe3186luMhXLY9ScNrYY5g+fYKxPHl5JVwz5Sny8oqxD5tG0rIUw47rwX33nW+skCwu9nHddU+TuS+vxjx9+3Zk5r8vNVa4+f1B/vD7Z9myZX+1z8uyFF26tGH2o1cQG2umFdC2Hf7y5xdZs2ZntTwulyItLZk5j19prNVNa80997zG54cVbBB6f5KT43j8iato29ZcoTRz5jssXrS6xjxxcV4em3MFnTq1jug5G3LMiPQ1Nq5PJ6mB08wXFjoc3Tcrqnmbi4jfqZkzZzJlyhSuvPJK+vXrx5w5c4iPj2fu3Lk1rj937lxycnJ4/fXXGT16NN26deOkk06qLEiO5Dkbi23bPDbtmbDrzPnjM9h24/zKY1201jz26FJqK0gAnnzyI8rKAkbyAPzfk5/gODUXJAD//e8X5OeXGMvz7DOfEQjUXJAAvPrK12Rm5hnL8+KLy2osSAC0hiUfrGPz5ixjeRa++jW5udULEgh1Ca74agurV++s4ZHR8c7i79i7J7fWPN9/v4cvvthkLM/HH69n06asGj8vx9Fs357NkiXrjOVZsWILq1fvqDGPbWuysgp4661vjeX54Yc9fPZp9YIEQu9PQUEpr7y8wlienTsPsujt6gVJRZ6yMj/PP/+lsTxHwmmkpaWIqCjx+/2sXLmSsWN/OhO1LIuxY8eybNmyGh/z5ptvMnLkSK6//nrS09M55phjuO+++yoP9EfynD6fj4KCgirLkVj3+Y9k7z4Ydp2cfbl89/EPR/T8kdq+PZtt2w7UWpAAlJT4Wb58s5E8Bw4U1rrDrGDbNp9+8qORPCUlPj77bEONB7gKlqVYuuR7I3kcR/Pee2vDvj8ul8X77681kgfgnXe+qyOPMp4n3PZsWYp3311jMM+asK1ESoUKKVPef29t2O5GrTWLF5nL88H763C5aj8sOI7mnXfMfV4ffLAOl6v298e2NUuX/EAgYObEUURfREVJdnY2tm2Tnp5e5fb09HQyMzNrfMzWrVt55ZVXsG2bxYsXc8cdd/Dggw/yt7/97Yifc8aMGaSkpFQuGRkZkfwZlXLreUZd3/UaKienqM51lKrfeo0hN7e4znUsyyInp+71GkNhQVnYA24ojzKWx+cL4PMFw66jtSbXUB6A/PzSsPfbtubgQTPbD1DnZ+E4moPZhYbSwMHswlpb/SDUupWdbe79yc4uqnObrs/3sLHk5BRj2+HPy4uKyupcp/HyFAHhuxqDQZviYp+RPEfCLr/6pqFLSxH1eUocx6Fdu3Y88cQTDB06lAsvvJDbbruNOXPmHPFzTp8+nfz8/Mpl165dR/Q8bTrWrx+ybYT9lUeqTZu6+2m1xlh/bps2iXWu4ziOsTzJKXFhz5pCebSxPDExHuLiwo89UEoZ7X9PTQ0/SNPlsowOnGzbNvw2ZFmKdu3M9ZG3a5cctmVCKUW7duben3btkrHq2Kbreg8bU5u2iXV+x5KT48K2pjSmtm2TwhaRAF6vi4SEpr3yLhxbN87SUkS0ZbVt2xaXy0VWVtU+8qysLNq3r/nyrA4dOnD00Ufjcv00kK1v375kZmbi9/uP6DljYmJITk6ushyJ/qN7k94tjVpbcxWkZbThmBP6HNHzR6pbt7YcdVR62OblxMQYjj++l5E8bdokMnRYt7A7cbfbxUknm3l/4uK8nHRS37A7Ta1h7On9jeSxLMUZZwwM+/7YtsO4cQOM5AH45S8H1yPPQGN5xo8fHPZ+x9GcOX5Q2HUa05njB4VtmdBaM/6Xg43lOePMgThhjjhKqTrfw8Y0btyAOrtHf2nw/fnFL46pszty7OnH4PE03fQNdZExJZGJqCjxer0MHTqUpUuXVt7mOA5Lly5l5MiRNT5m9OjRbN68Gcf56W3duHEjHTp0wOv1HtFzNhbLsrj+P1cBqnphUv7v6/9zVZWCKtp+97uxWFYNecpdd91Yo5d0TpkSuqS1tgPdVVefRGJirLE8k684gdhYb615Lrr4eNLSzJ15X3TxSFJS4mstlM46azDdDM7v8KtfD6Ndu+Qa8yilOOHE3gwY0NlYnjPOHEj37mk1fl6WpRg8pKuxIhvgpJP60L9/p1rzHHV0e047zUxRCzB0aHeGj+hZ44mIZSk6dUrlrAnmpgHo06cjY8f2r3H/43IpWrdO5NzzjjOWp1On1pxz7rAa77MsRXxCDJddau7qPxF9EbfBTZs2jSeffJJnnnmG9evXc91111FcXMyVV14JwKRJk5g+fXrl+tdddx05OTnceOONbNy4kUWLFnHfffdx/fXX1/s5o2nkhGH89c2bad+96piW9t3acc9rf2H0r8zMlVJh4KAu/POBi6pNnNSmTSK33nY2Z5xp7iwX4Kij2vPvWZdWmwsgJSWem24axwUXjDCap3Pn1jz08CT69O1Y5fbExBh++9tTufrqk4zmads2iYcfmcTAgV2q3B4X5+HySaP5w43jjOZJTo7joYcncdxxPavc7vW6Ofe847j99olG55WJi/My89+XcuKJfaq8rtvtYvz4Qdx33/nGugIqXvf+f17EL34xoMrrulyheVP+9a+LjRb9lqW4555zmPirY6uc7SsVmjflPw9dbrxr4i83n8VFF40kJqbq+3Dssd15ZPYkUlMTjOa57rqxXHXVicTHe6vcfswxnXn44Umkt08xmidSDgq7gYtTx7ia/yURz1MC8Mgjj1ROdDZ48GAeeughRowIHZxOPvlkunXrxrx58yrXX7ZsGVOnTmX16tV06tSJq6++mptvvrlKC0S456xLY1xzrrVm/fKNHNybS+sOqfQ9/igsq+l+GkhrzcaNmWRlhWZ0PeaYzkZ33jXZsiWLvXvySEyMYcDADOOTgh1u+/Zsdu08SFych4GDujTpjLcAe/bksG3rATxeNwMHZhAX5637QVGUlZnPpk2ZuD0uBgzIaPJ+9+zsQn78cR+Wpejfv5PxScoOl5dXwg/f70Gj6du3E61bmz3YHq6wsJR163Zj25revdsbbfGrSUmJj7VrdhEI2PTo2Y6OHc1OmnY4ny/AmjW78JUF6Nq1LRldjnzGW5PzlHzzfTqJDZynpKjQYVj/ljFPyREVJc2NiQ1MCCHE/wYpSpov+e0bIYQQIkoqumAa+hwthRQlQgghRJRIURKZph2kIIQQQghRTlpKhBBCiChxtMLRDWvpaOjjf06kKBFCCCGiRLpvIiPdN0IIIYRoFqSlRAghhIgSGwu7gef/Lek3kKUoEUIIIaJEN8KYEi1jSoQQQgjRUDKmJDIypkQIIYQQzYK0lAghhBBRYmsLWzdwTMnP/sdg6k+KEiGEECJKHBROAzslHFpOVSLdN0IIIYRoFqSlRAghhIgSGegaGSlKhBBCiChpnDEl0n0jhBBCCGGUtJQIIYQQURIa6NrAH+ST7hshhBBCNJTTCNPMy9U3QgghhBCGSUuJEEIIESUy0DUyUpQIIYQQUeJgyeRpEZCiRAghhIgSWyvsBv7Kb0Mf/3MiRQlg2w4rvtrCu++s4cCBAtLaJjHuzIGMOL4XLpf5YTdaa5Zt3MlrK9axJ6eA1olxnDW0L6cN6IXH5WqSPKu27eHV5evYfiCXlPhYzhzSm3GDjibG0zSb0Lqdmby0bA2bMw+SGOvlF4OOZvyQPsTHeJokz4a9B3h52Vp+2J1FnNfDqcf05Oxh/UiKi2mSPNv25/DysrV8t2MvXrebE/t259fD+9MqIa5J8uzJyeelL9ewatseLGUxqndXzh1xDG2TE5okT1Z+Ea8uX8vyTTtBw7Benbng+IG0T01qkjw5RSUs/Godn/+4naDtMKR7Ry4YOZCMtq2aJE9+SRlvfP0DH3+/BV8wyDEZ7blg5EB6tm/TJHmKy/y8vWo9H6zZRIkvQJ9OaZx//ED6dm7XJHlE9Citf/6dVQUFBaSkpJCfn09ycnJEj/X5Atxx68usXLkdy1I4jq787+AhXfn7jAuIjTV3oAvYNjc/t5gP1mzGZSlsR2MphaM1/TPSefyac0iJjzWWx3E0976yhFe/WlctT/d2rZl73XlGDyxaa/696HOe/uibyjxKgdbQMTWJp647n85tUozlAfi/pSv4z+IvfspTfntqYjxPXXcuvdq3NZrnpWVr+NurS7FUKA+AUpAQ4+WJ357LgC7tjeZ559sNTJ//DlqDU767sZTC63bx8FUTOf7oLkbzfLp+G1PnvUXQdqrksSzFvy7/JacN6GU0z8qtu/ndk69TFghW5nFZCq3h3gtPZ+Jx/Y3mWb97P1Mef5WC0jIqjg6u8n3iXyaexGUnHms0z/YDuVz16MscKChGAbo8j+1orvvF8fxu3MiIn7Mhx4xIX2Pet4OIT2rYyWRJoc0VQ76Lat7mosVffTP7kSWsWrUDCB2AD/3vmu928vB/3jOa59H3lrFkzWaAygNKxY7qxz37uf0Fs3n+++kqXv1qXY15dmbnctO8t4zmef3rH3j6o2+q5KnYcWblF/G7/3ut8vMz4aN1W/jP4i+q5ilf8ktK+e0Tr+EPBo3lWbl1N399ZSla/5QHQu9RiS/AtU8spLDUZyzPhr0HuOX5d7AdXbndQGgb8gWD/H7uGxwoKDKWZ09OPlPnvUUgaFfLY9sOf3p2EdsP5BrLk1tUWq0gASrfrzsWvM+6nZnG8pT4Alz7ZGgbOfR01XY0Grj/jU/4csMOY3mCtsO1Tywkp6gEoHJkRcW2/dj7y3l39QZjeY6Eo61GWVqKlvOX1iA/r4T33vmO2hqLHEfzwftryc0tNpKn1B9g/merax3SZDuaj3/Yys7sPCN5grbDvI+/qfV+29F8t2OfsZ2m1pq5H35d6zRCtqPZtj+XLzea22k+/dE3WKrmRLaj2Z9fxAflRaYJz3y8EpdVcx5HawpLfbz5zQ/G8jz/2bfU8vagNfiDNq8sW2ssz4Iv1xC0ax42GComNS98vtpYnoUr1lEaCFQpSA5lKcV/P11lLM873/5ITlFprXlcluKZMPuExvbJD1vZk1NQpcA+lKUUcz80l+fnZPbs2XTr1o3Y2FhGjBjBihUrwq4/a9YsevfuTVxcHBkZGUydOpWysrLK+7t164ZSqtpy/fXXV65TVlbG9ddfT5s2bUhMTOTcc88lKysrotwtuihZu3YXwaATdh3b1qz5bqeRPN/vyqLEH6hzveWbzOTZtj+H7MKSsOtYShnLk11YzPYDuWHHobsti+UbzeTxB4N8u31vrTtwCO3Elxkskr7csKPWHXgFU+8PwGfrt4fN42jN5z9uN5hnW9jPy3Y0n63fZizPFxu2E64D3XY0X2zYbizPso07ay2yK/Is37Sr1hO5xvblhh24rdoPU47WrN+zn6Iyc61/kbLLJ09r6BKJBQsWMG3aNO666y5WrVrFoEGDGDduHPv3769x/fnz53PLLbdw1113sX79ep566ikWLFjArbfeWrnO119/zb59+yqXDz74AIDzzz+/cp2pU6fy1ltv8fLLL/PJJ5+wd+9ezjnnnIiyt+iBrrYdviCJdL2GCrezrKBoZnkUBB0zeeo62P60nqn3p+51NObyQN2fmcbc5wXg6Lpfy2ieenxoJvPYdt156rNOY3G0U2fBobVGa2ptAWtMdj22H6j/vqEpODT86plIt8iZM2cyZcoUrrzySgDmzJnDokWLmDt3Lrfccku19b/88ktGjx7NJZdcAoRaRS6++GK++uqrynXS0tKqPOYf//gHPXv25KSTTgIgPz+fp556ivnz53PqqacC8PTTT9O3b1+WL1/O8ccfX6/sLbqlpE+fjvVar2+/TlFOEtK7YxqeOq720cCgbh2M5OmalkpCjDfsOrajGdTVTJ605ATS6hhUG3QcY3liPW56pLcO+6sU2tEM6lq/7awxDOjSIeyZrqUUg7uZyzOke8dau5Mg1JJ0bA8z3y+AY3t0qjPPsB6djeUZ0r1j2M/LZSkGdzf3eQ3s0oFwG7SlFP0y0rHCvIeNaVDXjmGLRAV0bp1CchNd5WZaQUFBlcXnq95C5Pf7WblyJWPHjq28zbIsxo4dy7Jly2p83lGjRrFy5crKLp6tW7eyePFixo8fX+P6fr+f5557jquuugpVvv2uXLmSQCBQ5XX79OlDly5dan3dmrTooiS9fQqjRh9d6xfM5VKMOL4nHTq0MpInJT6Ws4b2rXUn5bIUA7q0p1/ndCN5Yj1uLhg1MGyeLm1bMaKXmasnXJbFpScMqXWfaSlF68R4o1dPTDrx2Fq7k5SCuBgPZw3tYy7PScfW2lqiCH1m54wwdzXHpSccG/YsVmu4cNQgY3kuGj0obGuJ7WguHjPYWJ7zRw4I2+JgO5rLThhiLM+vhvfH63bX+h1ztOZyg1ffnDH4aJLjYmrdB2ng8pOOrTwwNkcVk6c1dAHIyMggJSWlcpkxY0a118vOzsa2bdLTqx4n0tPTycysefzfJZdcwr333suYMWPweDz07NmTk08+uUr3zaFef/118vLyuOKKKypvy8zMxOv10qpVq3q/bk1adFECMO1PZ9KxU2q1jVopRfv2rfjTX35pNM9fJp5E745pKKqesFQccP95Wc2Va7T8btxIju0eOpM99C2ylCIxNob/XDnB2FkTwOSThnJy/56VGSq4LEWs183DV52Nx21uLpdfDz+Gs4f1rTGPx+Vi1hUTSIw1dxZ36jE9mVR+0Di0RcBlhS55/edl40lLTjSW57ienfnDmaNrzKMU3H3B6XRLSzWWp3fHNG4959Qa8wD86ewTjV4y3al1Cn+/+AwspWrMc83YEYzu081YnlYJccyc9EtcLqtKnopt+8KRAxk/pLexPHFeD/+58my8bleNec4YfDQXjhpoLM+RqJhmvqELwK5du8jPz69cpk+f3igZP/74Y+677z4effRRVq1axcKFC1m0aBF//etfa1z/qaee4swzz6Rjx8ZvxWvx85QAFBf7WPT2aha/vZqDBwtp3SaR8b8czC/PGkxiork5QSqU+gO8vuJ7Xl62hn25haQkxPKr4f25cOQgUhPNT34VCNq8+c0PLPhyDbsO5pEUG8NZw/py8ehBRg9wFWzHYfG3G3jxi9Vszcoh3uvhzCF9uGTMYDq2Nn8Nv9aaJWs3M/+zb9mwNxuvx8UvBh7NJScMNnrAPTTPZz9u5/nPvmXtjkw8bouT+/fk0hOGcHQHs3OmVFixeRfPfbqKlVv3YCnFqN7duPzEIRxjeM6UCqu37+W5T79l+aadaK0Z3iuDy04cwlCDXTeHWr97P899tqp8YLDD4G4dufSEIYzq3bVJ8mzNOshzn33L0rVbCARt+nVuxyUnDOGU/j2apFVi18E85n+2mve+20iZP0ivDm24ePRgxg2qvaU7HJPzlDyycgRxiQ0bvllaFOSGoV/VK6/f7yc+Pp5XXnmFX/3qV5W3T548mby8PN54441qjznhhBM4/vjjeeCBBypve+6557jmmmsoKirCOmSw8Y4dO+jRowcLFy5k4sSJlbd/+OGHnHbaaeTm5lZpLenatSs33XQTU6dOrdffKkWJEEKIFsVkUfLQyuMbpSj5w9Dl9c47YsQIhg8fzsMPPwyA4zh06dKFG264ocaBrkOHDmXs2LHcf//9lbe98MILXH311RQWFuI6ZCbxu+++m8cff5xdu3bhdv/0d+Xn55OWlsYLL7zAueeeC8CGDRvo06cPy5Ytq/dA1xZ99Y0QQggRTY3zK8GRPX7atGlMnjyZYcOGMXz4cGbNmkVxcXHl1TiTJk2iU6dOlWNSJkyYwMyZMxkyZAgjRoxg8+bN3HHHHUyYMKFKQeI4Dk8//TSTJ0+uUpAApKSkcPXVVzNt2jRat25NcnIyv//97xk5cmS9CxKQokQIIYSImiOZZ6Sm54jEhRdeyIEDB7jzzjvJzMxk8ODBvPvuu5WDX3fu3FmlS+b2229HKcXtt9/Onj17SEtLY8KECfz973+v8rxLlixh586dXHXVVTW+7r///W8sy+Lcc8/F5/Mxbtw4Hn300YiyS/eNEEKIFsVk982/vhnTKN03fxr2eYs4xklLiRBCCBEljlY4DZ08rYGP/zmRokQIIYSIEqcRum+cFjR7R8v5S4UQQgjRrElLiRBCCBEljrZwGnj1TUMf/3MiRYkQQggRJTYKO+wvZNXvOVqKllN+CSGEEKJZk5YSIYQQIkqk+yYyUpQIIYQQUWLT8O4Xu3Gi/Cy0nPJLCCGEEM2atJQIIYQQUSLdN5GRokQIIYSIkqb4Qb6fMylKhBBCiCjRKJwGjinRckmwEEIIIYRZ0lIihBBCRIl030RGihIhhBAiSuRXgiPTcsovIYQQQjRr0lIihBBCRImNhd3A8/+GPv7nRIoSIYQQIkqk+yYyLaf8EkIIIUSzJi0lh8gpKuFgUQltEuNpnRjf1HHI85WSVVpE65g40uISmzoOBf4yMksKSfbG0j4+qanjUBTwsbe4gASPl04JKU0dh9JggN3F+cS63HROSEGppj278dlBdhXl4bYsuiSmYjVxHr9ts6soD6Wga2IqLqtpz4mCjsPOolw00CWxFR7L1aR5HK3ZUZiLrR0yElsR42ra3bPWml1Fefgcm4yEFGLdnibPs6c4n5JggM6JKcS7vU2ap74cLJwGnv839PE/J1KUABv2HeA/73zBZz9uQwMKGN27GzeeMZq+ndoZz7O14CAPrP6E93dtxEEDcHx6F/406CSGpnU2nmdPcT7/Wv0Jb+9YT1A7AAxp25FpA09kTIfuxvNklxXzr9Wf8Nq2dfid0E9V9Uttx00DT+T0zkcZz1PgL+PB7z7l5S1rKLUDAPRMbsPvjxnNxO79jecpDQaYteYz5m/+lqKAH4CMhBSu7T+Si3sNNl4s+W2bR7//kmc2fEOevwyA9LhEruk3git6H2e8WLIdhyfXr2Dujys4UFYMQOuYeK7sM4xr+43EbbhY0lrz342rePyH5ewtKQAg2RPDZUcP5Q8DRhsvTrTWvLp1LY+s+5IdRbkAJLi9XNRrEDcNPIFET4zRPACLd/7If9Z8zsb8AwDEuNyc12MAfxx0IqkxTX8CGY6tFXYDu18a+vifkyP69s2ePZtu3boRGxvLiBEjWLFiRa3rzps3D6VUlSU2NrbKOkVFRdxwww107tyZuLg4+vXrx5w5c44kWsTW7crk0kde5IsN28sP/6CBZRt3cOnsF1mzc5+RHBW25B/k1+8+wwe7fypIAFbs38VFHzzPZ/u2Gc2zpzifX737DG/t+KGyIAH4Lnsfkz58kcU7fzSa52BZCee8+wyvbF1TWZAArM89wDWfvMKLm1cbzVMY8HHB+8/x/KZVlQUJhArLm758kznfLzeax2cHuWzpC/zfjysqCxKA3cX53LbiXf65+mOjeYKOwzWfvsJDa7+oLEgAskqL+OvKpUz/6h201mGeoXFprZn25Vvcv/qjyoIEIMdXwszvPuWGz1/DMZgH4J5vPuCub96vLEgACgI+5ny/jCs/egm/bfY3Yh9a+zl/Xr6IneUFCUBx0M/TG77h4g+epyToD/Poxjdvwzdc/9lrbCovSCC0nb+4eTXnvvdf8n2lRvOI6Iq4KFmwYAHTpk3jrrvuYtWqVQwaNIhx48axf//+Wh+TnJzMvn37KpcdO3ZUuX/atGm8++67PPfcc6xfv56bbrqJG264gTfffDPyvygCWmvuemUJ/qCNfdiOyNaaoO1w58sfGN1p3vXN+xQH/dXyOFpja81flr2N7Ti1PLrx3f/tR+T6SqrnKS+Yblm+mLJgoKaHRsV/1n7G3pKCanl0eZ47v36fPIM7qf9b/xWbCrJryBPyz9Ufsac431ie+Zu+5dvsPdUOrBX/mvPDcn7Mrf272tje2vEDn+zdWvn5HO6lLd/x1f5dxvJ8sncrb+74ocb7NPDero28v2ujsTzfZu/hmY0ra7zPQbMsawevbltrLM/WgoPMWvs5QLVPzNGaH3L38+yGmvNGw4HSIv62ckmNeWyt2VmUy6PfLzOW50hUDHRt6NJSRFyUzJw5kylTpnDllVdWtmjEx8czd+7cWh+jlKJ9+/aVS3p6epX7v/zySyZPnszJJ59Mt27duOaaaxg0aFDYFpjGsH7PfjbsO1DrmZGjNZuzDrJud1ZUc1TYXZTHF5nbqx3gKmg0maVFfJ5pprUkz1fK4p0/hskTail4z9BO3GcHeWXL2lrzAAQdm9e3f28kj9aa5zZ+G/bMWinFy1vWGMkD8N+Nq8Le71IWL25ZbSYM8NzGVVhhfrfDpSxe2PStsTzPb/oWV5juIkspnt8U/j1sTC9sWo1L1b4bVsDzdXymjWnB5u/Cvj8Ous5trDG9unUt4c4Jba15YfNqggZP1CKly38luCGLbkEzukb0l/r9flauXMnYsWN/egLLYuzYsSxbVnu1WlRURNeuXcnIyGDixIl8/33Vg8aoUaN488032bNnD1prPvroIzZu3MgvfvGLGp/P5/NRUFBQZTkSO7Lz6rXeznqu11DbC3PrXEeh2FaP9RrD7uL8sAUAgFtZbC/MMZLnQGlxlS6SmrgM5ikJBsjxlYRdR4GxPAA7i/JqaZMIsbXD1gJzebYV5lTphqwpz+aCg8bybKmhVetQjtZsMZrnILau/YCqqd9+obFsL8yt8zu/t6TAWGvttsKcOsccFQZ8FBzSNdjc2KhGWVqKiIqS7OxsbNuu1tKRnp5OZmZmjY/p3bs3c+fO5Y033uC5557DcRxGjRrF7t27K9d5+OGH6devH507d8br9XLGGWcwe/ZsTjzxxBqfc8aMGaSkpFQuGRkZkfwZlZLi6jdgKyHGzCjvJG/deTSaJI+hPPUY0OZobWzgW33+bo0m0W0mT4zLHfYsF0JFpMmBgQl1XCFhKUWyJzbsOo2prm1IAcn12O4bS7K37r/d5PuT4o0N25IEkGDo+w6hfVC4lhKAWJfb2ODk+uyDFBDfxFcGicYT9TahkSNHMmnSJAYPHsxJJ53EwoULSUtL4/HHH69c5+GHH2b58uW8+eabrFy5kgcffJDrr7+eJUuW1Pic06dPJz8/v3LZtevI+qSP69G5zsIkMdbL8Ud1OaLnj9SA1h3oUMelth7LxWmdzFxh0iWxFX1T26HC7DQ1mjO69DaSJyUmjlHpXcPuEG2t+WXXvkbyuC2LMzN6h92JB7XDWYbyAJzdrX/45netjeaZ2K1/2M9LE8psMk+4w6mF4lcGr5g6q2vfsC1JLqX4lcH355dd+oRtKXEpxYSu/YxdwfXLrn2rDLCvKc9pnY5q8suVw3F0Y4wraeq/wpyIipK2bdvicrnIyqo6xiIrK4v27dvX6zk8Hg9Dhgxh8+bNAJSWlnLrrbcyc+ZMJkyYwMCBA7nhhhu48MIL+de//lXjc8TExJCcnFxlORIxHje/G3t82HV+e9oIYj1mLsmzlOKPg06q9X4F/KbPcFrFxBnJo5Ri2sATax2kqIALew4yOkfIjQNPqHztw1lKMa7z0fRNNXcZ93XHjMRSVo2Fm0sphrfLYEQ7M0UtwG/6DiemljNZl1L0adWO0zr3Mpbn8qOPJdlT89m3SykyElKY2K2fsTzn9hhAelxSrXlax8ZzYa9BxvL8smtfeiS3rjVPgtvL5N7DjOU5sUMPBrXpUGMeC4XbcvHbfuH3mY1pcJuOnNChe43bsyLUEnnDgFHG8hyJho4nqVhaioj+Uq/Xy9ChQ1m6dGnlbY7jsHTpUkaOHFmv57Btm7Vr19KhQwcAAoEAgUAA67C5AVwuF46BfsvLxgzh9+NG4bYslAK3y0IphduyuG7s8Vxx4tCoZzjUuT0GcNew0/FaLhTgURYWCgvFlb2P44+Dau7SipaxnY/iXyPPIs4VOhPxKAtLhQ7B5/ccyD3HjTOaZ3i7DB474ZzKLhG3sip3oGdk9Obfo882mqdfajpPn3IBrWJiq+UZ0747T550ntF5QbompfLcaReTFptwSJ7Qd2tI207897SLjE4SlhaXyIunX1ZZuB6ap3erNF44/VKjk2Ale2N58fRL6ZHcpjKPuzxPl8RUXjz9UqPzXsS43Mw/7RL6p4ZO6lyH5EmPS2L+2EvomHBkJ11HwmVZPH3KBRzXLqM8j6rM0zo2nv+eehE9U9oYy6OU4tETfs2pHXtWy5PsjeXJk85jUJuOxvKI6FM6wutdFyxYwOTJk3n88ccZPnw4s2bN4qWXXuLHH38kPT2dSZMm0alTJ2bMmAHAvffey/HHH0+vXr3Iy8vjgQce4PXXX2flypX06xc6Qzr55JPJzs7mkUceoWvXrnzyySdcd911zJw5k+uuu67OTAUFBaSkpJCfn3/ErSY5RSW8890G9hcUk5aUwJmDe9OmCWd1LfCX8db2H9hTXEDr2HjO6tq3SWdRLQ74WbRzPTsKc0nyxPLLrn3ISGzVZHnKggEW7/yRLQUHiXd7OaNLb3omm9tZHs5v27y/eyPrc/cT63IztvNRRltsDhd0HD7cs5nvDu7Da1mc3Klnk+68Ha35bN9Wvt6/G5elGN2+O8eldW6yWW+11izP2smyrB1oNCPadWFU+25NNuut1ppvs/fw6b5tBB2HY9M6cVKHHk066+26nEw+3LMZn21zTOt0xnY+qklnvd2Yd4D3d2+kNBikd6u2jMvofcQTyzXGMaO+r3H5RxfjTWxY4e0v8vPfU16Iat7mIuKiBOCRRx7hgQceIDMzk8GDB/PQQw8xYsQIgMrLeufNmwfA1KlTWbhwIZmZmaSmpjJ06FD+9re/MWTIkMrny8zMZPr06bz//vvk5OTQtWtXrrnmGqZOnVqvnZaJDUwIIcT/BpNFySUfXtIoRcn8U+e3iGPcERUlzY0UJUIIIepLipLmS377RgghhIiSxhio2pIGukpRIoQQQkSJQ8OniXdk8jQhhBBCCLOkpUQIIYSIEo1qcEuHbkEtJVKUCCGEEFHSGL/y25J+JViKEiGEECJKZKBrZFrOXyqEEEKIZk1aSoQQQogoke6byEhRIoQQQkSJ0wgDXeWSYCGEEEIIw6SlRAghhIgS6b6JjBQlQgghRJRIURIZ6b4RQgghRLMgLSVCCCFElEhLSWSkKBFCCCGiRIqSyEj3jRBCCCGaBWkpEUIIIaJE0/B5RnTjRPlZkKJECCGEiBLpvomMFCVCCCFElEhREhkZUyKEEEKIZkFaSoQQQogokZaSyEhRUm5fXiFvr1rPgcJi2iYlMGFIHzqkJjdZngOlxby2bR17S/JpHRPP2d360S2pdZPlyfWV8Pq279lRlEuyJ5azuvbl6FZpTZanMODjjW3fs6XgIPFuL2d26c0xrds3WZ6SoJ+3d6xnfe5+Yl1uTu98FEPadkKpptmZ+Owg7+z8kTUH9+GxXJzcsSfHp3dpsjwBx+aD3ZtYeWA3llKMTu/GiR17YDVRHttx+GjvFpZn7QQ0w9t14dROvXBbTdN47GjNF5nb+WzfNmztMLhNR8Zl9MbrcjVJHq01K/bv4qO9W/DbQfq3TueXXfoS6/Y0SR6A1dl7eX/XRkrtAEe3SuPsrv1I8HibLE99SVESGaW1/tkP7C0oKCAlJYX8/HySkyMrJLTWzHr3C+Z+/DUKhaUUjtZoNJNPGMq08SdgWWY3iDnfL+Nf332C1mAphUZja81FvQbz1+PGGd9xPr9xFfesXELQcXAdkueXXfrw4KgJxLjM1rZvbv+em5cvxmcHcSmrMs/JHXvw8JhfkeiJMZpn6e5N3PjFmxQH/bhV6LMJaodhaZ15/MRzaR0bbzTP8qydXPfpQvL8pVXy9Ettx1MnX0D7+CSjedYe3MeUT14hq7SoSp7uSa15+pQL6JqUajTP5vxsrvroJXYV51fJ0yE+madOPp++qe2M5tldlM9VH7/EpvzsKnnaxMbz5EnnMaRtJ6N5DpQWM+WTl/nu4L4qeZK9sTwy5lec0KG70TwF/jKu+3QhX2btwKUslIKg4xDv9vDgyAmc0aV35M/ZgGNGpK8x5s3rcSc0bJ8ULPbx+dmzo5q3uWjxY0qe+vhrnvroa7QOna0EHSdUlGiY9+lKnvxohdE8L2xezf2rP8bWGgdNUDvY5XXjgs2rmbHqQ6N53tn5I7d//R4Bx0YfluednRuYvvwdo3m+yNzOTV+8SZkdREOVPJ/t28YNn71uNM+ag/u49tOFlAT9UJ4nqB0Avs3ew9Ufv4RjsO7fUnCQKz5aQIG/rFqeDXkHuGzpC/ht21iefSUFXLr0BQ6UFVfLs7Mol4uXPE9RwGcsT56vlIuXzGdvSUG1PPtLC7lkyfNkl2c1oSwY4JIlz7O14GC1PLllpVy29AV2FeUZyxN0HCZ9+CLrcjKr5Sn0+7j645f5MXe/sTxaa6755FW+2r8TAFs7BJ1QntJggOs/f41v9u82ludIaK0aZWkpWnRRUhYI8uSHX4dd56mPvqbEHzCSx3YcZq35rNb7NfDsxpUcLCsxkkdrzb/XfFbrFfYOmte3r2NnYa6RPAD/WfN5rV0QttZ8sm8raw/uM5bn0e+/JNSuVnOe1Qf38UXmdmN5nlq/gqBj49SQyNaaLQUHeX/XBmN5/rthFcVBf42Fma01mSWFvLZtnbE8L21Zw8Gy4spC9vA8BX4fL2xabSzPWzvWs6s4v8Y8DhqfHWTehm+M5flwz2Z+zNtfYx6NxtGax39YbizPNwd289X+nbXkAQU88v0XxvIcCQfVKEtL0aKLkhWbd1Hs84ddp8Qf4KtNO43kWZOzj/2lRWHXCWqHD/dsNpJne2Eum/Kzw07co5Tivd0bjeTJ9ZXw9YFdYVseXMriXUMH3aDjsGT3php3mBXcyuKdnT8ayQPw9o71YfNYKBYbLEre2vFDnS1Fb+9YbygNvL3jh7Dbs4PmrR0/GMuzaOd6VJgDjq01b243l+fdXRtwhRnnY2uHxTt/xFSv/zs7f6zsQqo5j+bTvVspDZo5cRTR16IHupb4wxckP61nZoMvqccXSwHFwfrlbqiSeryOhaIkYCpP83p//E4wbAEAobPL+ryPjaWunbODpthgd0ldn4UGigxtP0C9uopMdicVBXy1tLP9xOQBtyTor3Ob9js2jtZhi5fGUhwM1DmbqSb0HsU14SDccGSga2RadEtJ93b1u5qlRz3Xa6juSa3rbKTTQK/kNibikJHYKuxZCoRabnqmtDWSp21sAgnu8KPtbe3QK9lMnjiXh3axCWHX0UBPQ3kAuiWH34ZcSnGUoc8L4KiUtlhhErmUorfBq7h6t2oX9mDqUsroVWVHp6ThCvMds1D0NPR9B+iZ3Cbs+6MI7Rdchgbb90ppU2erTCtvLCneWCN5joSMKYlMiy5KendI45iM9FovS7SUom/HdvTtZGY0fseEZE7s2KPWnYKFonNCCqPadzOSJ9kby4Ru/WrNowjtEE7vfJSRPDEuNxf2GhR2pxnjcnN2t35G8iiluOzooWEPugq4oOdAI3kAJh89NOz9FVdxmXL5UcfWOL7l0DyXHjXEWJ5LjxoStiXA1prLjjrWWJ5LjhqCXT6QtCYOmkm9zeW5sOegOrvbJtWxjTWmc7sPwBXm6kdLKS496lhjRZKIvhb/Sd573i+I87qrbfguSxHrcfPXC043m2fYL0jxxlY78LqUwm1ZPDhqgtG5HW4Zcgrt4pJqzGMpZfyS4D8cM5puSa2r5bFUqGd+xogzSTZ41vSbvsM5pnX7ap9JRaFyx9CxpBu8BPeCnoMY1b5btUKp4l9TB55AL4MtJeO79uXMjN7VyraKf1/ZexhD0zobyzO6fTcu7DmoSoZD/apbf07r1MtYnmNat+e6fiNrzKOAUzv1YmK3Y4zl6ZKUyi1DTi1//erb9NC0zlx+tLkiqXVsPH897ozK1z+USymOTknj2v7HG8tzJCq6bxq6tBQtfp4SgG37c3j0g2W8v3YTtqOxlOL0AUfxu9OPp2e6uabTCruL8pm19jPe3P4DAceu3DlNHXgC/ZtggrADpUXMWvM5r25bi88OAnBC+278YcAJDGtn7oBSId9XykPrvuDFzasrx5kcl5bBHwaMZozhORQAigN+Zq/7kuc3raKgfDzCwNYduP6YUfwi42jjeXx2kMd/WM4zG1aS4wtdqXV0Shq/6z+Sid37G88TdBzm/vg1c39cQVb5QO5uSalc0+94Luo5yPiEbo7WPL9pFU/+8BW7ivMB6BifzG/6Dmdy72HGJ3TTWvPq1rXM+WE5W8ovDU6LTeCK3sOY0m8EHsv8BGqLdqxn9vdfsr788t9UbxyXHX0sv+s/skkmUPtoz2YeXvcl32bvASDJE8NFvQbz+wGjSTqCeYlMzlMy9NWpjTJPycpz/90i5imRouQQxWV+8kpKaRUfR0Js088UWBL0k1NWQrI31ujZf23KggGyy0pI8nhJiYlr6jj47CAHSouJd3uMT1BWk4Bjs7+0iBiXm7Z1jDUxIeg4ZJUW4rVctI1NaLLZXCvYjkNWaREupWgXl9jkeRyt2V9ahEaTHpfUZLPLVtBac6CsmKDjkB6X2Cy6JA6UFuN3grSLS2yS4uhwOWUllNoB0mITGzTbrcmi5NhXpuFqYFFiF/tYdd7MiPLOnj2bBx54gMzMTAYNGsTDDz/M8OHDa11/1qxZPPbYY+zcuZO2bdty3nnnMWPGDGJjfzr27Nmzh5tvvpl33nmHkpISevXqxdNPP82wYcMAuOKKK3jmmWeqPO+4ceN499136/23tuirbw6XEOttFsVIhXi3l/jE5pMn1u2hc2JKU8eoFONyN6s8HstFp4Tmk8dtWc0qj8uy6JjQfM7yLKWMz24bjiov1pqTtLimL64P1RxOPn4OFixYwLRp05gzZw4jRoxg1qxZjBs3jg0bNtCuXfUxkvPnz+eWW25h7ty5jBo1io0bN3LFFVeglGLmzJkA5ObmMnr0aE455RTeeecd0tLS2LRpE6mpVWdkPuOMM3j66acr/x0TE1lBJkWJEEIIESUaaGh/RKQPnzlzJlOmTOHKK68EYM6cOSxatIi5c+dyyy23VFv/yy+/ZPTo0VxyySUAdOvWjYsvvpivvvqqcp3777+fjIyMKgVH9+7Vu8tjYmJo3/7Ihxk0ffugEEII8T/K9Iyufr+flStXMnbs2MrbLMti7NixLFu2rMbHjBo1ipUrV7JiRehnVbZu3crixYsZP3585Tpvvvkmw4YN4/zzz6ddu3YMGTKEJ598stpzffzxx7Rr147evXtz3XXXcfDgwXpnB2kpEUIIIX4WCgoKqvw7JiamWvdIdnY2tm2Tnp5e5fb09HR+/LHm2aUvueQSsrOzGTNmDFprgsEg1157LbfeemvlOlu3buWxxx5j2rRp3HrrrXz99df84Q9/wOv1MnnyZCDUdXPOOefQvXt3tmzZwq233sqZZ57JsmXLcNVzDJAUJUIIIUSUNMbkZxWPz8jIqHL7XXfdxd13392g54ZQ68Z9993Ho48+yogRI9i8eTM33ngjf/3rX7njjjsAcByHYcOGcd999wEwZMgQ1q1bx5w5cyqLkosuuqjyOQcMGMDAgQPp2bMnH3/8Maeddlq9skhRIoQQQkSJoxWqkaaZ37VrV5Wrb2oaRNq2bVtcLhdZWVlVbs/Kyqp1rMcdd9zB5Zdfzm9+8xsgVFAUFxdzzTXXcNttt2FZFh06dKBfv6oTU/bt25dXX3211tw9evSgbdu2bN68ud5FiYwpEUIIIX4GkpOTqyw1FSVer5ehQ4eydOnSytscx2Hp0qWMHDmyxuctKSnBOuwS9IrulopZQ0aPHs2GDVV/zHPjxo107dq11ry7d+/m4MGDdOjQoX5/INJSIoQQQkSN1o1w9U2Ej582bRqTJ09m2LBhDB8+nFmzZlFcXFx5Nc6kSZPo1KkTM2bMAGDChAnMnDmTIUOGVHbf3HHHHUyYMKGyOJk6dSqjRo3ivvvu44ILLmDFihU88cQTPPHEEwAUFRVxzz33cO6559K+fXu2bNnCX/7yF3r16sW4cePqnV2KEiGEECJKGnNMSX1deOGFHDhwgDvvvJPMzEwGDx7Mu+++Wzn4defOnVVaRm6//XaUUtx+++3s2bOHtLQ0JkyYwN///vfKdY477jhee+01pk+fzr333kv37t2ZNWsWl156KRBqWVmzZg3PPPMMeXl5dOzYkV/84hf89a9/jWiuEpnRVQghRItickbXfi/+BVd8A2d0LfHxw0X/bBHHOGkpEUIIIaKkKVpKfs6kKBFCCCGipDGvvmkJpCgRQgghoqQpBrr+nMklwUIIIYRoFqSlRAghhIiSUEtJQ8eUNFKYnwEpSoQQQogokYGukZHuGyGEEEI0C9JSIoQQQkSJLl8a+hwthRQlQgghRJRI901kpPtGCCGEEM2CtJQIIYQQ0SL9NxGRokQIIYSIlkbovqEFdd9IUSKEEEJEiczoGhkpSoA8XynPbPyGBVtWc7CsmNax8VzQczCTjx5G65h443nK7FKWZb/L8pwlFAQOEudKZFjqyYxJ+yXJnlTjeQKOj+UHl7D84Pvk+LOIseIYknoCJ6SdRWtvO+N5bB1kxcEPWXbwXQ749uGxYhjUahQnpp1FWkxH43kcbbMq9zO+yH6HzLKduJWHY1KGc2LaBDrEdTWeR2vNmvxlfH5gMbtLt+BSbvokDeHEdhPoEn+U8TwAP+R/w2fZi9hRvAGFxVFJAzgh7Sx6JvZvkjybCtfy2YG32FL0PRpN94S+nJh2Fr2ThzRJnu3FG/j0wFtsLFyNox0y4nsxpu0vOSZlOEqZP0veXbKVTw+8xfqCbwjqIB3jujG67XgGtxqNpcwPRcwq28Wn+99mTf4ygjpAekxnRrY9g2GtT8alXMbziOhRWkdeg82ePZsHHniAzMxMBg0axMMPP8zw4cNrXHfevHlceeWVVW6LiYmhrKysym3r16/n5ptv5pNPPiEYDNKvXz9effVVunTpUmeehvwMdWZJIRcseZa9JQU4h7wVllKkxyXx8thJdEww91PRxcFC5my+k/2+PehDOhIVFvGuRK7rdS/tYjsZy+OzS3li673sLtlSJY+FhceK4bc976ZzfA9jeYJOgKe3zWBT0doqt1tYuJSbq3vcRo/EfsbyONrm+R2zWJu/HIWqfI8sLEAxqfuf6Zc81FgerTULdz/BVzlLUFhonMo8Gs2FXX7PsaknGMsD8M6++Xy0/zUsLJxD8jg4/KrT1Yxqe4bRPB/vf4PF+56rMc8v2l/I2PTzjOZZcXApr+yeUyVPxWc3pu14JnS8wmhhsiZvGc/vmIWCQ/KEtu1jU0/kgozrjRYmGwu/4+lt/0Brp1qevslDmdTtT7hUZOfXDTlmRPoa3ebejhUf26DnckrK2H7V36Kat7mIeMtasGAB06ZN46677mLVqlUMGjSIcePGsX///lofk5yczL59+yqXHTt2VLl/y5YtjBkzhj59+vDxxx+zZs0a7rjjDmJjG/ZB1sf0FYvYd1hBAuBozf7SQm7+6u2oZzjUm3ue5oBvb5UCAEDjUGoXMX/HLI6gjjxi72UuYHfJ1mp5HBz8jo9nt/8LRzvG8nx84A02F62rdruDQ1AHeHb7AwQcv7E8yw8uYW3+coAq71Fo92nz/PaZlNrFxvJ8l/clX+UsKc/z0+fi4KDRvLTzEfL8B43l2Vj4HR/tf60yw6F5AF7f8xRZZbuM5dldsoXF+56rNc/7mQvYXvyjsTzZvn28uvvxankqPrvPsxezvmClsTxFgXxe2PkQGuewPKFte1Xup6zK/cRYHp9dyn+3P4ij7RrzrC9YxRfZ7xjLc0S0apylhYi4KJk5cyZTpkzhyiuvpF+/fsyZM4f4+Hjmzp1b62OUUrRv375ySU9Pr3L/bbfdxvjx4/nnP//JkCFD6NmzJ2effTbt2kW3a2BnUS6f7NuKXctB3taaL7K2s60wJ6o5KhQHC/gu78sqX75DOTjsLdvOrpLNRvL4HR8rcpZUObgdSuOQFzjAxsLvjOSxtc2X2e9WK5B+yqMpsYsqi4Ro01rzefYioPYdRkAHWJnzsZE8EDqIqTB5NLCivGgx4Yvsd8pbjWpmYbEs+z1jeb7Mfq/OPCYPcssPfhD281JYfJ692Fier3M+xNF2mDyKzw4sMpZndd4X+JzSWr/zoPn8wGKjJ2oiuiIqSvx+PytXrmTs2LE/PYFlMXbsWJYtW1br44qKiujatSsZGRlMnDiR77//vvI+x3FYtGgRRx99NOPGjaNdu3aMGDGC119/vdbn8/l8FBQUVFmOxLqczHqtt/bgviN6/kjtK92BQ+07hBDFrlIzRUm2by9+xxd2HQuXsSKpMJBLUTC/2eQJaD/Zvn2Eu15PodhVssVIHoA9pVvC7MBDhaSp9wdgZ/GmWotsCBXa24s3Gsuzo2RDnXl2GMxT1/tj+vPaVef2o9lXtsNY6+iuks1YhB8zkhfIpsQuMpLnSFQMdG3o0lJEVJRkZ2dj23a1lo709HQyM2s+wPfu3Zu5c+fyxhtv8Nxzz+E4DqNGjWL37t0A7N+/n6KiIv7xj39wxhln8P777/PrX/+ac845h08+qbmZcMaMGaSkpFQuGRkZkfwZlTxW/QZIeVxmBlLVr19UR9x/eqTq8zoajbsZ5YlkvYYKd8ZdQWEuD4BV59h1ZTSPy6r7tdyWx0CSkPr87SbfH3c93h+TAzldyo2qY7tWWGFbdxo7T2Ou1yR0Iy0tRNRHK40cOZJJkyYxePBgTjrpJBYuXEhaWhqPP17ej+qEKu6JEycydepUBg8ezC233MJZZ53FnDlzanzO6dOnk5+fX7ns2nVkfdLD22XgraMwcSuL49vVPdi2MXSO70msVffVPkcnDTKQBtJiOpLiaRN2HY1D7+TBRvIkulNoH5sRdofoYNMnycwVFG7LQ4+E/mF34g4OfQxe0dEneUgdxZKmT/KxxvL0Sx4aNo9CGR0I3C95WNjPy8Kif8pxxvKEPovat2cLi77Jw4zl6Z00uNbu2oo8vZMGGxt42zt5SNjWY4WiS/xRxLrijOQR0RdRUdK2bVtcLhdZWVlVbs/KyqJ9+/b1eg6Px8OQIUPYvHlz5XO63W769at6xUTfvn3ZuXNnjc8RExNDcnJyleVIpHjjuLjXEKxadgoWigt7DibV0GXBHsvLCWln1Xq/wmJAyvHGLsO1lIuT202s/X4seib0p2NcdyN5lFKc0u7XtTYvW1h0iO1Kz8RjjOQBOKXdxFp34hYWqZ40owe5E9Mm1Pr+KCwSXMkMaTXGWJ7Rbc+ktoOuQuG1Yhje+jRjeY5v8wvcyl1LYatQymJkm3HG8gxLPYU4V3ythZIGTkgbbyzPoFYjSXKn1prHweGkdmcby9MnaTBtYzrUWthqNCe3+5WxPEei4rdvGrq0FBEVJV6vl6FDh7J06dLK2xzHYenSpYwcObJez2HbNmvXrqVDhw6Vz3ncccexYcOGKutt3LiRrl2jP8fDLYNP5bROobkbXOWXubnKzwJO6tiD248dW+tjo+G09HMYmnoS8FP3QMV/uyX05vyM3xnNM6rNGYxp+8sqOSp2WO1ju3BZt2lG8wxJPYHT0y84LE/o82odk86V3acbvXyyd/IQJna8qsY8SZ5UftPzDqNNy10TjuaCjOvLm9grvt6hPPGuRKb0vJ0Yg2eV6bEZXN7tj9UKgVBBEsvVPW4j0ZNiLE8rbxuu7H4LHstbLY9bebii219oE5Me5hkaV7w7kd/0uL3amb4KXeTOpV1vMlb0A3isGK7peQeJ7uTyHKoyj0JxbuffGp1bxlIuftP9Nlp521bJU/FdG9/hMo5JqXk6imZFum7qLeJ5ShYsWMDkyZN5/PHHGT58OLNmzeKll17ixx9/JD09nUmTJtGpUydmzJgBwL333svxxx9Pr169yMvL44EHHuD1119n5cqVla0jr732GhdeeCGzZ8/mlFNO4d133+Wmm27i448/ZsyYus/qGnrNudaar/bv5NVta9hXUkj7uCTO6T6Akeldm2TiIq01O0s28XXOh+T495PoTmZI6on0ThrcJBMXAewp2caKnCVk+/YR50pkcOpo+iYPa7KJi7LKdvHVwSVkle0mxoplQKuRDEgZYXR8wqEO+jJZfvAD9pZux2N5OSZlOINajcJjxTRJnjx/Nl8dXMLOks24lZs+yccyJPWEJmvmLgzksiLnQ7YVr8fCRa+kAQxLPZl4d2KT5CkOFvJ1zodsKfoe0PRI6MdxbU4l0W2uQDpUqV3MqpxP2VC4GgebrvG9Gd7mNFI8rZskj98u49u8z1lfsJKA46dzfA9GtDm9SSZLBAg4ftbkLWNd/gr8Thnt47owovXYI56zyeQ8JV2euBMrroHzlJSWsfOae1vEPCVHNHnaI488Ujl52uDBg3nooYcYMWIEACeffDLdunVj3rx5AEydOpWFCxeSmZlJamoqQ4cO5W9/+xtDhlTtZ587dy4zZsxg9+7d9O7dm3vuuYeJE2vvOjiUiQ1MCCHE/waTRUnG43c1SlGy67f3tIhj3BEVJc2NFCVCCCHqy2hRMqeRipJrW0ZR0oyvoxJCCCF+7hThrrCq/3O0DE0zQEEIIYQQ4jDSUiKEEEJES2NcQfOzH2RRf1KUCCGEENEiRUlEpPtGCCGEEM2CtJQIIYQQ0aJVaGnoc7QQUpQIIYQQUdIYv/L785+4o/6k+0YIIYQQzYK0lAghhBDRIgNdIyJFiRBCCBEtMqYkItJ9I4QQQohmQVpKhBBCiChROrQ09DlaCilKhBBCiGiRMSURkaJECCGEiBYZUxIRGVMihBBCiGZBWkqEEEKIaJHum4hIUSKEEEJEixQlEZHuGyGEEEI0C9JSIoQQQkSLtJRERIoSIYQQIlrk6puISPeNEEIIIZoFaSkpZ2ubrUVrKQzkkuRpRY/EgbiUq8nyaO2AfwU4e0GlQsxolPI2YR4NgVVg7wCVDDFjUCq2ifOsAXsrqHjwjkZZiU2WB0AH1kPwR1Cx4B2FslKaNk9wMwTWAR6IGYmyWjdxnp0Q+BZwgXcYytW+afPY+8D/DaDBcyzK3bmJ8xwA/1eADZ6BKHf3ps3j5IJvGeAHdz+U5+gmzlMI/i9Al4L7aJSnf5PmqS+Z0TUyUpQAa/O+YNHeuRQGcytvS3S3YnyHKxmUeoLxPNr3CTr/rlBBUkGlQNIfUfEXmc/j/xqdfxvY2w/JkwiJ10P8VShltmlRB75H598MwY2H3BqLTvgNKvEGlDLbAKiDm9F5t0BwzSG3etHxl6KS/oRSHrN57D3ovJshsOKQW93ouHNQyXegVIzhPNno/Ong/+SQWy107C9RyfcYLya1k4/Ovx187/NTZ71Cx5yKSvm78eJNOyXognuh7HXA+el27yhUyj+MF29a+9EF/4DSF4HgT7d7jkWl/BPl7mI4j40u+jcUPwP4frrd3Q+Vcj/K09tonojJmJKItPjum3V5X/LizgerFCQARcE8Xtr1b9bkfW40j/Z9gc79LTj7DrsjH11wJ7pkvtk8/u/QOVeAvfOwO4rQhfdD8WNm8wQ3o3MugeDmw+4pg+JH0IX/MJvH3oM+eAkEvz/sHj+UzEPn32o2j5ODPnghBFYedk8QSl9B594QamUylqco9Hn5D/8eOVC2CJ17NVoHzOXRfnTOZPAtoeqeXoPvY3TO5WhdajCPjc67tlpBAoD/K3TOxWgn32Aejc77I5Q+z6EFCQCB79A5F6LtLGN5AHTB3VD8JIcWJAAEN4Ten+AOo3lEdLXoosTRNov2PR12ncV7n8bRtpE8Wmt04QzClda68F9md5pFDwI21XaYlffPDjXzmspT+BBof615KHkGHdxtLk/Rk6ALCb1H1e6FsjfQgR/M5Sl+BpzsWvI4odYK/1fG8lD6cqjLr7Y8gW/Bt9RcnrJFEPyhljw2BDdB6Rvm8vg+Bf9yat6ebbD3QckL5vIEVoPvPWre/9jg5KGLw+8zG5MOboHSBbXn0aXoIrMnRiK6WnRRsqP4RwoCB8OuUxjMZVvR4WfBURLcVN4lEeZMVhdB2UdG4mg7M8wOs0IQyt41k8cpKm9yD1ckKih7y0we7UDpwjryuNClrxvJA0DpK4T/vFzo0tdMpUGXvlLHGha65FUjWYDy1wq321P1yNx4Qp9FuLFrDrr0ZVNxyrfVcHns8m3MDF36BnXmKXsLrf2mIkVM8dO4kiNemvqPMKhFjyk5vMumoes1mHOgHiup8jNhA5zwBVuIC20fMPOl0fmEP+ACWGjHVJ5SoKyulcx9XgBOTh0r2ODsNxIl9HIHCN8h7oBjsDvAySL8NqTBNvj+OFmEL2qp5/ewkTgHqDOPLkBrG2XiQoB6fXcCoZM11bQDuWsllwRHpEW3lCR76rcRJ3vaRDlJOVd6PVbS9VyvEVhp9VjJRpnKo1oR/qwJwEFZpvLEha78Cb8SmMoDYLWtYwUXuDoYiRJ6uXTCn+dZ4OpoKk353x5ut2eByYGlVgfq3KatdkaiAOBqR515VCszBQnU87sTExp4L/4ntOiipEt8H1p52hFup5niaUO3hL5G8ih3L3D3I+zHopIh5mQzeVztwDs6fB48EHummTxWQvlr1bFDjJtoJo+yIO7cOvLYqLhzjOQBUPEXEP7zslFxvzYVBxV3fh1rOKi484xkgYo84VpKHFTcBabioOLPpa7uyNBnakZoWw3fHYnRPL+izjxxE5t0uoQ66UZaWogWXZRYyuKsTleXlyQ1FyZndfwNlsH5SlTybYQ+lprzqKTpRi/pVEl/BjzUtqmopKkoK9lcnsQ/lLdO1PKZJEwxegmlSrgGrNTa88RdiPIcZSwP8ZeXtwbUlEdBzDjwDDOXJ+48cB9VSx4LvMdDzCnm8sSeAZ4h1Lw9W+DuD3ETzOXxjgbvSbXkcYGrK8SZmwZAeQZC7NnUvP9xgdUWFX+luTzurhA/uZZ7XaCSUInXGctzRKQoiUiLLkoA+iYfx2XdppPqrdpEmuppx2Vdb6FfygijeZT3OFTq0+DqUfUOqx0q5cHyMyuDeTz9UG2eB/dhcwFYrUNzTCRcbTaPuxuqzQLwDDzsjmRU0s2oxGlm87jSUa0XgPe4w+6Ih4TrUcl3m81jtQrliTmRqgeWGIi/AtVqptF5ZZQVj2r9XKgYqrK78UDc+ajUJ8x1BQBKeVCpcyH211QdUueC2LNQrZ81W/QrC5U6G+IuBQ4921cQcyqqzYvG53FRKf+AhCnAoZMjqtCEgG1eRrkMdWdXvHLSdFTiVFAJVe/wHItqswDl6mQ0j4gupU1OWhAlBQUFpKSkkJ+fT3LykZ21a63ZVbKRgmAOSe5UMuKPxjI8CdfheQiuA3tv6EzcM9TozrvGTIH1oflKVHJoRk7Dk4JVyxPcDMEtoZ2V9zjjk4JVz7MDghtAxYDnOJRV13iTKOex90Dge8ATen+aesZbOys0Cy8u8A5BWalNm8fJAf+3hGZ0HYxy1TUeJ9p58sG/CgiCZ0DTz3jrFEHgm9Al+O4+xidNq5ZHl4H/6/IZXXuh3D3qflAtGuOYUd/X6Pb3v2PFNmz2a6esjO233RbVvM1Fi7765lBKKbokNJ+ZAZVS4BkQWpoJ5ekLHjPja+ojNAanV1PHqKTcXcHdtaljVFKuTtCMziKVKx1cpzd1jErKag2xpzV1jErKSoFYg11ZdVBWorHxa/WhVCzEmJ9hu8FkRteItPjuGyGEEEI0D9JSIoQQQkSLtJRERIoSIYQQIkrkV4IjI903QgghhGgWpKVECCGEiBaZZj4iUpQIIYQQ0SJjSiIi3TdCCCFElDT4F4KPcEzK7Nmz6datG7GxsYwYMYIVK1aEXX/WrFn07t2buLg4MjIymDp1KmVlVX9wdM+ePVx22WW0adOGuLg4BgwYwDfffFN5v9aaO++8kw4dOhAXF8fYsWPZtGlTRLmlKBFCCCH+hyxYsIBp06Zx1113sWrVKgYNGsS4cePYv7/mX8CeP38+t9xyC3fddRfr16/nqaeeYsGCBdx6662V6+Tm5jJ69Gg8Hg/vvPMOP/zwAw8++CCpqT9NgvjPf/6Thx56iDlz5vDVV1+RkJDAuHHjqhU34Uj3jRBCCBEtTdB9M3PmTKZMmcKVV4Z+p2jOnDksWrSIuXPncsstt1Rb/8svv2T06NFccsklAHTr1o2LL76Yr776qnKd+++/n4yMDJ5++unK27p37/5TRK2ZNWsWt99+OxMnhn4U9dlnnyU9PZ3XX3+diy6q3284SUuJEEIIES2N0XVTXpQUFBRUWXw+X7WX8/v9rFy5krFjx1beZlkWY8eOZdmyZTVGHDVqFCtXrqzs4tm6dSuLFy9m/Pjxleu8+eabDBs2jPPPP5927doxZMgQnnzyycr7t23bRmZmZpXXTUlJYcSIEbW+bk2kKBFCCCF+BjIyMkhJSalcZsyYUW2d7OxsbNsmPT29yu3p6elkZmbW+LyXXHIJ9957L2PGjMHj8dCzZ09OPvnkKt03W7du5bHHHuOoo47ivffe47rrruMPf/gDzzzzDEDlc0fyujWR7hshhBAiWhqx+2bXrl1VfpAvJqZxfoT0448/5r777uPRRx9lxIgRbN68mRtvvJG//vWv3HHHHQA4jsOwYcO47777ABgyZAjr1q1jzpw5TJ48uVFygBQlQgghRPQ0YlGSnJxc568Et23bFpfLRVZWVpXbs7KyaN++5l+evuOOO7j88sv5zW9+A8CAAQMoLi7mmmuu4bbbbsOyLDp06EC/fv2qPK5v3768+uqrAJXPnZWVRYcOHaq87uDBg+v9p0r3jRBCCPE/wuv1MnToUJYuXVp5m+M4LF26lJEjR9b4mJKSEiyrajngcrmA0ABWgNGjR7Nhw4Yq62zcuJGuXUO/jN69e3fat29f5XULCgr46quvan3dmkhLiRBCCBElTfHbN9OmTWPy5MkMGzaM4cOHM2vWLIqLiyuvxpk0aRKdOnWqHJMyYcIEZs6cyZAhQyq7b+644w4mTJhQWZxMnTqVUaNGcd9993HBBRewYsUKnnjiCZ544olQRqW46aab+Nvf/sZRRx1F9+7dueOOO+jYsSO/+tWv6p1dihIhhBDif8iFF17IgQMHuPPOO8nMzGTw4MG8++67lYNQd+7cWaVl5Pbbb0cpxe23386ePXtIS0tjwoQJ/P3vf69c57jjjuO1115j+vTp3HvvvXTv3p1Zs2Zx6aWXVq7zl7/8pbLbJy8vjzFjxvDuu+8SGxtb7+xKV7TN/IwVFBSQkpJCfn5+nf1tQgghWjYTx4yK1+h56324Ijgo18QuK2PLfbe2iGOctJQIIYQQ0SK/fRMRKUqEEEKIKGmKMSU/Z1KUCCGEENHUgoqKhpJLgoUQQgjRLEhLiRBCCBEtMqYkIlKUAI622Vj4LStzllIQOEiypw3Hpp5C7+ShWMplPI/WGvxfokteBmc3WG1QsRMh9nSU8jRNnsA36JKXwN4GKgUVdxbEjkepxpnmOOJMgTXo4hfB3gQqERV7BsROQFnxTZTnR3TpixD4HlQcKmYsxP0aZSU1TZ7gVnTJixBYDcqLijkZ4s5FWal1PTRKeXajS18A/zeACxUzBuLOR7nSmiaPnRnanv3LAA3eEaj4i1CuDnU+Nip5nBwoeRnt+xQIgudYVPzFKHeXJsqTD6UL0b4PQfvAM6A8T68mylMEZW+iy94DXQLuvqHPy9Ov7gc3MRlTEpkjuiR49uzZPPDAA2RmZjJo0CAefvhhhg8fXuO68+bNq5ywpUJMTAxlZWU1rn/ttdfy+OOP8+9//5ubbrqpXnkacnlXwPHx3+0z2FK0BoWFxqn8b4+EY7i8+214LXMHXq0D6Lxp4HsPcAE2oV42B9wDUK3noqwUg3kcdMEdUPpy9TyuHqjW/zV6YNFao4v+BcVPHpJHARqsjqE87gxjeQB00ePoogcPywNYrVGpz6I8R5nNU/IiuuAuQp+TXX6rChVvqXNR3kFm85S+jc7/M6HTPaf8VgvwolLnoGJGmc3j+xidewMQPCyPhWr1H1Ts6Wbz+L9G504BXXZIHhegUSn3oeLOMZsn8AM65wrQ+fx0iu4CHFTSraiExvudk3rlCW5D51wOzn4qv+sV37WEG7CS/hDxc5q8JPiov9yHK6aBlwT7ytj0z5ZxSXDEY0oWLFjAtGnTuOuuu1i1ahWDBg1i3Lhx7N+/v9bHJCcns2/fvsplx44dNa732muvsXz5cjp27BhprCO2aO9cthatBUCX7xAq/rut+Afe3vNkrY+NBl30EPjeL/9XxQGlfEcV/AGdf7PRPJQ8XV6Q1JDH3oHOu8FsntKF5QXJoXnKd5xOFjp3Clo7NT0yKnTZ0vKC5PA8Gpw8dO5VaO03l8f/NbrgzvIM9qH3gC5G516NdgrN5Qn8iM7/U3mWQz8XB/Chc69F27XvOxo9T3B3eUESqCGPjc67ER3cZi6Pk1NDQQIV75fOn44OrDGYpwSdexXoAqr2GdiARhf+He37wlweHUTnXg3OwYpbDskDFD+CLl1sLM8R0Y20tBARFyUzZ85kypQpXHnllfTr1485c+YQHx/P3Llza32MUor27dtXLof/tDHAnj17+P3vf8/zzz+Px2Omi6I4WMDKnA/RtXziGodvcz+mKJhnJI/WpVDyX2rfAm3wfYgO1lzUNX6eILr4qTBr2BD41thOU2uNLn6CypaImvLYW8H/uZE8ALr4SWr/GtngZEHZewbzzCV0FlkTB3QhlL5mMM+z1P55acAPpQvM5Sl9gYoDbM15NLrkOWN5KHkFdClVC5JDWejieebylL0NTk6YPC508f+Zy+P7EOzdVC2wD2WV7xOar4rum4YuLUVERYnf72flypWMHTv2pyewLMaOHcuyZctqfVxRURFdu3YlIyODiRMn8v3331e533EcLr/8cv785z/Tv3//OnP4fD4KCgqqLEdie/EPOLVu7OXZcNhe9MMRPX/EAutC/aV18df+Xjeq4FZwsutYyQW+L43EwTkQGtMS9rTBjTaUR2s/BFZR+w4cwIX2mzuzxPc5te/AQ7Tf0OcF4P+E8Hmc8nEUhvjqymOXr2OG9n9G+O3ZBt9npuKUb6vhDgs2+JdhaiLwUKtMuKGPTqgF2SkykkdEX0RFSXZ2NrZtV2vpSE9PJzMzs8bH9O7dm7lz5/LGG2/w3HPP4TgOo0aNYvfu3ZXr3H///bjdbv7wh/r1Dc6YMYOUlJTKJSPjyMYQ1LeZ3wl70GlEOvzBJESBDkY9Skh98kSyXkPV93NoZnmMfV5QdybdzPJgNk99vmPNLY+x7RnQDnX3FZjsT6jv325ym46QdN9EJOrzlIwcOZJJkyYxePBgTjrpJBYuXEhaWhqPP/44ACtXruQ///kP8+bNQ6namnmrmj59Ovn5+ZXLrl27jihbp/j6jSTvHG9ooKKnD1BX15UG7xATacDdHVRCHSvZ4BlsIg1YaWC1q2OlIMpQHqViwdWL2rsnAByUqc8LwDOI8F9rC+U91lQa8BxL7d1JhO7zHmcqDXiH0bzy1OP98Zj7vJR3cB1rWOA+BqXMTHGlPEMIX3AocGWAMjf4P2JSlEQkoi2rbdu2uFwusrKyqtyelZVF+/bt6/UcHo+HIUOGsHnzZgA+++wz9u/fT5cuXXC73bjdbnbs2MEf//hHunXrVuNzxMTEkJycXGU5EqnedvRNPg6rlrfBwuLopKG09lYfAxMNymoFsROp/WNxgWcgylN3F1ej5FGxEH9J+DyuruAdaSiPCxU/idqLAAusNmDw6gmVcAW17zEUqLjyz9RkntpaJxTggrjzDOaZTPizXY2Kv9hUHFT8pYRvvbFR8ZeZioOKu6iONWyzV7vEnQN4qf075pRvY6byjAeVTLhDlYq/ot4ntKL5i6go8Xq9DB06lKVLl1be5jgOS5cuZeTI+h2YbNtm7dq1dOgQmg/g8ssvZ82aNaxevbpy6dixI3/+8595773oDxD8VefraO1tjzrsS6hQtPK249zO10c9Q5XXTb4V3H0I7RQOzRQ64KqUf5vNk/h78Ayr+FfVPCoJ1epRY2dNACRcBTGn/pShkis0P0irOSjlNZcn7jyI/XXNefCgWs1GWYnm8sScDvEVl+AfegbuInTJ60yUq67WpsajvMNRiVNryaNQyX9Hububy+Ppg0q+s5Y8oJJuMXrJtHJ3RqX8k9C2Uz0PCb9DxZxgLo+Vimr1UPnr15An7hKIPctcHhWHSn2MUKF0aJ7y71rs+PITp+ZLBrpGJuLJ06ZNm8bkyZMZNmwYw4cPZ9asWRQXF1fORTJp0iQ6derEjBkzALj33ns5/vjj6dWrF3l5eTzwwAPs2LGD3/zmNwC0adOGNm3aVHkNj8dD+/bt6d27d0P/vjolultx3VH/5JucD/g6ZwmFgRyS3KkMaz2W49qcTqyrru6LxqWsRGjzApS8GpqMy94LVitU3LkQfzHKam02j4qF1nOh9HV0yQtg7wSVBHETUfGXGj3AhfK4odUjUPY2uuR5CG4pb404C5VwOcrVyXAeC1L+AbGnoov/C8H1oGIg9gxU/OVGD7ihPAqSboGYkaErXwLfAR6IPQ0VPwnlif53qlqmxOvAMwRdMq988jQLYk5AJUxGeQaazxN/Kbj7ha5qOXTytITJKJNdNxV54iaAuye6+BnwfUyoS/RYVMKk0CRzpvPEngJt3wxtP74PQPvB0z/UShlzmvFWCeU9Dtq+jS75L5QtDl0+7T469DnGjjd7UnQkGqP7RYqS2l144YUcOHCAO++8k8zMTAYPHsy7775bOfh1586dWNZPG0lubi5TpkwhMzOT1NRUhg4dypdffkm/fs1nJr5YVzxj0iYyJs1cM3s4SsVBwmWoBHPNyOEo5YX4C1DxFzR1FCDUjUPcRFRcc/m8FMSOQ8WOa+ooQHmemJNDs7g2EyrmeFTM8U0do5LyDjE71qcOytMP1er+po5RSbl7oVLuBe5t6igAKHcXVPJtkHxbU0eJnBQlETmiGV2bGxOz8wkhhPjfYHJG1943Ns6Mrhv+0zJmdJXfvhFCCCGiRH77JjJSlAghhBDRIt03EWnmI4SEEEII0VJIS4kQQggRJdJ9ExkpSoQQQohoke6biEj3jRBCCCGaBWkpEUIIIaJFWkoiIkWJEEIIESWH/2DIkT5HSyHdN0IIIYRoFqSlRAghhIgW6b6JiBQlQgghRJTIJcGRkaJECCGEiBZpKYmIjCkRQgghRLMgLSVCCCFENLWglo6GkqJECCGEiBIZUxIZ6b4RQgghRLMgLSVCCCFEtMhA14hIUSKEEEJEiXTfREa6b4QQQgjRLEhLiRBCCBEt0n0TESlKhBBCiCiR7pvISFFyiKJgAYWBPJI8rUh0Jzd1HLSTh7azUFZrlCutqeOgnQK0nYmyklGu9k0dB+0Uoe29KCsB5erU1HHQuhQd3I1SseDqjFJN+9ueWvvQwV0o5QZXF5Rq2t5arf1oexegUK6uKOVq4jxBtL0TAOXKQClPE+dx0PYO0DbKnYFSMU2cR4O9C6195Xlim0GePWhdgnJ1RlnxTZpHRIcUJcDe0h28s+8F1hd+W3lbn6TBnNn+IjrFdzeexwluJVjwL7TvfcABQHmPx530RyzvUON5tL2HYMG/cMoWAcFQHs9g3EnTsGLGNEGebIKF/8IpfR3wh/K4++FKuglX7FjzeZwCgoUzcUpfBl0ayuPqiSvpBlxxE83n0aXYhf/BLpkPuih0o6sz7sTrsOIuMl4sae3HLnoUu/hZ0HmhG610XIlTcMVfYbxY0trGLv4/7OK54Bwoz9MaV/yVuBJ/GyrijObROCX/JVj0BDh7QzeqZFzxl+FK+r3x4kRrjVP6KsGi2WDvKM+TgCv+QlyJN6GsRKN5AOzSxdhFD6GDG8tvicGKPxd30h9RVqrxPBGR7puIKK31z/7PLSgoICUlhfz8fJKTI2vh2FWyhUc3342tgzjlBQCAwsKlXFzX8y66JhzV2JFr5QS3EMg+F3QxYB9yjwVYeFo/hRVzgrE82t6DP/vX4OTWkEfjbvUwrrjxBvMcxH/wHLD3HpZHhfKkzMAVf6G5PE4hgYPno4NbaszjSroZd+JvzeXRPgIHL0EHvoNDtufKPAm/xZ18s8E8QQK5U9C+T6lpz2rFXYA7ZYaxQklrTTBvKk7ZmzXcq1Axv8CTOttooRTIvxun5Nka7rFQ3hF4Wj+NUl5jeYKF/8Eu+g8V20yVPO5+eNq8aLSVwi5+hmDBPTXkcaFcXfC0XYiyUiJ6zoYcMyJ9jYFX3IfL27BWJttfxpp5t0Y1b3PRoq++0Vrz8q7HCR5WkABoHGwd5KVdczBZtwXz766hIIHQAcYmkPcXtD78vijmKbi/hoKkIg8E86ejdZm5PEUP1VCQQMXOKph/J9rJM5bHLv4/dHBzrXnswn+i7T3m8pTMRwdWw2Hbc2We4sdxAj8ay+OUvo32fUJtp3pO6Uto/wpzeXyf1FKQAGi07z2csvfN5fGvrqUgAXDQ/mU4pQvN5QluLS9IoPpn5qCDP2DXmrfxafsAwYK/1ZLHRts7sYseM5bnSFSMKWno0lK06KJkT+k29pbtQFfbgYdoNFm+3ewq3WIkjw7uRvu/oPoB7qdEOFlo3+dm8jh5OGXvhM+jC3HK3jOTR/twSl8JkwcgiFP6hqE8GrvkeaoXAIdS2CUvG8kD4BQ/V8caLpySBUayANglzxF+N+MKdTMZEnqtcGNZLMN5XiB8HoVd52faeJySlwifxzGaxy59lfB9FzZ2yQtoHTQVSURZiy5Ksn2ZjbpeQ2l7ez3WUvVcr+G0vZvwBQCAGx3cbiANYGdXjtmonctcHl0CTk7dq5nKA+UDN8PvxJ3gVlNx0MFthC/a7PKuL0OqdbMdzjGap3q3X7U1QoNfDQltq3V85529xlprQ9tPHYcpXQi6wEieI6IbaWkhWnRREuuqX79orCsuyknKqaR6rKRBmRlopuqVxzGWh3oNsNP1XK8RqBjCn1UCWObyAKiEOlawUJbBPmmrrm1IgdE8db+W2fcnhTp3w3V+po3ISqLubToGU4cOVef2A6BANd8rcZTWjbK0FC26KOmZ2I84V/gvfKwVx1GJA4zkUZ4BYHWoYy0PVuxpRvLg6oJy9yU0wKw2GlfcGUbiKCsF5R1F+M3Wxoo1M/BWKTdW7BmE34kHccWeZSQPgBV3NnU1v1uxvzQVp/zqo3Cfl8YVd7apOOXvT7jt2cIyeMVUaNsI15LkwhX3K0NpKP/uhGsFcWHFnW1sYLIVexYVV/zVlkfFnNbklyuLxtOiixKP5eX09HPDrjM2/Vw8lpmR70pZuJP+GHYdV8LVKKuVoTwKV9I0am87VFhxFxidI8Sd9IfK167OQsX8AsvT11geV+LvCH2NasrjQnmGo7wjjOVxJ1xd3oJT01fbhXL3MVfUAq74y0AlU3Oh5AJXBlasuaLEFXcuWOm157FaG716y4obj3L1qD2PiseVMMlcnpgTUZ6BteSxADeuxGuM5VGeQSjvCdS8PStA4U683lieIyLdNxFp0UUJwAltx3NG+wuwcKFQuFTovxYuTk8/j5PSzJ3lArjiz8GdfBfgJfSlc1NxObAVfxWuOoqWRs8TexrulH+BqujCqsijsOLOx51yj9E8lnc47tRHD+kyclOxA7Viz8CT+m+zeTx98bSeC6pVtTwqZgye1k8YnRdEubviaf0cWBWT7R2SxzMET+tnjU4SplxpeNq8AK6O1fO4e+NtM9/o5aXKSsbb5gWUu8chedzlWbuUX+5qbt4LpWLwtHke5elffourMg9WOp4281GV752JPK7QJcje42rI0xpPm2ex3D0N5lGhS7RjTqmeRyXjTn0CyzvIWJ4jIVffRKbFz1NSoShYwOrcLygI5pLkTmVwq1EkeSK79r0xaacAp/St0OWkVmtccWc16Syq2inGKVuEDu4AKxlX7HiUO6Pp8ugynNJ3QpfjWvFYsWdiVR5omiKPH6fsA3RgPahYrNjTjLbYVM8TxPF9hPZ/B8qDFXNyk+68tXbQvs9wAt8AFlbMaJTnuCab9VZrjfYvx/EvBzSWdzjKO6rJZr3VWqMD3+L4PgVslGcIVsxJTTrrrRNYh1P2IWg/ytMfK3Zsk8566wQ24pR9ALoU5TkaK3bcEU8sZ3KekiGX/r1R5in59vnbWsQ8JVKUCCGEaFGMFiWXNFJRMr9lFCUyzbwQQggRJfKDfJFp8WNKhBBCCNE8SEuJEEIIES3yg3wRkaJECCGEiBLpvomMFCVCCCFEtEhLSURkTIkQQgghmgVpKRFCCCGiqCV1vzSUFCVCCCFEtGgdWhr6HC2EdN8IIYQQolmQlhIhhBAiSuTqm8hIUSKEEEJEi1x9ExHpvhFCCCFEsyAtJUIIIUSUKCe0NPQ5WgppKRFCCCGiRTfSEqHZs2fTrVs3YmNjGTFiBCtWrAi7/qxZs+jduzdxcXFkZGQwdepUysrKKu+/++67UUpVWfr06VPlOU4++eRq61x77bUR5ZaWEiGEEOJ/yIIFC5g2bRpz5sxhxIgRzJo1i3HjxrFhwwbatWtXbf358+dzyy23MHfuXEaNGsXGjRu54oorUEoxc+bMyvX69+/PkiVLKv/tdlcvIaZMmcK9995b+e/4+PiIsktRIoQQQkRJU1x9M3PmTKZMmcKVV14JwJw5c1i0aBFz587llltuqbb+l19+yejRo7nkkksA6NatGxdffDFfffVVlfXcbjft27cP+9rx8fF1rhOOdN8IIYQQ0VIxeVpDF6CgoKDK4vP5qr2c3+9n5cqVjB07tvI2y7IYO3Ysy5YtqzHiqFGjWLlyZWUXz9atW1m8eDHjx4+vst6mTZvo2LEjPXr04NJLL2Xnzp3Vnuv555+nbdu2HHPMMUyfPp2SkpKI3i5pKRFCCCGipDFbSjIyMqrcftddd3H33XdXuS07OxvbtklPT69ye3p6Oj/++GONz3/JJZeQnZ3NmDFj0FoTDAa59tprufXWWyvXGTFiBPPmzaN3797s27ePe+65hxNOOIF169aRlJRU+Txdu3alY8eOrFmzhptvvpkNGzawcOHCev+tUpQIIYQQPwO7du0iOTm58t8xMTGN8rwff/wx9913H48++igjRoxg8+bN3Hjjjfz1r3/ljjvuAODMM8+sXH/gwIGMGDGCrl278tJLL3H11VcDcM0111SuM2DAADp06MBpp53Gli1b6NmzZ72ySFEihBBCREsjTp6WnJxcpSipSdu2bXG5XGRlZVW5PSsrq9axHnfccQeXX345v/nNb4BQQVFcXMw111zDbbfdhmVVH+nRqlUrjj76aDZv3lxrlhEjRgCwefPmehclMqZECCGEiJKK7puGLvXl9XoZOnQoS5curbzNcRyWLl3KyJEja3xMSUlJtcLD5XIBoGv5McCioiK2bNlChw4das2yevVqgLDrHE5aSoQQQoj/IdOmTWPy5MkMGzaM4cOHM2vWLIqLiyuvxpk0aRKdOnVixowZAEyYMIGZM2cyZMiQyu6bO+64gwkTJlQWJ3/605+YMGECXbt2Ze/evdx11124XC4uvvhiALZs2cL8+fMZP348bdq0Yc2aNUydOpUTTzyRgQMH1ju7FCXlcv0H+SbnMwqCeSS5WzGs9Rhae9s2WR7HPkCgdCHa3oOyWuOJ+xWWu1vT5XFyCZS8hra3g0rBE3cWLk/vJsujnUICpa/jBDeDSsATeyYu74AmzFNCoOwtnMAPoGJxx/4Cl+dYlFJNk0eXESx9BzvwHeDBHXsKLu/IJswTIFj2Prb/G8CFK2Y07piTUKppGmu1tgn6PsT2LQc0Lu8I3LGnoVTT7BK1drB9nxP0fQYEcXmH4I49A6W8TZRHY/tXEPQtBe3H8vTHEzcBpWKbJA+A7V9NoOxd0KVY7t544iairIQmy1Nvh1w906DniMCFF17IgQMHuPPOO8nMzGTw4MG8++67lYNfd+7cWaVl5Pbbb0cpxe23386ePXtIS0tjwoQJ/P3vf69cZ/fu3Vx88cUcPHiQtLQ0xowZw/Lly0lLSwNCLTRLliypLIAyMjI499xzuf322yPKrnRtbTNhzJ49mwceeIDMzEwGDRrEww8/zPDhw2tcd968eZXVWYWYmJjKmeICgQC33347ixcvZuvWraSkpDB27Fj+8Y9/0LFjx3rlKSgoICUlhfz8/Dr72w6ntebtfS+yNOstQGEphaNDnYCntPslEzpejGV4x+krfBRf4QOEOhJdgAPYeOIvJjbl78Z3nP7i/1KWfzcQLM+jARt37FnEpc40vqMKlLxBaf6fQfuq5HHFnEJ86myUlWg2T9kSSnN/D7qYn+r8IC7PccS1fhLL1dponqBvOSU514DOq5LHcvcnvs3TWK4jn0PgSNj+NZTkXI12sqrmcfUgvs0848W2HdhESc4VaHtXlTzK6kh8m6dxefoazeMEd1OScwVOcONhedoS1/r/cHuPNZvHPkBJzlU4ge+q5EGlEJ86G3fsiUbzaCefkpzfYvu/PCxPPHGt/o0n7sxwD69RQ44Zkb7GyDPvxe1p2D4yGChj2Tt3RjVvcxHx0bZipri77rqLVatWMWjQIMaNG8f+/ftrfUxycjL79u2rXHbs2FF5X0lJCatWreKOO+5g1apVLFy4kA0bNnD22Wcf2V8UoSVZb7Ik6000Go2DrW00DhrNh/vf5oOs143kqOAvno+v8B+ATagYCZT/PwRKXqSs4O9hHt34AqWLKcu/rTyHJlSYhPIEyxZTmld9Ip5oCvo+pzTvD6DLquWxfZ9Skvs7o3ls/3eU5lwDuuJa/GD5AnZgVejgp839cIUd3ELJwctBF1TL4wR/pOTgxWjtN5bHsfdRfPBitHOgeh57B8XZF6KdImN5tJNHycEL0fbeanm0k0Vx9oU4dra5PLqM4oMX4gS31JAnh5KDl+IEq88FEb08QUoOXoYTWFctD7qAkpwrsQM1X1YanTyakpwp2P6KSbwOzVNKae51BH1fG8sjoi/iouTQmeL69evHnDlziI+PZ+7cubU+RilF+/btK5dDr59OSUnhgw8+4IILLqB3794cf/zxPPLII6xcubLGiVkak9/x80HWG2HXWZL1Fj67LOw6jUVrG1/hzHBrECh+Bsc+aCiPxlf4IFBbk79DsPQ1nOCOWu5vfL7CWWHy2Ni+j7H9a8zlKZpN7cPrbZzAamzf58by+IueJLTTrqkQsnGCWwiWvWsuT/Ez5S1INefRTiaB0vrPYdDgPCUL0M5BKgrZw/OgCwiUzDeWJ1D6ZnmLTU15HNBl+IufNpYnWPYhTnB9LXk04OArmmMsj+3/Gtu/PEweha/oYWN5jkgT/fbNz1VERcmRzBQHoVG6Xbt2JSMjg4kTJ/L999+HfZ38/HyUUrRq1arG+30+X7WZ7Y7EpsLv8TmlYdfxO2VsLFoXdp3GYgfWoJ3aW5xCgqF+XgMceztOcBPhvxGKQNl7ZvI4udj+FdR8gKvgIlD2jpE8WgcJln1AzTvMCm4CZYuN5AEIlL5F+DwWgVKTed4k/OdVkdmM0GuF254dAqXhT1QaU6D0bWovsgHs8vfQjGDZYkJdorWxCZa+XesVGdHJE6672sb2fYKuYz/elExfffNzF1FREm6muMzMzBof07t3b+bOncsbb7zBc889h+M4jBo1it27d9e4fllZGTfffDMXX3xxrX1nM2bMICUlpXI5fJa7+vI79WsB8dnVp/KNCl1cj5UUOPVZrxHUK49Vz/UagVOf6YoN5tF+whcAABqtI5tmuUF0XTtnB23q/YFDurVqXcFo9w1OYZ2rmM1TRF2nwSa3n9Br1bVN+6mr0Gws9fvbNbrO7V78XER9BOfIkSOZNGkSgwcP5qSTTmLhwoWkpaXx+OOPV1s3EAhwwQUXoLXmscceq/U5p0+fTn5+fuWya9euI8rWLrZ+A2nb13O9hrLcPQh/1gSgsTy9TMTBcmVQ9wVaQSy3mTzK1RZUXaPtg1juo4zkQcWhrOq/uFmVxmXo/QGw3N0Jvw25cJl6f6D8swi3m3FhGbyKy/L0IXxLgOk8RxM+j2Xs+wVguXsSPo9CubqgVLh1GjNPL+osgFQrlJViJM8RcXTjLC1EREXJkcwUdziPx8OQIUOqzQJXUZDs2LGDDz74IOwI45iYmMqZ7eozw11tOsV1pUt8T1Qtb4PConNcNzrHdz+i54+U5eqIK+Ykat8pWChXZ1ze0UbyKCsFd9zZYfIoUK1wx/7CTB4Vgzf+ojB5AGLwxE00lEfhTZhE+K+RwhN/gZE8AN6EK+pYI3QVlynehMsJf1Cx8SZcZipO+WuFawmwyzOb4Y2/lPB5nPJtzIzQ9yt8EeBNmGwmDOCJO4+6ijZvwuXGiqQjImNKIhJRUXIkM8UdzrZt1q5dW2WGt4qCZNOmTSxZsoQ2bdpEEqtBLu5yDV7Li3XYW2Fh4bW8XNzlt8ayAMSl/LW86j/8S+YC3MS1+rfRuR1ik6ejrPRa8ljEpf4bpRrn9xfqIybpxvJLSA/PYwGKuFb3oyxzl8x5E6ZgeY6h+lcp9O/YlLuMXoLrib+wvGitOU9M0h9xecy1lLhjz8IdO57qrTehf3sTrsLtHWYsj8s7Bk9cRVFWvUXJHfdr3DFjq90evTwD8CZWXDFW/T1yx5yGJ+7XxvJY7q7EJFf8CNvheSxcnmFGizbL1ZrYlIorDg/fpl1Y7t7EJF5nLM+RUDTCmJKm/iMMivjoNm3aNJ588kmeeeYZ1q9fz3XXXVdtprjp06dXrn/vvffy/vvvs3XrVlatWsVll13Gjh07KufYDwQCnHfeeXzzzTc8//zz2LZNZmYmmZmZ+P3Rv3SxY1wX/tj77wxuNaKyMFFYDGo1nGm9/0bn+G5Rz3Aoy92VhLZv4447B/CU36pwx5xCQtrruGNGmM3jSich7U088RcBPxUfrphRxLd5CU/saUbzKKsVCW1fC7UIqPif8niHEd/mOTzx5nbgoTxxJLRZgDfxWlA/FUOW5xjiUv+vHi0XjZxHeYlv8zQxSTehrJ+Ke8t9FHGtHiIm6UbDeSziUh8hJvlWlPVTcaZc3YhN+QcxyXcZzqOIbTWD2JS/oVydf7rd6khM8l3lRb/ZQ0BM0s3EtnqwvPu2Ik8aMUl/Jq71E8bnJYpJ/C1xqY9iuX+ar0WpVLyJvye+7fPG5yXyJlxEXOt5uDyDf7pRJeFN+A0JbV8xPi+RiK4jmjztkUceqZw8bfDgwTz00EOVP7xz8skn061bN+bNmwfA1KlTWbhwIZmZmaSmpjJ06FD+9re/MWTIEAC2b99O9+41d4989NFHnHzyyXXmaayJcMrsUoqDRSS4E4l1xR3x8zQW7ZSgnYMoK8Xo2X+teXQZ2s5GWYkoq1VTx0FrH9o+ACre+ARlNecJoO39oGKwXE03G/BPeYJoOwuUB2WlNdlsrj/lscsnULNQVnozyOOUX+2my/M07U+Baa3L89jleZq+S8KxD4D2o1ztUMpT9wOinicHdCnKldag2W5NTp42+rS7cbsbOHlasIwvlt7dIiZPO6KipLkxsYEJIYT432CyKBlzauMUJZ9/2DKKEvmVYCGEEEI0C/KDfEIIIUS0NMbVMz/7/oz6k6JECCGEiBKlNaqBoyQa+vifE+m+EUIIIUSzIC0lQgghRLQ4NHxWfnM/NN7kpCgRQgghokS6byIj3TdCCCGEaBakpUQIIYSIFrn6JiJSlAghhBDRonVoaehztBBSlAghhBBRUvGjeg19jpZCxpQIIYQQolmQlhIhhBAiWqT7JiJSlAghhBBRopzQ0tDnaCmk+0YIIYQQzYK0lAghhBDRIt03EZGiRAghhIgWmackItJ9I4QQQohmQVpKhBBCiCiR376JjBQlQgghRLTImJKISPeNEEIIIZoFaSkRQgghokUDDZ1npOU0lEhRIoQQQkSLjCmJjBQlQHGwiE8PvMuygx9RFMwn0Z3M8W1O4cS0cSS6k43n0U4R/uJn8JfMR9uZKCsFT/x5eBOuxnKlm8+jy/AXP0eg+DkcexdKJeKJ/xXehN9guTOaIE+AQMmL+IufxQluBRWHJ24C3sQpuNw9miCPTaB0If7ieTiBH0HF4I49g5jEKbg8fZsgjyZY9jb+oqexA2tAuXHHnEpM4jW4vION5wEIlH2Av+gpbP9KUBZu7xi8iVNwxxzfJHmCvs/xFT2J7VsGaFwxw4lJmII79uSmyeP/Bn/RkwR9H4N2cHkH4024CnfsGSiljOex/WvxFT1J0PcB6ACWpx8xCVfijpuIUuZ7/e3ARvxFTxIoWwy6DMt9FN6EyXjiz0epZn4Y0zTCmJJGSfKzoLT++ZdgBQUFpKSkkJ+fT3JyZEVEnj+H/2y6m1z/QfQhbWwKixRPKjcdfQ+p3jaNHblWjpNLSfZ5OMEtVG3zc6GsVsS3fQWXu6exPNoppvjgxTiB7ypuqcyDiiOhzQJc3gHm8mgfJTlXYfs+r54HD/Ft/os7ZoTBPDaludcTLFsMqMPyKOJaP4EndqzBPJqy/OkESuYTGjJWsQ25AE1cq3/jif+1sTwAZQX34y+aXZ7BPiSPTWzKX/EmTDaax1c0B1/BfTXmiUn6IzFJNxrN4y9+kbL8mwl9XlXzeBKuJjb5TqOFSaB0EaW51xPanivyhLYld9y5xLV60GhhEiz7lJKcq8qzHJYnZixxrR9HKU9Ez9mQY0akr3Hq4Ftwu2Ia9FxB28eHq/8R1bzNRYsf6PrizifIO6wgAdA4FARymb9zjtE8Zfn3hM7+q3VC2mgnj9KcGzBZR/oK/4UTWEP1GYBs0CWU5F6D1uZ+mMFfNAfb90XNefBTkjMFrcuM5QmUPE+w7J3yfx2ex6Y093doJ99YnmDZW+UFCVTdhmzAoTRvGo69z2CeT8sLkooMVPn/svw7sQMbjeWx/WvKC5Ka8/gKHyTo+9pYHie4nbL8WwhtO9XzBIqfIuhbYi6PnU1p7h9qyBPaloKlrxIofdVYHu0UU5J7LRCsOY9vKf7iecbyHJGKq28aurQQLbooyfZlsb7wO5xaRiE5OGwsXMf+MjM7ccfOIVj6JlW/fIeycYLfYwdWG8mjnVL8JS9Q+ygtB23vIej7xEweHSzfAdWeB51HoHSxoTwaf9FT4dYA7cNf8oqRPAD+ormE/1pr/MXzw9zfuEKflyvMGhb+4v8aSgP+4mcJn8eFv/gZU3HwFz9PqEWiNi78RU+bikOgZAGh/U9tB0Grjm2+kfOUvgG6iNq/86HvYLNu8HcaaWkhWnRRsqtkWz3X2xrlJCFOcD2hM4Jw1CFdKdHl2FtBl9SxlttYHu3sRzsHm00edBmOvY3wHb5WeUuTGXZgLeH3YA62qfcHsAPfUnuRDWCHxpkYEnqtuvJ8YyoOtn8VdeYxdBIChMYghd2eHZzgD8ZaR0N/e/gxI9rZi9Z5JuIIA5r5CKHoctdzgJTLMvU21adfVNdzvcbwc8wD4I1qikoq3Bn3oUy9P4Bygw6EWwFl6v0B6vO3K2UwT33GHhjNU/drKZO7aeWh6tiomrgI37rTmOr3WSiT37EIydU3kWnRLSU9E/vUWZi4lIujEvsZyePyDgSVVMdaCnfMiUbyWO6eKKtDHWvZxq5YUFZbLHdvwm+2QXN5lBeXdyThuwPMvT8A7phTCJ9Hm80TO5a6um/cBgcCu2NPp67uG0/sL0zFwR17KnV137hiTzcVB3fMSYRvaXPhijnJ2MDb0LYarvXYwuUZgrISjeQ5IjKmJCItuiiJdycyqs1pqFp2CgrF8W1OIcFdV6HQOJSKJSbxN2HWsHDHjjd2Ga5SLmKSrguzhguXdyQuT39DeRQxiddT+07TheXui8s7ykgegJjE66i9+d2FcnXGHTvOWB5v4jWEe3+U1QZPnLmrb7wJVxA66Nb0HbNCl3PHX2Qwz2WEWm9qyqMAF96Ey83liT8fVDI174pDLRYxiVcZy+OJm4Cy2lF74eYQk3itsTzumFOwXD3C5vEm/s5YHhF9LbooAZjY6VKOSRkKgFX+dlT8t2/yYH7dydwOCsCb+AfcceeV/8tV5b8u7zDiWj1gNI8nfjLehKsPy1P+Prn7EJf6mOE8vyImaVrNeVxdiW8zz+jlk+7Yk4lNvoeKA1pI6PWV1Y74Ns9HfLlig/J4jyW21czyLBVf74o8KcS3eQ5lJRjL4/IcTVzqHEKFwKG7GwUqnvjWz2K52hrLY7k6EN/maVBxVC1MFBBDfOv/w3J3NZZHWa1IaPNceQvpocWbBbiIS33EWNEPoROj+DbzUVbrilvK/xvanmJTZhidW0YpF/FtnkW5OpbfUrENhbqQYpJvxRNnrug/ItJSEpEWP08JhK6i2Fy0nhU5n5DnzyHFm8rw1idyVGL/Jpm4SGuNHfiWQMmLOMFdKFdbPHG/xh1zcpNMXARgB9bhL34BJ7gNZbXCE3c27tixTTZxkR3YSKBkPnZgE8pKwBP7S9xxZ5odn3AIJ7gdf/Hz2MEfUMThjhsXOutUsU2Tx96Lv3h++UBBL57YU/DE/brJmrkdez+BkhcJ+r8GXLhjxuCNPw9ltWqaPE4ugZIFBMsnT3N7R+CJvwjLZW5OokNpp4BAyasEfJ8CQdzeY/HEX4zlat9EeUoIlL5OsGwpmjJcngF44y9tkskSITSBY6B0EcHSd9GU4HL3wZNwyRHP2WRynpLT+v6xUeYpWbr+wRYxT4kUJUIIIVoUKUqarxZ99Y0QQggRVQ4Nv1ipBc1TIkWJEEIIESVySXBkpCgRQgghoqUxBqq2oKKkxV99I4QQQojmQVpKhBBCiGhxNKgGtnQ4LaelRIoSIYQQIlqk+yYi0n0jhBBCiGZBWkqEEEKIqGmMGVlbTkuJFCVCCCFEtEj3TUSk+0YIIYQQzYK0lAghhBDR4mga3P0iV98IIYQQosG0E1oa+hwthHTfCCGEEKJZkJYSIYQQIlpkoGtEpCgRQgghokXGlEREihIhhBAiWqSlJCIypkQIIYQQzYK0lAghhBDRommElpJGSfKzIEWJEEIIES3SfRMR6b4RQgghRLMgLSVCCCFEtDgO0MDJzxyZPE0IIYQQDVXRfdPQJUKzZ8+mW7duxMbGMmLECFasWBF2/VmzZtG7d2/i4uLIyMhg6tSplJWVVd5/9913o5SqsvTp06fKc5SVlXH99dfTpk0bEhMTOffcc8nKyooot7SUlLO1zabC7ykI5JLkacXRScfgUq4my6O1g+1fjmPvQVmtcceMQamYJsyjsf3f4NjbUSoFd+yJKBXbpHmcwHfYwc0olYA75gSUldhkeQDswA/YgR9QKjb0eVmtmjjPJuzAGpTy4PKOxnK1adI8TnA7Qf8qFC5cMSOwXO2bNo+9F9u3AtC4vMOw3BlNnGc/tn85WgdxeQfjcvdo2jxOLrbvc7T24/Icg8vTu0nzaKeAoO8ztC7F5e6NyzugSfM0ZwsWLGDatGnMmTOHESNGMGvWLMaNG8eGDRto165dtfXnz5/PLbfcwty5cxk1ahQbN27kiiuuQCnFzJkzK9fr378/S5Ysqfy32121hJg6dSqLFi3i5ZdfJiUlhRtuuIFzzjmHL774ot7Zj6gomT17Ng888ACZmZkMGjSIhx9+mOHDh9e47rx587jyyiur3BYTE1OlAtNac9ddd/Hkk0+Sl5fH6NGjeeyxxzjqqKOOJF7Evs1dxsLdz1IQzKu8Lcmdwq87Xc7Q1qONZDhUoOwjyvKmo529P92oWhGbfDPehEuN5wn6vqIs7y849rZD8iQSk3Qj3oRrUEoZzWP711Ka90ec4I+H5InDm/BbYpJuQimzDYB2YBOledNwAt8dcqsXT8IkYpOno5THaB4nuJvSvGnY/uWH3OrGE38+sSn3GC8mHfsApXl/wvZ9dMitFu64s4lLuc94MamdPErzbiFY9g4/XdagcMeMJbbVA1iu1obzlFCafwfB0lc5tJnf5R1DXOpM48Wb1j7K8v9GoOR5IPhTHs+wUB53N8N5bHyFD+AvegrwVd5ueY4hrtVMXJ4+tT+4OWiCga4zZ85kypQplcfeOXPmsGjRIubOncstt9xSbf0vv/yS0aNHc8kllwDQrVs3Lr74Yr766qsq67ndbtq3r3l7zM/P56mnnmL+/PmceuqpADz99NP07duX5cuXc/zxx9cre8R774oK7K677mLVqlUMGjSIcePGsX///lofk5yczL59+yqXHTt2VLn/n//8Jw899BBz5szhq6++IiEhgXHjxlUpXKJlde5XzNv+UJWCBKAwmM+zOx5hVe6XUc9wqKDvM0pzrkQ7+6reofMoy5+Ov/i/ZvP4v6Xk4CU4dtXPDF2Er+Dv+IseNprHDmyk+OD5OMGNh+UpxV80C1/B34zmcYK7Kc4+Fyew7rB7/ASKn6I0789m89gHKc7+Nbb/68PuCRIoWUBJzm/RBkfya6eQ4uzzsH2fHnaPQ7D0TUoOXo7WAXN5tI/ig5cQLHuPqtdZaoK+Dyk5eAHaKTWYx6Yk56pqBQmA7V9GcfY5aCfPYB5Nae6NBEqe5dCCBMAOfEtx9jk4dqaxPABl+bfhL3qMQwsSACewPvTdC243midijm6cBSgoKKiy+Hy+ai/n9/tZuXIlY8eOrbzNsizGjh3LsmXLaow4atQoVq5cWdnFs3XrVhYvXsz48eOrrLdp0yY6duxIjx49uPTSS9m5c2flfStXriQQCFR53T59+tClS5daX7cmERclh1Zg/fr1Y86cOcTHxzN37txaH6OUon379pVLenp65X1aa2bNmsXtt9/OxIkTGThwIM8++yx79+7l9ddfjzReRBzt8NqeZ8Ou89ru/+IY+oVGrTVl+fdSfmF7jeuUFcwwutP0FdwP2NQ2UMtX+B8cJ9dcnsJ/g/bVmsdf/BROcJe5PEWPgS4k9B4dThMsXYgd+N5YHn/xXLRzoJY8DrbvI2x//XcQDc5TsgBtb689T2AlwbL3jeUJlL71/+3de1AT57sH8O/uJpsAlWC9EBGKjD1Q8WixHKEweOnvx1R7rFD0VGtbcDpWxx77c6Za66VeptgKHp3R1npBW8UZ51f0nFJxjh1sS6nV8TYHh2rxikURbbC2DRC55LLv+QOIjYRAQnYJ4fnM5A82u2+efdi8ebL77pu2AtJZPDZI1muwNBUqFo+1pRQ28yk4P55tYLa7MD84oFg8Nst5WJu/hvP+xwYm/Qmz6TMF46mEpfGfncYD1ojmBmW/GPWmiIgI6HQ6+yMnJ6fDOvfv34fNZnP4nAWA0NBQGAzOC8pXX30V2dnZSElJgVqtxsiRIzF58mSsWrXKvk5iYiLy8/NRXFyMnTt3oqqqChMmTEBDQwMAwGAwQBRFhISEdPt1nXGrKPGkAgMAk8mEyMhIREREID09HRUVDzvpqqoqGAwGhzZ1Oh0SExM7bbOlpaVDxeiJX0xXYLT84XKdeqsR102XPGrfXZL1GiTrVbicKYeZYG35rvPnvRmPzeCiw2xnhbXpfxWJh0kmWJuL4fwDpR0PS9NhZeJhEixN/91FPCpYGr9UJB4AsDQehOv/lwBL4/8oFQ4sjQVdrMHD3HhIkVgAwNJ4CK67PQ7mxoNKhdP2v3A1dk2Cucscek/rseoqHpuy+WkqRFfxWJsOgzGzUiG5jTHJKw8AuH37Nurq6uyPlStXeiXGH374ARs2bMCOHTtw/vx5FBYW4ujRo1i/fr19nRdeeAEvv/wyxo4diylTpuDrr7+G0WjEoUPeff+6VZR4UoHFxMRg7969KCoqwoEDByBJEpKTk1FTUwMA9u3caTMnJ8ehWoyI8GyAWr21rlvrNViMHrXvLiZ1fgnsIQ6S7TfZYwEA1q3XEZSLRzLCdQEAADwkSZl4wJoA1tUlRkm5eAAw6fcu1rBBktwbDd8TrceQq8tFEphNyXgMcF20sbZ1lNG6766PaSbdVyYYwMVZtr+uVAfGunofejOersasWcCkBiXC8QzzwqWbtkuuwcHBDg+NpuPND4MHD4YgCB3ueqmtre10PMiaNWuQmZmJN998E2PGjEFGRgY2bNiAnJwcSJ3cjhwSEoLo6GhUVlYCAPR6PcxmM4xGY7df1xnZRwQmJSUhKysLcXFxmDRpEgoLCzFkyBDk5eV53ObKlSsdqsXbtz07Xa9TD+zmesoMfOP40K5XAlNs4BsndByl3ZFNuXj4gXD9rQkAbOC7lUcv4AIALqirlcDzyg1U5PghXawhgBfCFIkFADghFK4/VHiF4xkO192e0vEMQ1fHtGLHM9r7INfxcNxAcArdmcjxenQ9x7oGHD9AiXA8o/AtwaIoIj4+HiUlJfZlkiShpKQESUlJTrdpbGwEzzu+LwRBaAvf+WubTCbcuHEDw4YNAwDEx8dDrVY7vO7Vq1dRXV3d6es641ZR4kkF9ii1Wo1x48Y5VFftbXS3TY1G06Fi9ERUUDQeF1134iHqQRj5mDKjuwV1NHj1v8Llv4ULhkr7N0Xi4YVQCJoJcN1JqaEOmKZIPBwfBJX2xS7iAdSBM5SJh+MhBr7cRTw2qAP/Q5F4AEAMmgPXb2sb1AEKxhM4p4s1JKgDX1EkFgAQA2fD9ZkSCeqgrmL2ntZ4XJ114BSO52W4jkdQOJ6Z6DKegBngOFGpkPqEJUuWYM+ePdi/fz8uX76Mt956Cw8ePLDfjZOVleVw6Wf69OnYuXMnCgoKUFVVhW+//RZr1qzB9OnT7cXJu+++i+PHj+PmzZs4deoUMjIyIAgC5sxpPR50Oh3mzZuHJUuWoLS0FGVlZXjjjTeQlJTU7TtvADeLEk8qsEfZbDZcvHjRXl1FRUVBr9c7tFlfX4+zZ8+6VV15gud4zAyfC87FN7mZ4XPBK3iLqTZ4HVr/Lc5j0urWKnpLpzZ4JVrvHHeeA03we+B4nWLxaIKXAFwgOisExMfeAi8MUywe8bH/dHkGRx34mqLzO4hBb4ATwjqJh4NK++8QROe378tBHTgbvCq6k3h4CGIyVNq/KxaPKmAaBHU8nB/PAnj1GKgD0hWLR9BMgKB5rvN4hCiIgcpNAyCIT0MVkAHn/Y8Ajh8CMehNxeLhVSOgDprXybMCwA2AZsA/FIvHI5LknYcbZs+ejc2bN2Pt2rWIi4tDeXk5iouL7cMkqqur8euvD+/wXL16NZYuXYrVq1cjNjYW8+bNw5QpUxyuaNTU1GDOnDmIiYnBrFmzMGjQIJw5cwZDhjz8Yr9lyxa8+OKLmDlzJiZOnAi9Xo/CQvcGjnPMzfsDDx48iLlz5yIvLw8JCQnYunUrDh06hCtXriA0NBRZWVkYPny4fVRwdnY2nn32WTz55JMwGo3YtGkTDh8+jLKyMsTGxgIANm7ciNzcXOzfvx9RUVFYs2YNLly4gEuXLkGr7foDuL6+HjqdDnV1dR6dNamoO48va/bjd/PDMR2Pi0MwIzwLY3T/5nZ7PWVtOY3muvchWSvtyzg+FNrg96EOfEnxeGzmn9BkXAHJ+nCAMscPgmbAEohBmcrHY7mGZuNy2CxlDxdywdAM+EevzJsiWavRZFwOm/kvEwRxgRCD5rfNm6LsJHySrRbNxhWwtnyPh6e+NRCDsqAJXqH4vCmt84Ksaruro71zVUMdOAta3TrF501h0gM0161rG0TZftur0DZvynpwvGdnXj2Oh7Wgue6jtrtM2gdsclBpp0Cry1F80jvGrGhp2Azzg32t46ba4hE0ExEQ8l+KFv2t8Ugwm7a33elmsi8XxERoQzZ6NMlcTz8z3HmNvz/2KlQ9PJNjZWaUmP4pa7y+wu2iBAA+/fRT++RpcXFx+OSTT5CYmAgAmDx5MkaMGIH8/HwArTO8FRYWwmAwYODAgYiPj8eHH36IcePG2dtrnzxt9+7dMBqNSElJwY4dOxAdHd2teLxxgDHGcLPxOuosf0KnGojIoCcVPUPiLB7JcsE+o6sgjlf8w+1RNsslSNZb4PhgCGKC4h9uHeO5Bsl6AxwXBEGT0KszzAKtM5baLFcATgOVmAiOD+zleGpgs/wMcGqoxIRev+7eejfXTwDHt86gyndvTJd88fzeWtgyQBDHgRe6Go8jLyYZYTX/H8BsEMSxin/4d4zHBKv5HMDMENSjwKsiezce1gxby1kw1gRe/S8QVCM9bouKEt/lUVHia5Q4wAghhPgHJYuSvwW+4pWi5PvGgn7xGUe/fUMIIYTIhXU+GaZ7bfQP9CvBhBBCCPEJdKaEEEIIkYvEAI7OlHQXFSWEEEKIXBiD67lxuttG/0CXbwghhBDiE+hMCSGEECITJjGwHl6+8YObZLuNihJCCCFELkxCzy/f9HD7PoSKEkIIIUQmdKbEPTSmhBBCCCE+wS/OlLRXkfX19b0cCSGEEF/X/lmhxBkIK2vp8eUXKyxeisb3+UVR0tDQAACIiIjo5UgIIYT0FQ0NDdDp5PmVc1EUodfrcdLwtVfa0+v1EMWeTVffF/jFb99IkoS7d+9iwIABPf6F2Pr6ekREROD27dt+/xsDnqD8uEb5cY3y4xrlxzVv5YcxhoaGBoSFhYHn5RvF0NzcDLPZ3PWK3SCKIrTa3v3RUSX4xZkSnucRHh7u1TaDg4OpU3CB8uMa5cc1yo9rlB/XvJEfuc6Q/JVWq+0XhYQ30UBXQgghhPgEKkoIIYQQ4hOoKHmERqPBunXroNFoejsUn0T5cY3y4xrlxzXKj2uUH//nFwNdCSGEENL30ZkSQgghhPgEKkoIIYQQ4hOoKCGEEEKIT6CihBBCCCE+we+Lku3bt2PEiBHQarVITEzEuXPnurVdQUEBOI7DSy+95LCcMYa1a9di2LBhCAgIQGpqKq5fvy5D5MrwZn4sFguWL1+OMWPGICgoCGFhYcjKysLdu3dlil5+3j5+/mrhwoXgOA5bt271TrC9QI78XL58GWlpadDpdAgKCsL48eNRXV3t5ciV4+0cmUwmvP322wgPD0dAQABiY2Oxa9cuGSJXhjv5yc/PB8dxDo9HJyfztz6632F+rKCggImiyPbu3csqKirY/PnzWUhICKutrXW5XVVVFRs+fDibMGECS09Pd3guNzeX6XQ6dvjwYfbTTz+xtLQ0FhUVxZqammTcE3l4Oz9Go5GlpqaygwcPsitXrrDTp0+zhIQEFh8fL/OeyEOO46ddYWEhe/rpp1lYWBjbsmWL94NXgBz5qaysZI8//jhbtmwZO3/+PKusrGRFRUVdtumr5MjR/Pnz2ciRI1lpaSmrqqpieXl5TBAEVlRUJOOeyMPd/Ozbt48FBwezX3/91f4wGAwO6/hTH90f+XVRkpCQwBYtWmT/22azsbCwMJaTk9PpNlarlSUnJ7PPPvuMzZ0716FDkCSJ6fV6tmnTJvsyo9HINBoN++KLL2TZBzl5Oz/OnDt3jgFgt27d8lbYipErPzU1NWz48OHs559/ZpGRkX22KJEjP7Nnz2avv/66XCErTo4cjR49mmVnZzsse+aZZ9j777/v1diV4G5+9u3bx3Q6Xaft+Vsf3R/57eUbs9mMsrIypKam2pfxPI/U1FScPn260+2ys7MxdOhQzJs3r8NzVVVVMBgMDm3qdDokJia6bNMXyZEfZ+rq6sBxHEJCQnoasqLkyo8kScjMzMSyZcswevRor8etFDnyI0kSjh49iujoaEyZMgVDhw5FYmIiDh8+LMcuyE6uYyg5ORlHjhzBnTt3wBhDaWkprl27hueff97r+yAnT/NjMpkQGRmJiIgIpKeno6Kiwv6cP/XR/ZXfFiX379+HzWZDaGiow/LQ0FAYDAan25w8eRKff/459uzZ4/T59u3cadNXyZGfRzU3N2P58uWYM2dOn/txMbnys3HjRqhUKixevNir8SpNjvzcu3cPJpMJubm5mDp1Kr755htkZGRgxowZOH78uNf3QW5yHUPbtm1DbGwswsPDIYoipk6diu3bt2PixIlejV9unuQnJiYGe/fuRVFREQ4cOABJkpCcnIyamhoA/tVH91d+8SvB3tDQ0IDMzEzs2bMHgwcP7u1wfI67+bFYLJg1axYYY9i5c6cCEfau7uSnrKwMH3/8Mc6fPw+O4xSOsHd1Jz+SJAEA0tPT8c477wAA4uLicOrUKezatQuTJk1SLN7e0N332LZt23DmzBkcOXIEkZGR+PHHH7Fo0SKEhYU5nCHwR0lJSUhKSrL/nZycjFGjRiEvLw/r16/vxciIt/htUTJ48GAIgoDa2lqH5bW1tdDr9R3Wv3HjBm7evInp06fbl7V3kiqVClevXrVvV1tbi2HDhjm0GRcXJ8NeyEeO/IwcORLAw4Lk1q1b+P777/vcWRJAnvycOHEC9+7dwxNPPGFfx2azYenSpdi6dStu3rwpz87IQI78REREQKVSITY21mHbUaNG4eTJkzLshbzkyFFYWBhWrVqFr776CtOmTQMAjB07FuXl5di8eXOfKkrczY8zarUa48aNQ2VlJQD4VR/dX/nt5RtRFBEfH4+SkhL7MkmSUFJS4lBpt3vqqadw8eJFlJeX2x9paWl47rnnUF5ejoiICERFRUGv1zu0WV9fj7Nnzzpt05fJkR/gYUFy/fp1fPfddxg0aJBi++RNcuQnMzMTFy5ccFgnLCwMy5Ytw7Fjx5TcvR6TIz+iKGL8+PG4evWqw7bXrl1DZGSk7PvkbXLkyGKxwGKxgOcdu25BEOwFTF/hbn6csdlsuHjxor0A8ac+ut/q7ZG2ciooKGAajYbl5+ezS5cusQULFrCQkBD7LWSZmZlsxYoVnW7vbOR7bm4uCwkJYUVFRezChQssPT29z95u5u38mM1mlpaWxsLDw1l5ebnDbXstLS1y747XyXH8PKov330jR34KCwuZWq1mu3fvZtevX2fbtm1jgiCwEydOyLkrspEjR5MmTWKjR49mpaWl7JdffmH79u1jWq2W7dixQ85dkYW7+fnggw/YsWPH2I0bN1hZWRl75ZVXmFarZRUVFfZ1/KmP7o/89vINAMyePRu//fYb1q5dC4PBgLi4OBQXF9sHQVVXV3f4xtGV9957Dw8ePMCCBQtgNBqRkpKC4uLiDhP49AXezs+dO3dw5MgRAOhwqrS0tBSTJ0/2VuiKkOP48Sdy5CcjIwO7du1CTk4OFi9ejJiYGHz55ZdISUmRYxdkJ0eOCgoKsHLlSrz22mv4448/EBkZiY8++ggLFy6UYxdk5W5+/vzzT8yfPx8GgwEDBw5EfHw8Tp065XDJz5/66P6IY4yx3g6CEEIIIaT/fs0jhBBCiE+hooQQQgghPoGKEkIIIYT4BCpKCCGEEOITqCghhBBCiE+gooQQQgghPoGKEkIIIYT4BCpKCCGEEOITqCghhBBCiE+gooQQQgghPoGKEkIIIYT4BCpKCCGEEOIT/h8JdmCl3ZMhWAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluamos el valor optimo para el threshold\n",
    "test_true_labels = []\n",
    "for data in test_en_dataloader:\n",
    "    input_ids, attention_mask, labels, _ = data\n",
    "    test_true_labels += labels.tolist()\n",
    "\n",
    "all_mcc = []\n",
    "threshold = []\n",
    "low, up = [], []\n",
    "test_outputs = np.array(baseline_test_outputs)\n",
    "test_outputs = test_outputs.mean(axis=0)\n",
    "for i in range(40, 51):\n",
    "    for j in range(50, 61):\n",
    "        test_mean_predictions = [0 if x < i/100 else (1 if x > j/100 else -1) for x in test_outputs]\n",
    "        mcc = matthews_corrcoef(test_true_labels, test_mean_predictions)\n",
    "        all_mcc += [mcc]\n",
    "        low += [i/100]\n",
    "        up += [j/100]\n",
    "        # create a df with the results and sort by mcc\n",
    "\n",
    "df = pd.DataFrame({'mcc':all_mcc, 'low':low, 'up':up})\n",
    "df = df.sort_values('mcc', ascending=False)\n",
    "# display all df\n",
    "#pd.set_option('display.max_rows', None)\n",
    "display(df.head(15))\n",
    "\n",
    "# plot que representa en los ejes x e y los valores de low y up y en el eje z el mcc\n",
    "plt.scatter(df['low'], df['up'], c=df['mcc'], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ensemble MCC 0.5 threshold: 0.8730\n"
     ]
    }
   ],
   "source": [
    "evaluate_kfold_ensemble(baseline_test_outputs, test_en_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes de la seleccion del top 0.5 en validacion:\n",
      "50\n",
      "test ensemble MCC 0.5 threshold: 0.8730\n",
      "Despues:\n",
      "23\n",
      "test ensemble MCC 0.5 threshold: 0.8730\n"
     ]
    }
   ],
   "source": [
    "# Seleccion de los modelos que superan al % de SELECTION en validacion\n",
    "SELECTION = 0.5\n",
    "l = [float(m.split(\"_\")[-1][:-4]) for m in modelos]\n",
    "\n",
    "# ordenamos de menor a mayor en una nueva lista\n",
    "l_sorted = sorted(l)\n",
    "threshold = l_sorted[int(len(l_sorted)*SELECTION)]\n",
    "indices = [i for i, x in enumerate(l) if x > threshold]\n",
    "\n",
    "# Filtramos los outpouts de los modelos que queremos ensamblar\n",
    "test_outputs = np.array(baseline_test_outputs)\n",
    "test_outputs = test_outputs[indices]\n",
    "\n",
    "print(f\"Antes de la seleccion del top {SELECTION} en validacion:\")\n",
    "print(len(baseline_test_outputs))\n",
    "evaluate_kfold_ensemble(baseline_test_outputs, test_en_dataloader)\n",
    "\n",
    "print(\"Despues:\")\n",
    "print(len(test_outputs))\n",
    "evaluate_kfold_ensemble(test_outputs, test_en_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4579360,
     "sourceId": 7862518,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
