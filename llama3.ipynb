{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3538bbc755a043a6b202f6f30154aed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, shiver me timbers! Me name be Captain Chatbot, the scurviest pirate to ever sail the Seven Seas! Me be a swashbucklin' chatbot, here to regale ye with tales of me adventures on the high seas, and answer yer questions to the best o' me ability. So hoist the colors, me hearty, and let's set sail fer a treasure trove o' conversation!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.float32}, \n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Iñaki and my favorite food is seafood paella.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"you are a professional translator who translates phrases from Spanish to English on demand. You only answere the translation without any greetings and farewells.\"},\n",
    "    {\"role\": \"user\", \"content\": \"me llamo iñaki y mi comida favorita son los arroces de marisco\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Iñaki and my favorite food is seafood paella.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3600 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 0/3600 [08:54<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El G7 realiza una simulación de “ Pandemia de Viruela de leopardo ” : los ministros de salud se reúnen “ contra la próxima crisis ” Los ministros de salud del G7 ya están practicando “ la próxima pandemia ” . En Berlín , realizan una simulación del curso de una pandemia de viruela en 2023 , según informa el periódico alemán Bild . Cabe recordar que el mismo escenario futuro , en base esta vez a una modificación de la viruela , viene siendo anunciado por el magnate Bill Gates .   | https :// trikooba . blog / 45408 . html   Síguenos en :   Nuevo TELEGRAM : https :// t . me / trikooba2022   Nuevo FACEBOOK : https :// bit . ly / 38b1CEr INSTAGRAM : instagram . com / trikooba TWITTER : twitter . com / 3Kooba _ com MEWE : bit . ly / 3dxxenE VK : vk . com / trikoobanews \n",
      "The G7 is conducting a simulation of a \"Leopard Virus Pandemic\": health ministers meet \"against the next crisis\". The G7 health ministers are already practicing \"the next pandemic\". In Berlin, they are conducting a simulation of the course of a 2023 smallpox pandemic, according to the German Bild newspaper. It is worth noting that the same future scenario, based on a modification of smallpox, has been announced by billionaire Bill Gates.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# load dataset train_es_data.pth\n",
    "datadir = \"/home/iñaki/host_data/dataset_oppositional/\"\n",
    "train_es_dataset_path = datadir + \"train_es_data.pth\"\n",
    "train_es_dataset = torch.load(train_es_dataset_path)\n",
    "\n",
    "# iterate over the dataset and translate the spanish sentences to english\n",
    "translated = []\n",
    "for i in tqdm.tqdm(range(len(train_es_dataset[0]))):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"you are a professional translator who translates phrases from Spanish to English on demand. You only answere the translation without any greetings and farewells.\"},\n",
    "        {\"role\": \"user\", \"content\": train_es_dataset[0][i]},\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    print(train_es_dataset[0][i])\n",
    "    print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "    print(\"--------------------\")\n",
    "    translated += [outputs[0][\"generated_text\"][len(prompt):]]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new dataset\n",
    "train_es_translated_data_path = datadir + \"train_es-translated_data.pth\"\n",
    "torch.save([translated, train_es_dataset[1]], train_es_translated_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
